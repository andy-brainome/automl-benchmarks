#!/usr/bin/env python3
#
# This code has been produced by an enterprise version of Brainome(tm) licensed to: andy Stevko.
# Portions of this code copyright (c) 2019-2022 by Brainome, Inc. All Rights Reserved.
# Distribution and use of this code or commercial use is permitted within the license terms
# set forth in a written contractual agreement between Brainome, Inc and brainome-user.
# Please contact support@brainome.ai with any questions.
# Use of predictions results at your own risk.
#
# Output of Brainome v1.8-120-prod.
# Invocation: brainome TRAIN_TEST_SPLITS/fri_c0_1000_50-clean-train.csv -f NN -y -split 70 -modelonly -q -o btc-runs/NN/fri_c0_1000_50.py -json btc-runs/NN/fri_c0_1000_50.json
# Total compiler execution time: 0:00:21.10. Finished on: Feb-26-2022 18:40:56.
# This source code requires Python 3.
#
"""

[01;1mPredictor:[0m                        btc-runs/NN/fri_c0_1000_50.py
    Classifier Type:              Neural Network
    System Type:                  Binary classifier
    Training / Validation Split:  70% : 30%
    Accuracy:
      Best-guess accuracy:        51.00%
      Training accuracy:          89.16% (436/489 correct)
      Validation Accuracy:        79.62% (168/211 correct)
      Combined Model Accuracy:    86.28% (604/700 correct)


    Model Capacity (MEC):        181    bits
    Generalization Ratio:          2.40 bits/bit
    Percent of Data Memorized:    83.36%
    Resilience to Noise:          -0.38 dB







    Training Confusion Matrix:
              Actual | Predicted
              ------ | ---------
                   1 |  217   23 
                   0 |   30  219 

    Validation Confusion Matrix:
              Actual | Predicted
              ------ | ---------
                   1 |   83   20 
                   0 |   23   85 

    Training Accuracy by Class:
         binaryClass |   TP   FP   TN   FN     TPR      TNR      PPV      NPV       F1       TS 
         ----------- | ---- ---- ---- ---- -------- -------- -------- -------- -------- --------
                   1 |  217   30  219   23   90.42%   87.95%   87.85%   90.50%   89.12%   80.37%
                   0 |  219   23  217   30   87.95%   90.42%   90.50%   87.85%   89.21%   80.51%

    Validation Accuracy by Class:
         binaryClass |   TP   FP   TN   FN     TPR      TNR      PPV      NPV       F1       TS 
         ----------- | ---- ---- ---- ---- -------- -------- -------- -------- -------- --------
                   1 |   83   23   85   20   80.58%   78.70%   78.30%   80.95%   79.43%   65.87%
                   0 |   85   20   83   23   78.70%   80.58%   80.95%   78.30%   79.81%   66.41%




"""

import sys
import math
import argparse
import csv
import binascii
import faulthandler
import json
try:
    import numpy as np  # For numpy see: http://numpy.org
except ImportError as e:
    print("This predictor requires the Numpy library. Please run 'python3 -m pip install numpy'.", file=sys.stderr)
    raise e
try:
    from scipy.sparse import coo_matrix
    report_cmat = True
except ImportError:
    print("Note: If you install scipy (https://www.scipy.org) this predictor generates a confusion matrix. Try 'python3 -m pip install scipy'.", file=sys.stderr)
    report_cmat = False

IOBUF = 100000000
sys.setrecursionlimit(1000000)
TRAINFILE = ['TRAIN_TEST_SPLITS/fri_c0_1000_50-clean-train.csv']
mapping = {'1': 0, '0': 1}
ignorelabels = []
ignorecolumns = []
target = ''
target_column = 50
important_idxs = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]
ignore_idxs = []
classifier_type = 'NN'
num_attr = 50
n_classes = 2
model_cap = 181
w_h = np.array([[-0.08651581406593323, 0.24070341885089874, 0.11573463678359985, -0.23629359900951385, 0.006079881452023983, 0.12449762225151062, 0.06546632200479507, 0.13947930932044983, -0.08953854441642761, -0.041750311851501465, -0.009387997910380363, -0.24618801474571228, -0.24243684113025665, -0.020733125507831573, -0.07323005795478821, 0.26995721459388733, 0.128413587808609, 0.07630033046007156, -0.22433310747146606, -0.04768757149577141, -0.184304341673851, -0.09646176546812057, 0.19103895127773285, -0.206983283162117, -0.42384910583496094, -0.30855271220207214, 0.44578230381011963, 0.08317966759204865, -0.20674467086791992, -0.12063504755496979, -0.28672632575035095, 0.436078816652298, -0.2802874445915222, -0.12452813982963562, 0.03478754311800003, -0.002226682612672448, 0.04258444532752037, 0.25952601432800293, 0.2483285367488861, 0.1629689782857895, 0.40159741044044495, -0.326473206281662, -0.10669735819101334], [-0.33360427618026733, -0.25816917419433594, -0.18419618904590607, 0.22543084621429443, 0.20948952436447144, -0.15845847129821777, -0.012892048805952072, 0.22851170599460602, 0.35519859194755554, 0.14180393517017365, 0.04826797544956207, 0.2395612746477127, -0.21037600934505463, 0.06657975167036057, -0.2770126163959503, -0.247636079788208, -0.18457262217998505, 0.16166625916957855, 0.143689826130867, -0.2116444706916809, 0.10794129222631454, 0.19614484906196594, -0.045096807181835175, 0.013642067089676857, 0.08278688788414001, 0.22165732085704803, 0.3430723547935486, -0.2753397822380066, -0.13093772530555725, 0.14042039215564728, 0.29603639245033264, 0.3109205365180969, 0.31526148319244385, 0.07110685855150223, -0.3106973469257355, 0.03286844119429588, -0.2235255390405655, -0.3329823613166809, 0.3174537420272827, 0.2716725766658783, -0.35641154646873474, 0.06687559932470322, -0.06018988415598869], [0.035828229039907455, -0.17573010921478271, -0.23908604681491852, -0.1610017716884613, -0.04640680178999901, 0.0713890790939331, 0.1349485218524933, 0.22251828014850616, -0.2888919711112976, -0.09302805364131927, 0.0745818093419075, 0.26326000690460205, -0.2805604040622711, -0.3621017634868622, 0.3069990873336792, -0.01827464997768402, -0.10401716083288193, 0.07900884002447128, -0.237309530377388, -0.1634797751903534, 0.034535687416791916, 0.10440420359373093, -0.24963760375976562, 0.5107547044754028, 0.21220959722995758, 0.5314595103263855, -0.3446722626686096, -0.0836464986205101, 0.23600777983665466, -0.2471897453069687, 0.07688413560390472, -0.13419188559055328, 0.15214323997497559, 0.12640203535556793, -0.1437961757183075, -0.2738781273365021, -0.3293986916542053, 0.2141321450471878, -0.4204637110233307, -0.14179807901382446, -0.47940295934677124, 0.0430791899561882, 0.04668527841567993], [-0.6149396896362305, 0.22678469121456146, 0.4181757867336273, -0.15779262781143188, -0.016977984458208084, 0.3774215877056122, -0.3873942196369171, -0.43053001165390015, -0.10673171281814575, -0.2656702697277069, 0.22340445220470428, -0.1778443604707718, -0.15275396406650543, 0.4406048357486725, -0.14408151805400848, -0.5464382767677307, -0.1794458031654358, 0.009870127774775028, -0.42187008261680603, -0.5490567684173584, -0.6002739667892456, -0.10604090243577957, 0.11127257347106934, 0.1331658661365509, -0.22401250898838043, -0.2891608476638794, -0.3252493143081665, 0.6572843790054321, -0.3583754599094391, -0.01741807721555233, 0.038807351142168045, 0.13206523656845093, -0.35303714871406555, -0.3631221652030945, -0.25350210070610046, 0.1064557433128357, 0.17630968987941742, -0.08227718621492386, 0.17520688474178314, -0.0942089781165123, 0.4741716980934143, 0.15932878851890564, 0.20309098064899445]])
b_h = np.array([3.2056760787963867, -6.314743518829346, 2.727062463760376, 0.37956205010414124])
w_o = np.array([[1.0651497840881348, 0.3967196047306061, -1.0835341215133667, 1.37498140335083]])
b_o = np.array(-1.423178791999817)


class PredictorError(Exception):

    def __init__(self, msg, code):
        self.msg = msg
        self.code = code

    def __str__(self):
        return self.msg
def __transform(X):
    mean = np.array([-0.01777930674846624, 0.015375668711656408, 0.06444775664621678, -0.02193591615541917, -0.02622103885480579, -0.008936423312883465, -0.022885498977505116, -0.012224654396728029, -0.010608959100204455, 0.023356652351738238, -0.007796087934560288, -0.052219507157464255, 0.024074752556237162, 0.0525286196319018, -0.01053550306748467, 0.03031556441717793, 0.016949126789366057, 0.008722398773006124, -0.011094439672801657, 0.04779569734151332, 0.005871985685071581, -0.08272261349693252, 0.01401954805725975, 0.04100653987730064, -0.026301695296523524, -0.031719517382413076, 0.00721666871165644, 0.03842802862985687, 0.030284597137014303, -0.010601834355828179, 0.025023674846625796, 0.025095468302658484, 0.0017756728016359838, 0.04391177505112474, 0.04169697750511246, -0.04005323517382411, -0.006639306748466273, 0.016238946830265843, 0.022605190184049082, -0.009093040899795528, -0.02952807566462177, -0.033681345603271975, 0.05110453578732103, 0.02927425562372188, -0.04133962167689162, 0.006122020449897752, 0.008265128834355857, 0.014430128834355817, 0.010886089979550102, 0.012228163599182012])
    components = np.array([[0.14682794406153085, 0.349217508911568, -0.010693743605991624, 0.017335805693624806, -0.16912743926291435, -0.07847237049674727, 0.030733198131095485, -0.02483006742300658, -0.2241445164250413, -0.05099489823565264, 0.010295469141680284, -0.020191069954319865, 0.17496506511682142, -0.21601875675820983, -0.10980446313144794, 0.026572331229886646, -0.19763790615503693, 0.038999563359710734, 0.019723156795574272, 0.29308578637116894, 0.04494147304408585, 0.2186984368110321, 0.028868196959310043, 0.0879191313610501, 0.17474538634198142, -0.015948006649802154, 0.030624734661501306, -0.1964330261978713, -0.08578877259149263, 0.13461277805801053, -0.05120182308752659, -0.22222823770200223, 0.2729657828182885, -0.12614941977447047, -0.256801727856414, 0.18766711570932623, 0.0650336429565835, 0.03618048714516998, 0.22320987764976968, -0.0321263341009427, -0.06059127118224136, 0.02846798627005679, 0.05937097252736792, -0.08837641045548074, 0.014951966904145877, 0.13871059535630245, -0.1634059752766461, -0.18173244720936807, -0.004113311089160271, 0.016216243623150557], [0.05011146425449629, -0.2819111351555741, 0.18982463708713782, 0.02139422592738735, -0.13614441858188078, 0.06442614160343307, -0.3149035558957875, -0.33902660564774006, 0.12152711915556974, 0.15627845726459638, -0.1632891678747992, -0.14512794199312756, -0.13948106538424304, 0.038544892138211446, -0.005129271070751187, 0.04964863066405874, 0.1185977037037734, 0.14307134801031218, 0.0053948353918811965, 0.19905022813425322, 0.12856248149819724, 0.051179768058535524, 0.26242146571364017, -0.0991476522572826, 0.062174845402956265, 0.1325816033607828, -0.2360176047862342, 0.06037640216638111, -0.0808037599385606, -0.05300842659620442, 0.10671094918511545, -0.15299269643303418, -0.01686626825183253, -0.05891499169956631, 0.10246390093785859, 0.16899268796692546, 0.06593728018152552, 0.10228015189064475, -0.13747416289239373, -0.15085730824559648, 0.0003685319240181841, -0.1451218930482882, -0.02820717931229022, -0.06216651181095525, 0.20598223188116976, 0.1028419735000569, -0.14500417117512324, -0.1952629445606233, -0.012114552842887311, -0.011208934839876113], [0.044914000974735226, -0.08124046614576896, -0.027134655894051285, -0.18770206571556663, -0.06324161084948185, -0.004944392361447475, 0.07286559789024642, -0.028694976030590888, 0.038084803915634825, -0.04355900103712989, -0.03561994746672425, -0.24085233487287241, -0.09861688594084839, -0.36270341752225044, -0.008573640121660925, 0.16286591148217383, -0.028245367695130974, 0.006248665306671841, -0.10975632550648329, 0.1477544930880626, -0.09049916081113879, 0.06362346160818144, -0.011933028665739379, 0.08863517922054995, 0.07847554044363092, -0.09587402107556373, 0.2440089024777388, 0.09250563226968736, -0.2833964938980317, -0.32195582529417116, -0.021212627717197678, 0.007554936053526412, -0.25382651846412196, -0.08994241610721053, -0.09576626741821498, -0.24828076386034748, 0.1777626946217598, 0.047244743031412635, -0.09961978846887679, 0.022059965242908722, 0.22114840527267668, 0.0722690666709285, 0.06557340898552703, -0.21828188644485527, -0.06376418740479266, -0.007602244218959456, 0.161222545484354, -0.039076753992312536, -0.034858655463325276, -0.25567299455936215], [0.14276128489270676, -0.01878288462424288, 0.015249912889812312, -0.05256112820789577, -0.017258665942243734, 0.05934437353161115, -0.09237953463405052, 0.06050270588340967, 0.1584118146877266, 0.17966364143118815, 0.30467789594420974, -0.12216931225752845, 0.24225764057113336, 0.06256585521120914, -0.11575250485298297, -0.07595930374535176, 0.1612327753794219, -0.031056506674526224, -0.015937214587645243, 0.0321611899380185, 0.14489203979422804, -0.13563245163342288, -0.026583687976937706, 0.16862075710195348, 0.232272578782041, 0.08754142278241525, -0.14393922194365955, -0.21223421165026, -0.04688829842343855, 0.06639509518603459, -0.25204259201046275, -0.030858304788886536, 0.13258001499846325, -0.08361439527168242, 0.020757023389525085, 0.03045220561451044, 0.040220015637054754, 0.14162254851062056, -0.2407051637441044, 0.1526217892774272, 0.09847649490649743, 0.20497075465178702, -0.20743738667733072, 0.10417795675651086, -0.06559831649051785, -0.3162531357007527, 0.2026841538844869, -0.12133963720872791, 0.05797113692358692, -0.142152222118728], [0.06223309336483693, 0.20703104297016206, 0.17481360784272576, -0.030996630912985337, -0.3835781588876075, 0.11096894940837962, -0.014351862457870054, -0.04164074626155719, 0.1007982935801633, 0.08094608825018873, 0.13137796689243814, 0.16215138771068716, -0.1187471314942962, -0.09892129550796414, 0.15055283100463984, -0.2279757470425976, 0.018136373645362025, -0.11119965458687554, -0.1926832600856316, -0.037314848554887536, 0.031016817582156297, -0.03091496970359081, 0.039608001639234364, -0.06780984915633274, -0.002784218735582808, 0.09881734446335294, -0.1127767531165796, -0.009725992413853458, 0.23624231474130847, 0.07627508157891416, 0.0018856237157556114, 0.14160259387399113, -0.242346879705545, -0.13431791951627836, -0.330695237999376, 0.014031911107341173, -0.11624678837657118, -0.008469538517861922, 0.07491796232350381, 0.11548578392265985, 0.2701250521417365, -0.11543439635596871, 0.07575277081023722, 0.05207176951852173, 0.23022967489620416, 0.01666113515961415, 0.0728709737278232, 0.12997422943759282, -0.18859686113640067, -0.11548803398564926], [-0.07135415898735173, -0.05222891993972871, -0.09502404160266098, -0.07335376771454777, -0.03777868306825784, 0.1475406670918768, 0.03083728584575171, -0.21486727815272813, -0.16001871240000012, -0.21110309939116484, -0.2512296297720219, 0.14172664400377677, -0.0031246849318311287, 0.1255272308466897, -0.25002456047422295, 0.027201387796534512, 0.03469886042558867, 0.09317778387088377, -0.30699335168779296, -0.17779090696600622, -0.10865182929757822, -0.15754488837840253, 0.20232924003868452, 0.04593103855276476, 0.31930313662490717, 0.03254023024093056, 0.0814488186012727, -0.12900869697144335, 0.21553792752290096, -0.2484041371656152, -0.22852787377388295, 0.16092254945296464, 0.012737496830478168, -0.044082348749060266, 0.039653936323522404, 0.17490853688064767, 0.10310829564989352, 0.04866555125080241, 0.2156878133109634, 0.0022191135738686236, 0.024744401400290345, 0.00919919371114115, -0.12986559922856655, -0.14297456170362927, -0.023101771875115494, -0.0834116453361191, 0.03640483676858602, 0.029642532009163607, -0.012487416556557928, 0.07366349951825396], [0.18460007680078805, -0.0968268700149669, -0.05811747732243547, -0.042813129207900064, 0.19280091569883234, -0.01613710747558192, -0.2613265514125694, 0.007257182527030448, -0.10050941462625684, -0.025418044537068002, 0.0756389608770113, -0.012634735584857837, -0.2117712094288088, 0.00013008799800471454, 0.1509697075964555, 0.022163287749135507, -0.0691209742960766, -0.014973086176401883, -0.15197795627519492, -0.13685436937130527, 0.014304796666130437, 0.038962352328036104, -0.11342034226148268, 0.0726804356833849, -0.016462929494045056, -0.14970879280554594, -0.04081750861212349, -0.3299473375231846, -0.08841650562903408, 0.26180480123439587, -0.1587193797256121, 0.23055458047429733, 0.07277672081055292, 0.1648386036164441, 0.09542629268540562, -0.12295002524884681, 0.29690719526051923, -0.11642636341154564, 0.07330592628943264, -0.011503581835941402, 0.274068951671614, -0.08693682681600501, 0.20184973634414996, -0.0711347767657848, 0.24890333386761238, -0.03655134751504075, -0.170068010227319, -0.11176685021583099, 0.0866705773568244, 0.03980509695524447], [0.09258916836986564, -0.12308306244968911, -0.32258905946078137, 0.21654918553094152, -0.05991627427401289, -0.22038636414472712, 0.07357950073267369, -0.05647921214039464, -0.004864286051003072, 0.1326975515415972, 0.007576425630267433, 0.1183971493983477, -0.08713155779711386, 0.0712183389389939, 0.04371868348122819, -0.19566827645164353, -0.11217431171968797, 0.11008424900510164, -0.11478259731753049, -0.07860289722989254, 0.2081187748963861, 0.0125331954098713, 0.07680738683019325, 0.18803448224488298, 0.22083688163941764, -0.06861946515027549, 0.11727483940749144, 0.2079758727102143, -0.26162169820957293, 0.04397011785059196, 0.006031319892870535, -0.023626157748623033, -0.0717624873072502, 0.06623351747135117, -0.0952099395068654, -0.04605676567007301, -0.1447324173260051, 0.3844000484424415, 0.04400129725812963, 0.12719357009335824, -0.05368222752045805, -0.06929087303459472, 0.02620949677531191, 0.031993039543463025, 0.17747154631282197, -0.010370597115005058, -0.06121662996004528, 0.20160813690612792, 0.2758599745739898, 0.026639107664708055], [-0.06357795642190156, 0.05700846081107135, -0.07979528951327919, -0.16840026776093708, 0.04709836837100575, -0.1378622918790189, 0.030556211571548253, -0.04440824719467722, 0.03319190786767641, -0.19693465751283318, -0.025970048215534308, -0.03463163367608986, -0.05675279620599398, 0.236086702985493, -0.031919391963052574, -0.26463517631632794, 0.0006803031409505222, 0.0438238720195358, -0.11179308186423195, 0.11218610888094983, -0.05298594231499221, -0.0649312073376272, -0.06828385748959193, 0.05788812019356626, -0.20142430922886984, 0.0012345249384836943, 0.169008588045035, -0.21855128899274825, 0.040243898873069006, 0.08976480675359455, 0.3686423261068068, 0.020045412437951132, 0.05392287373021001, -0.2187155093403199, 0.16184175543992474, -0.009236178364150726, -0.21202509754905435, 0.2366415104366977, -0.04290609282970576, 0.0746053919211134, 0.0688224243863053, 0.043004837374774896, 0.040008328778705006, -0.21675264236799927, 0.14992051960440292, 0.06425960773823071, 0.2659765064059044, -0.34502045110921453, -0.005771519450677574, 0.013864704150741074], [0.2884423902682863, 0.06900737581728683, 0.19023999240139935, -0.13219181792546816, -0.006949255663184661, 0.05698974190415418, 0.006203557716094821, 0.09732324450898433, 0.09523706416916658, 0.20356104574261819, -0.12923047567311657, 0.11981325185893399, -0.07808398504238889, 0.16482507947594913, -0.2561095096332544, 0.09398397237243428, -0.1805108587608009, -0.19900115413599093, -0.0979506868585294, -0.03241397722946846, 0.28971055475163154, -0.006387638503490695, -0.049038737804194335, 0.0015361282582156688, -0.019031050615173316, -0.24043650538520633, 0.06277577750018457, -0.022680239393666472, 0.09187972694274658, -0.0752593032920924, 0.07061040632698874, 0.1236816642733726, -0.14755799529346836, 0.11543004248331121, -0.12314614245577747, -0.014526181097431982, -0.10606667744862813, -0.11083003354278065, -0.1447064657036366, -0.051444312331080676, -0.028233754582665253, 0.18464548483106402, -0.2436581412155302, -0.12459100206755473, -0.06558767123044877, 0.28691637491324495, -0.08752710414160302, -0.13301825341255855, 0.26246634836636773, 0.042949358608710665], [-0.0031434900651540715, -0.0014707682766526568, -0.05502541699710832, 0.061510605965853456, -0.06026430757813488, -0.04702174336319252, -0.14112241661608638, 0.05709968539929099, -0.0264669849578069, -0.1057022709233374, -0.013743269646689803, 0.12950678473467644, 0.13539076552826312, -0.08574667957892686, -0.3104585081934492, 0.1002794224023226, 0.09613312141431642, -0.05230243695067474, -0.17509481866895116, -0.023801032805576314, 0.007700939238031763, 0.23306032272239727, -0.0882536018755682, -0.2297251382102545, 0.023714235074586816, 0.3776033925631905, -0.020155127522584238, -0.08642649473860825, -0.14148075659441936, 0.0943435401665614, 0.10228526666255362, 0.2002864325985498, -0.04789425865577054, -0.11813891377928187, 0.0564461043263926, -0.22944495675130994, 0.174028222602284, 0.15712214833013138, -0.23125816412156802, 0.11308936509962025, -0.0776265247401286, 0.1880236315918792, 0.039063981525015, 0.0927565049450627, 0.05220779035958961, 0.2348042543373991, -0.02619791509599001, 0.1944822816504952, -0.09890780797606663, 0.25210759471710575], [0.0840595113781177, 0.18549998735195392, -0.176443172165395, 0.08541882192864514, 0.03555969014546645, -0.18548573056417916, -0.3691922206106112, 0.14218319943620178, 0.1311685306482697, 0.07223640177679752, -0.06690466176488866, -0.08429378156852704, 0.27578811585392804, 0.04038902165840233, -0.10279357747185368, 0.07979953150713573, 0.059605815115350264, 0.3016783661495327, 0.21995438379075122, -0.15777719825279826, 0.15746480765926707, -0.1218917444561642, 0.014521866345775764, -0.32049675539094, 0.06749854122937902, -0.05751628119634786, -0.00973817385332576, 0.06705545191903006, 0.015793056425670415, 0.011789536640838441, -0.0049700453593226335, 0.1721988081747252, -0.14345596958340343, 0.03463079629469357, -0.06175103632350029, 0.0018648884854400947, -0.07703578540583676, 0.03347734890361974, 0.2363369494210552, -0.0823130958122962, 0.10375401488545435, -0.05706886975088539, 0.13200012822975027, -0.24486461641655338, -0.09879668255160037, 0.03518365061274072, 0.15019954985319772, -0.05292298219661286, -0.09509855270505009, -0.11936863095101848], [-0.1068852277020737, -0.12080011364175984, -0.2119752408653178, 0.1300774820376394, -0.0025991932664804172, 0.22876678305243314, -0.04507542188640186, -0.045198511076456886, 0.19653289810768637, 0.048202572490847445, 0.11124003872646906, -0.1238206097205263, 0.12888371050422825, 0.05996630926503177, 0.07355508647293824, -0.2064760797216041, -0.23548640428250883, 0.058839054937986746, 0.01805088476855988, -0.13273005181912972, 0.02223170138495554, 0.30986432825451043, -0.3070917635397765, 0.0035940212521300904, -0.025746740764712492, 0.11029536082495547, 0.1696346383361214, -0.02901081866882653, 0.08698378829843839, -0.15704530579728074, -0.09679459079621412, -0.030985142201906707, 0.006270302019929064, -0.06887883980045148, -0.07383853674028612, 0.08502488205381041, 0.068530670823121, -0.14124766127164884, 0.005600559202379346, -0.3509238816839511, -0.10002144207331644, 0.1416100538514711, -0.1882503569387593, -0.13123259737025203, 0.32441409398952503, 0.04457141851996079, 0.06158059813070559, 0.04697516328386416, -0.051478234722852775, -0.047207955418871295], [-0.2621645635090815, -0.043810480866116636, -0.2199603446026254, -0.13841332076972857, -0.17164217609628102, 0.15975515637575755, -0.07236821801366698, -0.02365908237647163, -0.015938441606462017, 0.18591228122084236, -0.0023879747867180112, -0.06447368702202416, -0.2501049797799272, 0.016600746262454613, -0.10595243133304857, 0.1185833316161122, 0.06806742128611012, -0.024520801411908467, 0.2160692658239495, -0.0049299446813616254, 0.16605161118604198, 0.022634416805519753, -0.007209790859181324, -0.041188665257720414, -0.007365203566939774, 0.12074121420854037, 0.07836463315808964, -0.08869200918220108, 0.18545903423666515, -0.09962675843068974, 0.20576886399235234, 0.06526714215471827, 0.09211375008646071, 0.03770920296542285, -0.16618685901477226, -0.08089375834795494, 0.16490376116562247, -0.02688783975433652, 0.23846094718474103, 0.19519533440994072, -0.14313859612017737, 0.19482728781711772, 0.24976555772664336, 0.23895205085491614, 0.03297632034206266, -0.09273829321702368, 0.04392677626788385, -0.14822199700578303, 0.2861168082847553, -0.11075699383837312], [0.06796577166295444, 0.02040252309050762, 0.005831744207651479, 0.10026081344312894, -0.12723515053068057, -0.022419593345891983, -0.2254863152260188, -0.20715147023128344, -0.008563191795052716, -0.053298282331259925, 0.15464615586913028, -0.10176361822720738, 0.1391009786954931, -0.07021266087440634, 0.12970710013351702, 0.1591795218377183, -0.2966388932071812, 0.21515607266270878, -0.16505792426271543, -0.008176845662005095, -0.30257430199323504, -0.3501495305779489, -0.15033722832673282, 0.1839906355366867, 0.01446206982001165, 0.09843275889155008, -0.18101556900145846, 0.10532314184382525, 0.14623970905873543, -0.01313989465292914, 0.12056918010169895, -0.08994110701606775, -0.08662345168171057, 0.15585526772078004, -0.037755827320638785, -0.11383410619436751, -0.048470640824278155, -0.13203626303433053, -0.04520220390013217, 0.20159993286042058, -0.1658374882007485, 0.19970755361503095, 0.03458560881430792, -0.07603510515395688, 0.023249590985638502, 0.10681463747314582, 0.035743858176881166, -0.04818574781976259, 0.15323307681304868, 0.13643672418884487], [0.10601255726659774, 0.05736399939350195, 0.1812847232815607, -0.009756658426329556, -0.08923618200275639, 0.26766788574362754, 0.046078244429589854, 0.0168605611277724, -0.09009811577551305, -0.08680461315827608, -0.03559019881063443, 0.07491438988845386, 0.08287095750471274, 0.07947544523068405, -0.03170974363644902, -0.00524585732144732, -0.1520005514334076, 0.20680300736234042, 0.07037885934331198, 0.023060671898672405, 0.23959012162244306, 0.05111525226025487, -0.1504713188742133, 0.054142995559231626, 0.1438470468092153, -0.11562917570292941, 0.059950976642935874, 0.10451453143124359, 0.07851798183963163, -0.10694557746700557, 0.09842222800230803, -0.1819487635558073, -0.12082264886049249, 0.09728117714665638, 0.24652248419273037, -0.15579419300600086, -0.04148147353488642, 0.1662623356854362, 0.03268157903539275, -0.15451089156317532, 0.26068371389385286, 0.19297590116581062, 0.27908700209517134, 0.22317193807694707, 0.01899028350447371, -0.22751456173450946, -0.041201986371528276, -0.06495598057803452, -0.19504326156113744, 0.2746640811156979], [0.196723890116016, 0.10094757876919706, 0.1375115350470958, -0.27867166495491813, -0.17038644358279764, -0.2593348787039835, 0.23689676382901237, -0.12392506588876595, 0.20685058766531242, -0.07345997428981749, 0.1311007331953879, -0.2560180988480504, -0.06617277145527663, 0.09789253334226922, -0.09234175033256478, -0.07891713698722866, 0.11473132472194969, 0.12683330038341162, -0.04737927765009414, -0.1598314518385564, -0.08472725709487917, 0.17797522055266093, -0.2564024676986473, -0.20434343720301631, 0.13588684520396122, 0.12672999395571022, 0.0460611378061995, -0.042756602032038446, 0.017385014177797656, -0.11824173814135805, -0.0053877962647100736, -0.00625623930036804, 0.02243419545379577, 0.19963377380303224, 0.0347691607675826, 0.1675778934727336, -0.01489602558055167, -0.06557862561082693, -0.07739346401596943, 0.022627985911012588, -0.09791279017981248, -0.21252105847481167, 0.20065248164920327, -0.04698964952886142, -0.0646176964276399, -0.14135131132887532, -0.1113816209897304, 0.07341334350997378, 0.19541070011891254, 0.11355583590879173], [0.17504111299008895, 0.09159021024288476, 0.06894491927391264, -0.207285580451583, -0.05679742043800262, -0.06899353494714186, -0.09530839479369374, -0.27671790544894526, -0.1442125601667561, 0.10142381199296732, 0.0933117630075758, -0.022888693431811824, 0.11225267710936326, 0.22217721703867133, 0.04330222854996901, 0.058287751435407306, 0.07616801129273704, 0.02490946628549165, 0.23841260872012413, -0.21453185196548996, -0.17678811375471737, 0.11359983128663459, 0.35911925673900974, 0.19131621708799623, -0.23191325339676155, -0.040185275826841865, 0.2730767611551468, -0.028944375628426278, -0.09139450451168601, 0.10896390352933166, 0.08697031417677864, 0.06473498806939956, -0.10645525060530361, 0.06263511218019109, -0.1581658317796922, 0.0431009610592746, 0.0905106227450633, 0.05068125655384828, -0.06261541212269692, -0.06440688404340636, -0.08063560666888642, 0.27231718024939155, -0.023980803880254184, -0.021092213841856562, 0.058665709209158264, -0.13984161462315717, -0.05905704136227173, 0.17597626273435704, -0.17074186473460634, 0.031809385911157784], [0.19696104274580967, 0.036255158137600094, -0.08127951021051273, 0.01917923599262697, 0.05480665837528456, -0.14796772432651706, -0.0805191949729431, -0.15709874771044874, -0.23838521831335674, -0.10842027237388843, -0.09147262118515914, -0.06620481580322117, -0.11684642881058377, -0.05201168953519003, 0.1225045102251587, 0.07991745896480176, 0.15549436274240847, -0.03550055638597094, 0.09311350508300062, -0.03957137566284119, 0.16303286703461722, 0.21087554173439435, -0.056331610575644286, -0.17065946939284596, 0.14441429501674433, -0.1814308549318097, 0.07605886890111627, 0.0644690814561978, 0.22179333779652596, -0.027231339417963435, -0.10201149059699835, -0.19838917399004818, 0.020816571209772337, 0.0728403977162548, 0.010161151312302524, -0.1508331057301088, -0.052955131459708094, -0.15032227694775463, -0.09119652889968405, 0.325672784020853, -0.1353365427910557, -0.057541116191875054, -0.25398938410104266, 0.08863997551428941, 0.2449595047558899, 0.00876172261608425, 0.33056973306612014, -0.07033447812134017, -0.17717377859197464, 0.08528639539462732], [0.23774363342511087, 0.1766298432655632, -0.015853513270186637, -0.047174723439409004, -0.11462709256372461, 0.07918958653153035, -0.1298997534653106, -0.0075900296751736235, 0.1989519551424108, -0.00691341645563405, -0.008370916895662023, -0.08616662076564358, 0.014688941372029224, -0.07149131364580132, 0.1121367100313411, -0.12037572212502576, 0.19370105853476835, -0.0070430627412565935, -0.11068083270389871, -0.013084122801572153, 0.0418592999742578, -0.02754083475344174, 0.1518390661970196, 0.22479659691743653, -0.1542400345108979, -0.05394533862219231, 0.08145073128594289, 0.05598471822773271, 0.05696399853820706, -0.23784449045854797, -0.2353727248543523, 0.12679870569032659, 0.3382886773074745, -0.0376480386293606, 0.23162618343927005, -0.2258035306161838, -0.07962993226402545, 0.05194847458861587, 0.09823060870301245, -0.14424065713094578, -0.20896600171583996, -0.02715205615959987, 0.19113572304346593, 0.1876204040253841, -0.036652215005767555, 0.33489301186052123, 0.08648296354323581, 0.05445567333997081, 0.004409522945237998, -0.002215351041971632], [-0.07407253538283115, 0.13318063576514974, 0.0279968791310475, 0.2965148281116136, -0.01211778786945765, 0.051182664470075745, 0.06590314512017077, -0.38066629864877494, 0.17653136383116946, 0.0539220422775139, 0.20028054839862847, -0.09218198528994057, -0.19846630620777028, 0.2757714957542915, -0.02118810397256478, 0.21379536851654785, 0.02727741563701124, 0.06163040686352484, -0.031979637431161036, 0.1550918493797834, 0.04684937443573209, 0.12608309015023944, -0.12602044718879912, -0.002104400740678195, 0.05875180890524032, -0.2001216623142569, 0.051373022507196796, 0.06396994106354942, 0.05260672668870979, 0.18222413043055252, -0.013485053820533707, 0.14194827509185098, 0.05312864461513861, -0.3590752844738163, 0.06648560931907278, -0.20062390007968242, 0.04053628864049878, -0.048097723529267944, 0.11858586202249535, 0.06037585325708475, 0.047258597244643284, -0.013905350056787232, -0.07041666197313612, -0.11713741649025747, -0.2804906994907343, -0.03520577481938292, -0.07320744664682255, 0.11962310692232453, -0.03299808679820468, 0.04212633220053397], [0.16674174213370643, 0.0007510448913197465, -0.030304090185990798, 0.05626570396181961, -0.09302950081023184, 0.020815252063768164, -0.11803442493391014, 0.1665201025635059, -0.0043840689784438724, 0.032637304502743346, 0.08456872224184966, 0.40236600753134133, -0.1509486702394734, -0.043496795272328234, 0.09556238339982931, 0.20404743243859394, 0.1709477941159312, 0.1540947795506692, 0.13309417354487002, -0.12830281182611503, -0.2664936006749564, 0.1505696965918502, -0.03547184052268029, 0.1126962072987947, 0.1789066100594402, -0.051863518143828086, -0.0526717539935533, -0.02418509078591051, -0.10430009821120559, -0.166541586436869, 0.2641796050617086, 0.004502458135396459, 0.17893562741129365, -0.23606516934398977, -0.039103299686125303, 0.11246755674849662, -0.07747381013031027, -0.14879862803752542, -0.10213269187246697, -0.18522839970770452, 0.1548219961987147, -0.05778110276910462, -0.039214317918917385, 0.0046504771136089765, -0.009784599442515855, -0.04353944238343661, 0.2379296171763414, 0.008860875757468384, 0.22364345350696985, 0.13467533360410103], [0.020880251246038744, -0.09975825463201632, 0.0724052010346538, -0.15569595769934932, 0.03808452708199784, 0.07892393650753085, -0.2691903323984876, 0.10216803843888952, -0.1822130307767508, -0.20423861124339554, 0.358264971819874, -0.11431063255361432, 0.14296358930195383, 0.11697678153385561, 0.10900146336956211, 0.00557137005760127, -0.0983995318487311, -0.05613079758877688, -0.03752969870471615, 0.21533882909665963, 0.013038335021702442, -0.05908339318397251, 0.07968707218662836, -0.21052447085370588, -0.02300144313241051, 0.02507139224635216, 0.26984367052540614, 0.08505634731310469, 0.09467075229668598, -0.12017965308488338, 0.06965210789738209, 0.05065751644109766, 0.002752664451970227, -0.04421718024826754, -0.14230064016418295, -0.08026521388946493, 0.06795562699492537, 0.17513909690400398, 0.09263665161094325, -0.08897407614329236, 0.08361154088934108, -0.3183017993756982, -0.26169991776338286, 0.1858699824650057, -0.07197361918854425, -0.0022990299314540907, -0.05178406343273817, 0.05425167705660408, 0.24345311810777298, 0.1354131079935503], [0.19947722457560726, -0.05421501834216488, 0.07338313536901417, 0.06604672817582137, 0.1899726566672812, 0.43040076754496115, 0.05925320130122999, 0.07885121812105317, 0.09128865811817277, 0.020107694059199932, -0.0818858804875307, -0.07182405571991118, -0.008600473541190597, -0.12108869510320408, -0.011381021687869808, 0.2328764078863203, 0.10389720194796742, 0.1451734573486904, -0.13049295520333498, -0.10318046231868801, -0.01704616018387048, -0.013418602389764112, -0.17020788089898597, 0.05506335628087214, -0.1780023627857496, -0.04452292233365557, 0.1449639383805984, 0.08150346162696936, -0.035204946676354314, 0.19207578682826623, -0.027144372144843637, 0.07982299616435845, -0.06108654800152105, -0.07274391826546554, -0.24694719430802842, 0.26773786843023406, 0.016091519713437447, 0.27406350398269563, -0.011192528207858998, 0.14084130742895676, -0.2821084527281342, -0.20528820589462005, 0.10622049294039686, 0.019487234770406522, 0.018504100698951767, -0.07033989354251081, 0.11774926559815531, -0.14076702016106998, -0.06693425949075331, 0.11964179203549881], [0.12493122251652422, 0.18557388678676978, 0.020429072348822172, -0.013348942648069753, 0.3976775009338998, -0.05036119601759807, -0.0032195269516690096, -0.014512978514996638, -0.036634151754758315, -0.05262538462806578, -0.25816865348168094, 0.00858738408679921, 0.09065388436489233, 0.16452275939691824, 0.22681149269757117, -0.011863004710231703, 0.11469114846453732, 0.11173553156972502, -0.173614197074449, 0.07220645264525186, 0.04666473500839603, 0.2110922947088147, -0.06398680420276158, 0.1468904954748071, 0.04398092884866349, 0.28778253556914235, -0.0837634107108487, 0.2443123686954207, 0.2717126376953479, -0.03687594362340496, 0.1531749891723129, 0.010519301700236378, 0.09728063228069699, 0.01926949848025089, -0.16786240349897824, -0.019556794418092063, 0.15047667419665386, 0.05244834976466238, -0.09092912583955573, 0.004849357520075259, 0.17567262420181048, 0.1013327166405991, 0.0231116363852982, 0.03325121368336087, -0.08365928334814593, -0.017883592690330963, -0.10036186594973107, 0.045217662837250094, 0.12063154834916875, -0.31350986065098574], [0.24661529683770955, 0.03166748734828079, 0.04821556194067278, 0.2655696153297262, 0.0830590602709564, 0.12658937229031295, -0.1628440886038497, -0.09048002923049052, 0.09388140854215346, -0.12134443272508497, 0.017317695014435225, 0.1707291540306817, -0.09151932930803006, -0.04035050724780659, -0.25798315680591144, -0.17010718660382312, -0.28413718166787394, -0.07213399708085816, -0.02538813058306738, 0.127306808110173, -0.1851738466975325, 0.14164652567185873, 0.18196615816948059, -0.12548548349339816, 0.05463298148818064, 0.0464856056274732, 0.1509846357954829, -0.08770935933051299, -0.0024561923564113963, 0.05588106731654094, 0.11140435747846107, 0.016182020397443375, -0.05799555761029748, 0.1743731853545486, 0.1391302351255692, -0.04958363236387464, -0.06498209783425084, -0.10774168362932332, -0.05161876363246998, -0.0002785027641801774, -0.19973526871571, -0.1098391993355908, 0.11187282611477585, 0.12738780707062938, -0.10471784905447779, -0.24349887230637784, 0.13104418212045227, -0.011689299108660428, 0.02435841986247892, -0.385792419271831], [0.27331848419106125, -0.11483658356816275, -0.31439551694339213, -0.1671548032045751, -0.265625921874857, 0.17020161805532313, 0.131910168702948, 0.01710210167446144, -0.25291863489826016, -0.025601419230506833, -0.1363863076909776, -0.014547852781486237, 0.026669713943087897, -0.061372253768311985, 0.22886573892884876, -0.04873879686881011, -0.0977070979206126, 0.08319756105436799, -0.014268839204408162, -0.027250891730832644, 0.13699319009890487, -0.11487791577455247, 0.022430773024499112, -0.22939334640796483, -0.055632504193871585, 0.06416371724268216, -0.0775085884899209, 0.045246761739432345, 0.031076985325881844, 0.14781237836351768, 0.02381242985583027, 0.15487613374508255, 0.10351358858404662, -0.25590527248008577, 0.06319237458932717, -0.1501794261330112, -0.10614371462506668, -0.11216739410245766, -0.2255446583749792, -0.10668505068638057, -0.16337576063917159, 0.019753604078404277, -0.01659241930951315, -0.1490255668700337, -0.15300186696307777, -0.23161357245514674, -0.19012371104511566, -0.024722612692905085, 0.018800081325784944, -0.08784753264231976], [0.07770746470948717, -0.045369431541529046, 0.06728202925493726, -0.3198383816392729, 0.25719020406947457, 0.12686516621046046, 0.028067751890462955, -0.029285548934785133, -0.09141535039271054, 0.03685597984923565, 0.3606197351735312, 0.24803545825141066, -0.1427855519983033, 0.0576487425070302, 0.06226580707002516, -0.08942476918568526, -0.06777718553804325, -0.04174882832472112, 0.204030408542657, -0.07752460433570615, -0.06544765127768123, -0.0031617166088247772, -0.03717062792452765, -0.09398176837190891, 0.2965381517125462, 0.12140680545927066, -0.07068459608709238, 0.22851868427707248, -0.03264451122579427, 0.03133550223218641, -0.13249056471979667, -0.0435819511775001, -0.1055758335233431, -0.15152824011979077, 0.16119614729805232, 0.03247294812197321, 0.030315082868449424, 0.11120058549261277, 0.12252449115677365, 0.09134265808494818, -0.18507407281962382, 0.09819100151260823, 0.13269656778238162, -0.16301814575842047, -0.007919744477131594, 0.29310467552085495, -0.03733960403818229, -0.10560398801079787, -0.08858792421397543, -0.1490596423684626], [0.053806568453823554, 0.08362222274090478, 0.1648224870995771, 0.16181176140356263, 0.06728632226512721, -0.06226288573856695, 0.06298481212742835, 0.06618986813820033, -0.41749350213556097, 0.08748470605631575, 0.10139300261386631, -0.25751402569744464, -0.08689549825954565, 0.022185584062385633, -0.2611097540129942, -0.20387993477674693, 0.1045187126930425, 0.19525113613482373, -0.06548007600443738, -0.03379928401146619, -0.03390013209900929, -0.2128548438526379, -0.15006648288722868, -0.028822414175204203, 0.011750465506576352, -0.21265715993429413, -0.10320174288358339, 0.08573230781454184, -0.09871619672985302, -0.14155625706492042, 0.18011996534267943, 0.19965327392821458, 0.00017739731855935525, -0.1981570675404539, 0.017718610225369746, 0.1056945650762536, 0.12213485819922844, -0.09909568483774632, -0.026824765676831175, -0.09334497857470844, -0.11029867999810444, 0.0628829504455583, -0.017857423021912414, 0.2252182745534096, 0.21549111179492403, 0.0525080763434988, -0.03793854788737894, 0.08484896008846464, -0.04461035986175865, -0.20502214208751818], [0.004913263622348716, -0.1500048115344444, 0.010941566641141733, -0.006503065080696492, -0.03646599685954087, -0.2752633600528233, 0.07531189977711053, -0.186512632541453, 0.021007902110117535, 0.16112541473197167, -0.04841613781179765, 0.23408998578861323, 0.09681896413801473, 0.12872774287572605, 0.1276814626075751, -0.03457757399565836, 0.016234329961920667, -0.10707556496958233, -0.23504034206011712, 0.12226647194061646, 0.01825675301454964, -0.20829776914584525, -0.11037128833275009, -0.17091401161483868, 0.07037816569895944, 0.003427455543839872, 0.19921147449936016, 0.14528510293298996, -0.1033228710596329, 0.1251073357994028, -0.07571196893211003, 0.0017717173901348991, 0.039543587676568355, 0.009413496415163203, -0.1839173885518337, 0.04848000034217097, 0.25241351702208603, -0.1511744221332645, -0.0054520291127572035, -0.29247588247563916, -0.07284883747894524, 0.07099955720620905, 0.1806478062568435, 0.22513799668971868, -0.11357813501007799, 0.01125506857293887, 0.2800376153976041, -0.23771677250499557, -0.1030924523023112, 0.07542374253447771], [0.08230893773245257, -0.03364010400429061, 0.1289159017339716, 0.04492094706270051, 0.05630604528539849, -0.16967005989502032, 0.09938660914290902, -0.06307040357417244, -0.08239297834825883, 0.0714384060560099, 0.0270478325307996, -0.14116179107360768, 0.10296745904787837, -0.09840602264246659, -0.0771428020068989, 0.3240416507931094, -0.23894010303188787, -0.24618090743929488, -0.05807754516360821, -0.3864985770906254, 0.2071193086095488, -0.06719870522596172, 0.08940278060279389, 0.08058974684922758, -0.06650634149361118, 0.23521905321975317, 0.06519444772021954, -0.009792376971895833, 0.12534100222036906, 0.08371417736099768, 0.06769016305204334, -0.19894172114313025, -0.009494922441099563, -0.3256809173556932, 0.22225158140258186, 0.024104403743777675, -0.009725733725220898, -0.014232261612398378, 0.1054492483018511, -0.11669611455704978, 0.07993250459730453, -0.1538622674618979, 0.10823346239296149, 0.04064035447541983, 0.09952784116827287, -0.014799701170333475, 0.16725506217373828, 0.08372948209093939, 0.13819320746104385, -0.10824882414844579], [0.06409907213504876, -0.27651190269993786, 0.28734816628734844, 0.03251581556507095, -0.1517029737951125, -0.09779171870678215, 0.08292516540799677, 0.06397309270935364, 0.036515808299502545, -0.03086097596004797, -0.1203661098252284, -0.10207759350408159, -0.16636351444105302, -0.03875459642862787, 0.007655099179995212, -0.01707523643761284, -0.1628910021500449, 0.08160234768381575, 0.12058283972072721, -0.2525171993297292, -0.15687052772136587, 0.01899310843092014, -0.09385787566854946, -0.042889465000899366, 0.10806921638996964, 0.047877439688789686, -0.06221570981883341, -0.027467675900886966, 0.04495213700057303, 0.14051330361907105, 0.08177010585764748, 0.08722959179371734, 0.3432880984536605, 0.14856075650138378, -0.16689558578383326, -0.24980207120702416, 0.00024034860384292145, 0.32351526668367425, 0.18682469577577576, -0.0940649890357236, 0.03212799827540022, 0.07116162306303457, -0.257897861293538, 0.03816801834322281, -0.13126857948278944, 0.07690833371169101, 0.06530720801101161, -0.0570714453934372, -0.1789260897696779, -0.13576483706279402], [0.09037126758148965, 0.09119704335872597, 0.10789793382103002, -0.039230432504323204, 0.27407365422162155, -0.00412387578163978, -0.0563838380638951, -0.15226504611708297, 0.19707248266864155, -0.010636997187505187, -0.2092597535755269, 0.05889534672859739, -0.10207566859655849, -0.21285260311798504, 0.0033909397249001494, -0.08265568255691924, 0.08692223952834444, -0.028333712467601357, 0.15055393525033028, 0.07774676183723908, -0.12929299679761175, -0.3258054545023724, -0.10001886293501032, -0.2881671879484038, 0.021976541924270645, -0.04735993765049107, 0.12937102208355475, -0.16240444515532348, 0.035065557943022685, 0.022394191353501278, -0.10195227584060522, -0.22075216373059828, 0.05396431916668994, -0.21236740916683308, -0.12446757603492667, -0.1283121526784004, -0.08695390064496858, 0.11472055823667004, 0.030585007752943913, -0.10783269682125823, -0.0011699896669256082, 0.23256541470127026, 0.0016134292628278146, 0.012531773856068207, 0.2002873147203455, -0.12270292378208157, -0.13319444031226546, 0.2577963677685876, 0.21645547786797847, 0.08161428334688223], [0.008967584233891976, 0.031205207742628287, 0.1077428865229066, 0.10541980901109062, -0.14016169470614176, -0.047554918008307454, -0.15512532099627782, -0.11466786759520675, 0.07648252125041459, -0.4218933789328297, 0.08544143460345163, 0.22868567553597607, -0.028025312146454626, -0.16278770029784226, -0.06492360326967024, -0.13158733609370063, 0.24833264725337553, -0.04496141239379028, 0.026953453258341413, -0.24617823015860557, 0.27504059049026647, -0.10805522557434022, -0.17122568972980642, 0.12736097997008994, -0.1916217274620304, 0.08201146099563722, 0.10329652519269729, 0.19861347921103426, -0.1825560974100458, -0.013963730507886126, 0.05646837231404665, -0.10756911357764495, -0.00990965916183863, -0.01721364429452904, -0.0028272186068965255, 0.012514696207229753, 0.13639225798606963, -0.11049838206000503, 0.1399434508506163, 0.048294466921703305, -0.03699431680187171, 0.054352092202875346, -0.1914358869805144, -0.07235176925302644, -0.06841664162292488, -0.12163876995136998, -0.22003422317776802, -0.21081681398058222, 0.04613379302160947, -0.10565800541065563], [0.16359738267634963, -0.12217631347015964, -0.017813919547795966, -0.14735746188496524, 0.05078062295173036, 0.10535275010199688, 0.06092324449762754, -0.09832626888564971, 0.12143122499247799, -0.02033461080953372, -0.0715234536360558, 0.01629415566977349, 0.2076452543394931, -0.024862357145693348, 0.027147422394777562, -0.2653595700087872, -0.09822208215306019, -0.03786962525231456, -0.045810705063422746, -0.03180061502060941, 0.059195740012014775, 0.12048193973702107, 0.06396954463988865, -0.09194091568680399, -0.15097086509401778, -0.2569836873355068, -0.38629982362768234, -0.024903379338356957, -0.1089339101897355, -0.04881426331604133, 0.23297270742835158, -0.11798910662148586, 0.0010656586154198788, -0.08459743583827847, 0.010169309773463642, 0.02299338630109568, 0.36319307214712737, -0.023102918590244877, 0.2803431448334968, 0.16747987655615676, -0.023092017706480644, 0.015948428147184168, -0.028153163669759666, -0.03534756105508145, -0.13326666106955587, -0.011415274137228412, 0.2526605939255249, 0.22997424645572923, 0.09855046711203583, 0.11779331321268849], [0.09896997593458724, -0.09375875893209867, -0.2143179344528497, -0.3518705375731821, 0.1492604392570032, -0.1365612050032235, -0.1392359298198255, -0.02054168012947305, 0.08020434061094618, 0.21815863876477937, -0.04166150400935875, 0.07691862785914418, -0.10608720282347064, -0.07602920180863937, -0.28174728190136494, -0.03925691055342018, -0.04912642197492609, 0.19927828393485647, -0.06481216742797884, 0.08853857033501228, -0.005733029810855883, -0.020600584879509956, -0.16797637693450712, 0.28682266113684807, -0.05862707891906589, 0.13318761499499177, -0.01751696052241475, -0.047793258309449055, 0.038600947324361534, 0.03586410867876466, 0.060399234389267115, -0.11632756328200416, -0.1087858271201177, -0.11105349104957474, -0.05126056447276259, -0.13729157221897553, -0.12346668810852923, -0.17178631059070526, 0.1763428615510613, -0.042950802184439626, -0.02751797127877975, -0.23763151388992412, -0.1827371418934452, 0.21298002565110108, -0.1057434043604002, -0.06570655688402596, -0.13010305129937239, 0.0606806533608788, -0.288989302280944, 0.05938133876930643], [0.0015375279092461193, -0.13626586234237298, 0.05888475962984989, -0.029750368411013705, -0.20214781787476577, 0.0062262785213829585, -0.03029960462117103, 0.13383951134803615, 0.0028233009115596532, -0.18358946282635683, -0.12276598599551673, 0.015046357379125798, 0.0431418112342723, 0.07437689713658727, -0.10208156068153834, -0.06744208599866056, 0.12798200497641507, -0.0084814020581419, 0.2797054837473293, 0.18512288011403438, 0.061165747893800554, -0.1448990547170172, -0.12695111063011066, 0.31643935363638426, 0.18552215466467056, -0.06834447243683639, 0.0947549020831614, -0.03065581218858964, 0.26724016686279095, 0.2912182014754867, 0.023776295105383215, -0.05555452353599723, -0.12117595435421046, 0.007520956885670449, 0.007311905656807553, -0.045669888019884045, 0.29047777489144777, -0.015502642938113792, -0.16482569514285603, -0.11994336426545063, -0.13488181215590142, -0.19152028440236052, 0.11584144177344892, -0.17884930717568895, 0.029346865655496657, 0.13022401982127774, 0.12100026106645125, 0.2845144349726079, 0.0643283014198893, -0.07914122578931587], [0.036530041503067136, 0.009386506553448457, 0.1134319679351552, -0.01605752906975275, 0.04314131418336476, 0.15467740111104583, 0.17731898851032707, -0.35154731137599693, -0.16647511704802836, 0.09790112485844826, -0.10391095338685993, 0.13183436986792188, 0.29783356413066436, 0.02880566314879094, -0.09333359476130981, 0.0263179230509028, 0.043763558144940214, -0.09094509963911032, 0.2839816280111131, 0.15414574647519416, 0.004452322259311109, -0.047317904903234745, -0.2084936039130389, 0.08411479014546988, -0.06029493205651815, 0.20003497456028588, -0.0785508288727359, 0.025632484676264708, -0.22199450355439887, -0.0872981929058313, -0.04255438999947184, 0.30626972072124925, 0.0908409256409519, 0.1444124373541768, -0.02387492817880099, -0.2079399615555052, -0.16262453641895358, -0.05913683807095221, 0.11026509532736811, 0.02988440532453661, 0.09504495548832113, -0.24770231640840723, -0.024632026610730717, -0.08547797355410938, 0.20390260414614625, -0.021135864596146914, 0.12708178910891174, -0.033369143609006495, 0.1273782390251239, -0.010505943329781942], [-0.13458807472070056, -0.1341078501458928, 0.13468677674597063, -0.12373786877487644, -0.06411966796393362, 0.10101939988989579, -0.12281403012457269, -0.058525917697690444, -0.21409975183493973, 0.20409831517062993, 0.11350040598024874, 0.1553929969006707, 0.0033147055303953676, -0.1086317888175467, -0.04457864354498725, 0.04584203447485323, 0.10616152932980943, 0.23135713845182151, -0.2666733269934465, 0.07703081286520776, 0.14769626642676906, 0.03588959100472541, -0.13140303909809212, -0.12199077153770146, -0.17448789692866398, -0.03295765071001448, 0.20830703380819454, -0.007234297263865264, -0.0033843960617247065, 0.12325850404383129, 0.001892220099548425, -0.17345165443146865, 0.2669377396980172, 0.21871840121198527, 0.1359679963646404, 0.13928487397370226, -0.16109771229947073, -0.028709862603611677, 0.022741106492625104, 0.06952130034803351, 0.10234823916150523, 0.09981581175079615, 0.023821821607085802, -0.20622480583917402, -0.08605688340959129, 0.06543020619937348, 0.12596840352433986, 0.3445829016103341, 0.030387139041877995, -0.1999412110059843], [-0.18068596147754287, 0.13233557743143118, 0.10162723923839788, 0.0018223533080417714, 0.07959994626495569, -0.09412331138641611, -0.09287082452399656, -0.1347487662596299, 0.03313612053197462, 0.14111064062190073, -0.04266006905677004, 0.16878162711022057, -0.03104002510808715, -0.14708324899490866, 0.06561218863821403, -0.15203606496902553, -0.3637427520348711, 0.14395976830418344, 0.19609912618450154, -0.13331840451684646, 0.1675809838787529, -0.10452348772184145, -0.01945674944425657, 0.025656553103592605, -0.050353873793299954, -0.035329510282683926, 0.13119222765899421, -0.0757971181947967, 0.07222261287141503, -0.25085551770362097, -0.009582380868694007, 0.1336922020598731, 0.2214624805830962, -0.09959757496648151, -0.027753018667987045, 0.08884412958098911, 0.23779740343974035, 0.07938737050478821, -0.4006451728403552, 0.2257320824329932, 0.014666382817961676, -0.21719899177849664, 0.04348874698685783, -0.0234642420557358, -0.13662278469901365, 0.008892757881412389, -0.034064085211419654, 0.013627818468067016, -0.12429681821915782, 0.08195010959694078], [-0.2222401376479631, -0.10740470827313575, -0.01363998594716409, -0.21898014642909916, 0.04175968706459762, -0.07797966038903238, -0.1551884078078946, -0.23675801003679103, 0.030001761414648165, -0.3321502591927965, 0.0180618468617367, 0.06764244241330734, 0.1528292891858752, -0.023004585548586295, 0.03862004404013825, 0.19844287821460366, -0.0599152109694055, -0.07247235176183281, -0.04495247724602801, -0.0784643072378911, 0.11476101767641744, 0.12880622640099873, -0.1425321128228287, 0.04734782038846069, 0.07918593469918844, -0.33523553952530116, -0.2443640517805782, -0.1335409422540742, -0.0372534700104296, -0.014152756127677732, 0.0001943670377682477, 0.1201560779945897, -0.028368395074023042, -0.060265444109619704, -0.16680615219066725, 0.07399769522363478, -0.29179362732473196, 0.12028130912561028, -0.14169815211583534, -0.1384475929456198, -0.13565968497110856, 0.01795359451865954, 0.15121339410954868, 0.23184620131691397, -0.015175130673858561, 0.022199547608373338, -0.028514778306583707, 0.08111219798668563, -0.011420097436395535, -0.24564729132738422], [0.1778584048269541, 0.08610756976162393, -0.30996323831525224, -0.053211281347095754, -0.06891909365278423, 0.15516528066647198, 0.10114649091675176, -0.009622620681641235, 0.17076509049913688, -0.21710007380797045, 0.03407768995053067, -0.006647356433170687, -0.10435899556140465, 0.30673554528764824, -0.12472293194842077, 0.24020986397451496, -0.12385470192341119, -0.06404191766117945, 0.06863654517965487, 0.01570387912290336, 0.0012693900777371037, -0.28197900690803746, -0.031163508191544342, -0.11170301077183825, -0.06365382490119254, 0.026747881353997416, -0.014275305963363877, 0.07691204822671041, -0.1901062641653967, -0.049137504143707184, 0.05622688547693941, -0.18254222537259301, 0.26033625840064906, 0.1091070106585361, -0.07345670581676668, 0.13233334328886362, 0.09967194684212084, -0.03146176188087071, -0.1043067051208771, 0.09281991856637775, 0.2413182293491916, -0.04838566472905562, -0.008381051314389543, 0.11872323426050574, 0.15555358765945448, 0.17970562420756594, -0.02045547491142524, 0.15400362212488544, -0.2174130383729316, -0.16802395880790844], [-0.055477840593350515, 0.18427816591446924, 0.10056836901472449, 0.030510912248161423, -0.07978827993311902, 0.06001815248828921, 0.12633220043925422, 0.0646559262556873, 0.006452950059301568, 0.09692242479367062, -0.05994134223292319, 0.15809914630767846, 0.09283405635367627, 0.19733593439628117, 0.32088049772255844, 0.15008440137366447, 0.06680757245712947, 0.22405226306470363, -0.09276036765817813, -0.06583401224188916, 0.04654549175624459, -0.06897788678212631, -0.05190549903625293, -0.06754398482625792, 0.05130010144411555, 0.04362892105143813, 0.05355629034667863, -0.4643583862147458, -0.1880018429830603, -0.11216973721193826, 0.06994226238904619, -0.18524871992334108, -0.24252034587680052, 0.028435475842423973, 0.1083194332401928, -0.18834473097292365, 0.1403470312190173, 0.05869391461731399, 0.07091580532468406, 0.015182970228984072, -0.23493395649498477, -0.14713270440746873, -0.16694658531774836, 0.09629160029433492, 0.013798342494534668, 0.09673464581641793, -0.0661667934253251, -0.008164699822116234, -0.005503469313214812, -0.23568105213343904]])
    explained_variance = np.array([1.6840839350106587, 1.5949452510250695, 1.5217657864137302, 1.5109947544608267, 1.4611667289678585, 1.425216973539068, 1.4046272764589405, 1.3953335686556878, 1.3571098118054599, 1.3069054692544653, 1.2900144271174654, 1.2682897945951843, 1.2210255896045983, 1.2096258841240581, 1.200326654575995, 1.1888826271045263, 1.1594675252968674, 1.1257337629134172, 1.0991319977954963, 1.0485543438362097, 1.0403389595401358, 1.0364236890829, 1.0017002048259027, 0.9809699624304604, 0.9514296395650804, 0.9359325708417605, 0.9123634521861045, 0.8946182903889047, 0.8766099217890858, 0.871801714546886, 0.8489534686476239, 0.8215516418848974, 0.8176981564186311, 0.7894477772338157, 0.7784917451883332, 0.7643392274542491, 0.7467412123928027, 0.7172676046487401, 0.7099569756332398, 0.6928025014246777, 0.6698982036627203, 0.6620323439690838, 0.6438659224534609])
    X = X - mean
    X_transformed = np.dot(X, components.T)
    return X_transformed


def __convert(cell):
    value = str(cell)
    try:
        result = int(value)
        return result
    except ValueError:
        try:
            result = float(value)
            if math.isnan(result):
                raise PredictorError('NaN value found. Aborting.', code=1)
            return result
        except ValueError:
            result = (binascii.crc32(value.encode('utf8')) % (1 << 32))
            return result
        except Exception as e:
            raise e


def __get_key(val, dictionary):
    if dictionary == {}:
        return val
    for key, value in dictionary.items():
        if val == value:
            return key
    if val not in dictionary.values():
        raise PredictorError(f"Label {val} key does not exist", code=2)


def __confusion_matrix(y_true, y_pred, json):
    stats = {}
    labels = np.array(list(mapping.keys()))
    sample_weight = np.ones(y_true.shape[0], dtype=np.int64)
    for class_i in range(n_classes):
        class_i_label = __get_key(class_i, mapping)
        stats[int(class_i)] = {}
        class_i_indices = np.argwhere(y_true == class_i_label)
        not_class_i_indices = np.argwhere(y_true != class_i_label)
        # None represents N/A in this case
        stats[int(class_i)]['TP'] = TP = int(np.sum(y_pred[class_i_indices] == class_i_label)) if class_i_indices.size > 0 else None
        stats[int(class_i)]['FN'] = FN = int(np.sum(y_pred[class_i_indices] != class_i_label)) if class_i_indices.size > 0 else None
        stats[int(class_i)]['TN'] = TN = int(np.sum(y_pred[not_class_i_indices] != class_i_label)) if not_class_i_indices.size > 0 else None
        stats[int(class_i)]['FP'] = FP = int(np.sum(y_pred[not_class_i_indices] == class_i_label)) if not_class_i_indices.size > 0 else None
        if TP is None or FN is None or (TP + FN == 0):
            stats[int(class_i)]['TPR'] = None
        else:
            stats[int(class_i)]['TPR'] = (TP / (TP + FN))
        if TN is None or FP is None or (TN + FP == 0):
            stats[int(class_i)]['TNR'] = None
        else:
            stats[int(class_i)]['TNR'] = (TN / (TN + FP))
        if TP is None or FP is None or (TP + FP == 0):
            stats[int(class_i)]['PPV'] = None
        else:
            stats[int(class_i)]['PPV'] = (TP / (TP + FP))
        if TN is None or FN is None or (TN + FN == 0):
            stats[int(class_i)]['NPV'] = None
        else:
            stats[int(class_i)]['NPV'] = (TN / (TN + FN))
        if TP is None or FP is None or FN is None or (TP + FP + FN == 0):
            stats[int(class_i)]['F1'] = None
        else:
            stats[int(class_i)]['F1'] = ((2 * TP) / (2 * TP + FP + FN))
        if TP is None or FP is None or FN is None or (TP + FP + FN == 0):
            stats[int(class_i)]['TS'] = None
        else:
            stats[int(class_i)]['TS'] = (TP / (TP + FP + FN))

    if not report_cmat:
        return np.array([]), stats

    label_to_ind = {label: i for i, label in enumerate(labels)}
    y_pred = np.array([label_to_ind.get(x, n_classes + 1) for x in y_pred])
    y_true = np.array([label_to_ind.get(x, n_classes + 1) for x in y_true])

    ind = np.logical_and(y_pred < n_classes, y_true < n_classes)
    y_pred = y_pred[ind]
    y_true = y_true[ind]
    sample_weight = sample_weight[ind]

    cm = coo_matrix((sample_weight, (y_true, y_pred)), shape=(n_classes, n_classes), dtype=np.int64).toarray()
    with np.errstate(all='ignore'):
        cm = np.nan_to_num(cm)

    return cm, stats


def __preprocess_and_clean_in_memory(arr):
    clean_arr = np.zeros((len(arr), len(important_idxs)))
    for i, row in enumerate(arr):
        try:
            row_used_cols_only = [row[i] for i in important_idxs]
        except IndexError:
            error_str = f"The input has shape ({len(arr)}, {len(row)}) but the expected shape is (*, {len(ignorecolumns) + len(important_idxs)})."
            if len(arr) == num_attr and len(arr[0]) != num_attr:
                error_str += "\n\nNote: You may have passed an input directly to 'preprocess_and_clean_in_memory' or 'predict_in_memory' "
                error_str += "rather than as an element of a list. Make sure that even single instances "
                error_str += "are enclosed in a list. Example: predict_in_memory(0) is invalid but "
                error_str += "predict_in_memory([0]) is valid."
            raise PredictorError(error_str, 3)
        clean_arr[i] = [float(__convert(field)) for field in row_used_cols_only]
    return clean_arr


def __classify(arr, return_probabilities=False):
    h = np.dot(arr, w_h.T) + b_h
    relu = np.maximum(h, np.zeros_like(h))
    out = np.dot(relu, w_o.T) + b_o
    if return_probabilities:
        exp_o = np.zeros((out.shape[0],))
        idxs_negative = np.argwhere(out < 0.).reshape(-1)
        if idxs_negative.shape[0] > 0:
            exp_o[idxs_negative] = 1. - 1. / (1. + np.exp(out[idxs_negative])).reshape(-1)
        idxs_positive = np.argwhere(out >= 0.).reshape(-1)
        if idxs_positive.shape[0] > 0:
            exp_o[idxs_positive] = 1. / (1. + np.exp(-out[idxs_positive])).reshape(-1)
        exp_o = exp_o.reshape(-1, 1)
        output = np.concatenate((1. - exp_o, exp_o), axis=1)
    else:
        output = (out >= 0).astype('int').reshape(-1)
    return output



def __validate_kwargs(kwargs):
    for key in kwargs:

        if key not in ['return_probabilities']:
            raise PredictorError(f'{key} is not a keyword argument for Brainome\'s {classifier_type} predictor. Please see the documentation.', 4)


def __validate_data(row_or_arr, validate, row_num=None):
    if validate:
        expected_columns = len(important_idxs) + len(ignore_idxs) + 1
    else:
        expected_columns = len(important_idxs) + len(ignore_idxs)

    input_is_array = isinstance(row_or_arr, np.ndarray)
    n_cols = row_or_arr.shape[1] if input_is_array else len(row_or_arr)

    if n_cols != expected_columns:

        if row_num is None:
            err_str = f"Your data contains {n_cols} columns but {expected_columns} are required."
        else:
            err_str = f"At row {row_num}, your data contains {n_cols} columns but {expected_columns} are required."

        if validate:
            err_str += " The predictor's validate() method works on data that has the same columns in the same order as were present in the training CSV."
            err_str += " This includes the target column and features that are not used by the model but existed in the training CSV."
            if n_cols == 1 + len(important_idxs):
                err_str += f" We suggest confirming that the {len(ignore_idxs)} unused features are present in the data."
            elif n_cols == len(important_idxs):
                err_str += f" We suggest confirming that the {len(ignore_idxs)} unused features are present in the data as well as the target column. "
            elif n_cols == len(important_idxs) + len(ignore_idxs):
                err_str += " We suggest confirming that the target column present in the data. "
            err_str += " To make predictions, see the predictor's predict() method."
        else:
            err_str += " The predictor's predict() method works on data that has the same feature columns in the same relative order as were present in the training CSV."
            err_str += " This DOES NOT include the target column but DOES include features that are not used by the model but existed in the training CSV."
            if n_cols == 1 + len(important_idxs):
                err_str += f" We suggest confirming that the {len(ignore_idxs)} unused features are present in the data and that the target column is not present."
            elif n_cols == len(important_idxs):
                err_str += f" We suggest confirming that the {len(ignore_idxs)} unused features are present in the data."
            elif n_cols == 1 + len(important_idxs) + len(ignore_idxs):
                err_str += " We suggest confirming that the target column is not present."
            err_str += " To receive a performance summary, instead of make predictions, see the predictor's validate() method."

        raise PredictorError(err_str, 5)

    else:

        if not input_is_array:
            return row_or_arr


def __write_predictions(arr, header, headerless, trim, outfile=None):
    predictions = predict(arr)

    if not headerless:
        if trim:
            header = ','.join([x for i, x in enumerate(header) if i in important_idxs] + ['Prediction'])
        else:
            header = ','.join(header.tolist() + ['Prediction'])
        if outfile is None:
            print(header)
        else:
            print(header, file=outfile)

    for row, prediction in zip(arr, predictions):
        if trim:
            row = ['"' + field + '"' if ',' in field else field for i, field in enumerate(row) if i in important_idxs]
        else:
            row = ['"' + field + '"' if ',' in field else field for field in row]
        row.append(prediction)
        if outfile is None:
            print(','.join(row))
        else:
            print(','.join(row), file=outfile)


def load_data(csvfile, headerless, validate):
    """
    Parameters
    ----------
    csvfile : str
        The path to the CSV file containing the data.

    headerless : bool
        True if the CSV does not contain a header.

    validate : bool
        True if the data should be loaded to be used by the predictor's validate() method.
        False if the data should be loaded to be used by the predictor's predict() method.

    Returns
    -------
    arr : np.ndarray
        The data (observations and labels) found in the CSV without any header.

    data : np.ndarray or NoneType
        None if validate is False, otherwise the observations (data without the labels) found in the CSV.

    labels : np.ndarray or NoneType
        None if the validate is False, otherwise the labels found in the CSV.

    header : np.ndarray or NoneType
        None if the CSV is headerless, otherwise the header.
    """

    with open(csvfile, 'r', encoding='utf-8') as csvinput:
        arr = np.array([__validate_data(row, validate, row_num=i) for i, row in enumerate(csv.reader(csvinput)) if row != []], dtype=str)
    if headerless:
        header = None
    else:
        header = arr[0]
        arr = arr[1:]
    if validate:
        labels = arr[:, target_column]
        feature_columns = [i for i in range(arr.shape[1]) if i != target_column]
        data = arr[:, feature_columns]
    else:
        data, labels = None, None

    if validate and ignorelabels != []:
        idxs_to_keep = np.argwhere(np.logical_not(np.isin(labels, ignorelabels))).reshape(-1)
        labels = labels[idxs_to_keep]
        data = data[idxs_to_keep]

    return arr, data, labels, header


def predict(arr, remap=True, **kwargs):
    """
    Parameters
    ----------
    arr : list[list]
        An array of inputs to be cleaned by 'preprocess_and_clean_in_memory'. This
        should contain all the features that were present in the training data,
        regardless of whether or not they are used by the model, with the same
        relative order as in the training data. There should be no target column.


    remap : bool
        If True and 'return_probs' is False, remaps the output to the original class
        label. If 'return_probs' is True this instead adds a header indicating which
        original class label each column of output corresponds to.

    **kwargs :
        return_probabilities : bool
            If true, return class membership probabilities instead of classifications.

    Returns
    -------
    output : np.ndarray

        A numpy array of
            1. Class predictions if 'return_probabilities' is False.
            2. Class probabilities if 'return_probabilities' is True.

    """
    if not isinstance(arr, np.ndarray) and not isinstance(arr, list):
        raise PredictorError(f'Data must be provided to \'predict\' and \'validate\' as a list or np.ndarray, but an input of type {type(arr).__name__} was found.', 6)
    if isinstance(arr, list):
        arr = np.array(arr, dtype=str)

    kwargs = kwargs or {}
    __validate_kwargs(kwargs)
    __validate_data(arr, False)
    remove_bad_chars = lambda x: str(x).replace('"', '').replace(',', '').replace('(', '').replace(')', '').replace("'", '')
    arr = [[remove_bad_chars(field) for field in row] for row in arr]
    arr = __preprocess_and_clean_in_memory(arr)

    arr = __transform(arr)

    output = __classify(arr, **kwargs)

    if remap:
        if kwargs.get('return_probabilities'):
            header = np.array([__get_key(i, mapping) for i in range(output.shape[1])], dtype=str).reshape(1, -1)
            output = np.concatenate((header, output), axis=0)
        else:
            output = np.array([__get_key(prediction, mapping) for prediction in output])

    return output


def validate(arr, labels):
    """
    Parameters
    ----------
    cleanarr : np.ndarray
        An array of float values that has undergone each pre-
        prediction step.

    Returns
    -------
    count : int
        A count of the number of instances in cleanarr.

    correct_count : int
        A count of the number of correctly classified instances in
        cleanarr.

    numeachclass : dict
        A dictionary mapping each class to its number of instances.

    outputs : np.ndarray
        The output of the predictor's '__classify' method on cleanarr.
    """
    predictions = predict(arr)
    correct_count = int(np.sum(predictions.reshape(-1) == labels.reshape(-1)))
    count = predictions.shape[0]
    
    class_0, class_1 = __get_key(0, mapping), __get_key(1, mapping)
    num_TP, num_TN, num_FP, num_FN, num_class_1, num_class_0 = 0, 0, 0, 0, 0, 0
    num_TP = int(np.sum(np.logical_and(predictions.reshape(-1) == class_1, labels.reshape(-1) == class_1)))
    num_TN = int(np.sum(np.logical_and(predictions.reshape(-1) == class_0, labels.reshape(-1) == class_0)))
    num_FN = int(np.sum(np.logical_and(predictions.reshape(-1) == class_0, labels.reshape(-1) == class_1)))
    num_FP = int(np.sum(np.logical_and(predictions.reshape(-1) == class_1, labels.reshape(-1) == class_0)))
    num_class_0 = int(np.sum(labels.reshape(-1) == class_0))
    num_class_1 = int(np.sum(labels.reshape(-1) == class_1))
    return count, correct_count, num_TP, num_TN, num_FP, num_FN, num_class_1, num_class_0, predictions


def __main():
    parser = argparse.ArgumentParser(description='Predictor trained on ' + str(TRAINFILE))
    parser.add_argument('csvfile', type=str, help='CSV file containing test set (unlabeled).')
    parser.add_argument('-validate', action='store_true', help='Validation mode. csvfile must be labeled. Output is classification statistics rather than predictions.')
    parser.add_argument('-headerless', help='Do not treat the first line of csvfile as a header.', action='store_true')
    parser.add_argument('-json', action="store_true", default=False, help="report measurements as json")
    parser.add_argument('-trim', action="store_true", help="If true, the prediction will not output ignored columns.")
    args = parser.parse_args()
    faulthandler.enable()

    arr, data, labels, header = load_data(csvfile=args.csvfile, headerless=args.headerless, validate=args.validate)

    if not args.validate:
        __write_predictions(arr, header, args.headerless, args.trim)
    else:

        count, correct_count, num_TP, num_TN, num_FP, num_FN, num_class_1, num_class_0, preds = validate(data, labels)

        classcounts = np.bincount(np.array([mapping[label] for label in labels], dtype='int32')).reshape(-1)
        class_balance = (classcounts[np.argwhere(classcounts > 0)] / arr.shape[0]).reshape(-1).tolist()
        best_guess = round(100.0 * np.max(class_balance), 2)
        H = float(-1.0 * sum([class_balance[i] * math.log(class_balance[i]) / math.log(2) for i in range(len(class_balance))]))
        modelacc = int(float(correct_count * 10000) / count) / 100.0
        mtrx, stats = __confusion_matrix(np.array(labels).reshape(-1), np.array(preds).reshape(-1), args.json)

        if args.json:
            json_dict = {'instance_count': count,
                         'classifier_type': classifier_type,
                         'classes': n_classes,
                         'number_correct': correct_count,
                         'accuracy': {
                             'best_guess': (best_guess/100),
                             'improvement': (modelacc - best_guess)/100,
                              'model_accuracy': (modelacc/100),
                         },
                         'model_capacity': model_cap,
                         'generalization_ratio': int(float(correct_count * 100) / model_cap) / 100.0 * H,
                         'model_efficiency': int(100 * (modelacc - best_guess) / model_cap) / 100.0,
                         'shannon_entropy_of_labels': H,
                         'class_balance': class_balance,
                         'confusion_matrix': mtrx.tolist(),
                         'multiclass_stats': stats}

            print(json.dumps(json_dict))
        else:
            pad = lambda s, length, pad_right: str(s) + ' ' * max(0, length - len(str(s))) if pad_right else ' ' * max(0, length - len(str(s))) + str(s)
            labels = np.array(list(mapping.keys())).reshape(-1, 1)
            max_class_name_len = max([len(clss) for clss in mapping.keys()] + [7])

            max_TP_len = max([len(str(stats[key]['TP'])) for key in stats.keys()] + [2])
            max_FP_len = max([len(str(stats[key]['FP'])) for key in stats.keys()] + [2])
            max_TN_len = max([len(str(stats[key]['TN'])) for key in stats.keys()] + [2])
            max_FN_len = max([len(str(stats[key]['FN'])) for key in stats.keys()] + [2])

            cmat_template_1 = "    {} | {}"
            cmat_template_2 = "    {} | " + " {} " * n_classes
            acc_by_class_template_1 = "    {} | {}  {}  {}  {}  {}  {}  {}  {}  {}  {}"

            acc_by_class_lengths = [max_class_name_len, max_TP_len, max_FP_len, max_TN_len, max_FN_len, 7, 7, 7, 7, 7, 7]
            acc_by_class_header_fields = ['target', 'TP', 'FP', 'TN', 'FN', 'TPR', 'TNR', 'PPV', 'NPV', 'F1', 'TS']
            print("Classifier Type:                    Neural Network")

            print(f"System Type:                        {n_classes}-way classifier\n")

            print("Accuracy:")
            print("    Best-guess accuracy:            {:.2f}%".format(best_guess))
            print("    Model accuracy:                 {:.2f}%".format(modelacc) + " (" + str(int(correct_count)) + "/" + str(count) + " correct)")
            print("    Improvement over best guess:    {:.2f}%".format(modelacc - best_guess) + " (of possible " + str(round(100 - best_guess, 2)) + "%)\n")

            print("Model capacity (MEC):               {:.0f} bits".format(model_cap))
            print("Generalization ratio:               {:.2f}".format(int(float(correct_count * 100) / model_cap) / 100.0 * H) + " bits/bit")

            if report_cmat:
                max_cmat_entry_len = len(str(int(np.max(mtrx))))
                mtrx = np.concatenate((labels, mtrx.astype('str')), axis=1).astype('str')
                max_pred_len = (mtrx.shape[1] - 1) * max_cmat_entry_len + n_classes * 2 - 1
                print("\nConfusion Matrix:\n")
                print(cmat_template_1.format(pad("Actual", max_class_name_len, False), "Predicted"))
                print(cmat_template_1.format("-" * max_class_name_len, "-" * max(max_pred_len, 9)))
                for row in mtrx:
                    print(cmat_template_2.format(
                        *[pad(field, max_class_name_len if i == 0 else max_cmat_entry_len, False) for i, field in enumerate(row)]))

            print("\nAccuracy by Class:\n")
            print(acc_by_class_template_1.format(
                *[pad(header_field, length, False) for i, (header_field, length) in enumerate(zip(acc_by_class_header_fields, acc_by_class_lengths))]))
            print(acc_by_class_template_1.format(
                *["-" * length for length in acc_by_class_lengths]))

            pct_format_string = "{:8.2%}"      # width = 8, decimals = 2
            for raw_class in mapping.keys():
                class_stats = stats[int(mapping[raw_class])]
                TP, FP, TN, FN = class_stats.get('TP', None), class_stats.get('FP', None), class_stats.get('TN', None), class_stats.get('FN', None)
                TPR = pct_format_string.format(class_stats['TPR']) if class_stats['TPR'] is not None else 'N/A'
                TNR = pct_format_string.format(class_stats['TNR']) if class_stats['TNR'] is not None else 'N/A'
                PPV = pct_format_string.format(class_stats['PPV']) if class_stats['PPV'] is not None else 'N/A'
                NPV = pct_format_string.format(class_stats['NPV']) if class_stats['NPV'] is not None else 'N/A'
                F1 = pct_format_string.format(class_stats['F1']) if class_stats['F1'] is not None else 'N/A'
                TS = pct_format_string.format(class_stats['TS']) if class_stats['TS'] is not None else 'N/A'
                line_fields = [raw_class, TP, FP, TN, FN, TPR, TNR, PPV, NPV, F1, TS]
                print(acc_by_class_template_1.format(
                    *[pad(field, length, False) for i, (field, length) in enumerate(zip(line_fields, acc_by_class_lengths))]))


if __name__ == "__main__":
    try:
        __main()
    except PredictorError as e:
        print(e, file=sys.stderr)
        sys.exit(e.code)
    except Exception as e:
        print(f"An unknown exception of type {type(e).__name__} occurred.", file=sys.stderr)
        sys.exit(-1)
