#!/usr/bin/env python3
#
# This code has been produced by an enterprise version of Brainome(tm) licensed to: andy Stevko.
# Portions of this code copyright (c) 2019-2022 by Brainome, Inc. All Rights Reserved.
# Distribution and use of this code or commercial use is permitted within the license terms
# set forth in a written contractual agreement between Brainome, Inc and brainome-user.
# Please contact support@brainome.ai with any questions.
# Use of predictions results at your own risk.
#
# Output of Brainome v1.8-120-prod.
# Invocation: brainome TRAIN_TEST_SPLITS/speeddating-clean-train.csv -f NN -y -split 70 -modelonly -q -o btc-runs/NN/SpeedDating.py -json btc-runs/NN/SpeedDating.json
# Total compiler execution time: 0:01:13.37. Finished on: Feb-26-2022 18:58:11.
# This source code requires Python 3.
#
"""

[01;1mPredictor:[0m                        btc-runs/NN/SpeedDating.py
    Classifier Type:              Neural Network
    System Type:                  Binary classifier
    Training / Validation Split:  70% : 30%
    Accuracy:
      Best-guess accuracy:        83.53%
      Training accuracy:          85.57% (3512/4104 correct)
      Validation Accuracy:        84.65% (1490/1760 correct)
      Combined Model Accuracy:    85.30% (5002/5864 correct)


    Model Capacity (MEC):        111    bits
    Generalization Ratio:         20.42 bits/bit
    Percent of Data Memorized:    11.49%
    Resilience to Noise:          -1.50 dB







    Training Confusion Matrix:
              Actual | Predicted
              ------ | ---------
                   0 |  3362    66 
                   1 |   526   150 

    Validation Confusion Matrix:
              Actual | Predicted
              ------ | ---------
                   0 |  1435    35 
                   1 |   235    55 

    Training Accuracy by Class:
               match |    TP    FP    TN    FN     TPR      TNR      PPV      NPV       F1       TS 
               ----- | ----- ----- ----- ----- -------- -------- -------- -------- -------- --------
                   0 |  3362   526   150    66   98.07%   22.19%   86.47%   69.44%   91.91%   85.03%
                   1 |   150    66  3362   526   22.19%   98.07%   69.44%   86.47%   33.63%   20.22%

    Validation Accuracy by Class:
               match |    TP    FP    TN    FN     TPR      TNR      PPV      NPV       F1       TS 
               ----- | ----- ----- ----- ----- -------- -------- -------- -------- -------- --------
                   0 |  1435   235    55    35   97.62%   18.97%   85.93%   61.11%   91.40%   84.16%
                   1 |    55    35  1435   235   18.97%   97.62%   61.11%   85.93%   28.95%   16.92%




"""

import sys
import math
import argparse
import csv
import binascii
import faulthandler
import json
try:
    import numpy as np  # For numpy see: http://numpy.org
except ImportError as e:
    print("This predictor requires the Numpy library. Please run 'python3 -m pip install numpy'.", file=sys.stderr)
    raise e
try:
    from scipy.sparse import coo_matrix
    report_cmat = True
except ImportError:
    print("Note: If you install scipy (https://www.scipy.org) this predictor generates a confusion matrix. Try 'python3 -m pip install scipy'.", file=sys.stderr)
    report_cmat = False

IOBUF = 100000000
sys.setrecursionlimit(1000000)
TRAINFILE = ['TRAIN_TEST_SPLITS/speeddating-clean-train.csv']
mapping = {'0': 0, '1': 1}
ignorelabels = []
ignorecolumns = []
list_of_cols_to_normalize = [2, 3, 4, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119]
column_mappings = [{1249151596.0: 0, 1435361449.0: 1}, {18.0: 0, 19.0: 1, 20.0: 2, 21.0: 3, 22.0: 4, 23.0: 5, 24.0: 6, 25.0: 7, 26.0: 8, 27.0: 9, 28.0: 10, 29.0: 11, 30.0: 12, 31.0: 13, 32.0: 14, 33.0: 15, 34.0: 16, 35.0: 17, 36.0: 18, 37.0: 19, 38.0: 20, 39.0: 21, 42.0: 22, 55.0: 23, 1684325040.0: 24}, {18.0: 0, 19.0: 1, 20.0: 2, 21.0: 3, 22.0: 4, 23.0: 5, 24.0: 6, 25.0: 7, 26.0: 8, 27.0: 9, 28.0: 10, 29.0: 11, 30.0: 12, 31.0: 13, 32.0: 14, 33.0: 15, 34.0: 16, 35.0: 17, 36.0: 18, 37.0: 19, 38.0: 20, 39.0: 21, 42.0: 22, 55.0: 23, 1684325040.0: 24}, {48735271.0: 0, 891460694.0: 1, 1526403006.0: 2, 2597850670.0: 3}, {32599200.0: 0, 293327590.0: 1, 412686884.0: 2, 1684325040.0: 3, 2399808559.0: 4, 4087319907.0: 5}, {32599200.0: 0, 293327590.0: 1, 412686884.0: 2, 1684325040.0: 3, 2399808559.0: 4, 4087319907.0: 5}, {0.0: 0, 1.0: 1, 2.0: 2, 3.0: 3, 4.0: 4, 5.0: 5, 6.0: 6, 7.0: 7, 8.0: 8, 9.0: 9, 10.0: 10, 1684325040.0: 11}, {1.0: 0, 2.0: 1, 3.0: 2, 4.0: 3, 5.0: 4, 6.0: 5, 7.0: 6, 8.0: 7, 9.0: 8, 10.0: 9, 1684325040.0: 10}, {1149761359.0: 0, 1421673377.0: 1, 2597850670.0: 2}, {1149761359.0: 0, 1421673377.0: 1, 2597850670.0: 2}, {15017931.0: 0, 26596220.0: 1, 44306896.0: 2, 45905266.0: 3, 47730397.0: 4, 54464509.0: 5, 70499459.0: 6, 125480160.0: 7, 148074040.0: 8, 152415091.0: 9, 152645570.0: 10, 174075239.0: 11, 185490720.0: 12, 201029600.0: 13, 202069295.0: 14, 202918097.0: 15, 225501280.0: 16, 242652078.0: 17, 307361439.0: 18, 321187713.0: 19, 376497099.0: 20, 395107967.0: 21, 416360697.0: 22, 435878292.0: 23, 450920598.0: 24, 460805064.0: 25, 462970398.0: 26, 465879842.0: 27, 476883735.0: 28, 485909208.0: 29, 497974144.0: 30, 539054596.0: 31, 547815489.0: 32, 556358680.0: 33, 567325923.0: 34, 578162972.0: 35, 579089110.0: 36, 628612686.0: 37, 647408932.0: 38, 668560958.0: 39, 677667344.0: 40, 710571969.0: 41, 723882923.0: 42, 744116156.0: 43, 763128263.0: 44, 783136072.0: 45, 792979606.0: 46, 803176885.0: 47, 814319542.0: 48, 835505082.0: 49, 877007823.0: 50, 892527186.0: 51, 912111495.0: 52, 915709135.0: 53, 917775891.0: 54, 919988817.0: 55, 953004754.0: 56, 974512775.0: 57, 988992924.0: 58, 997845351.0: 59, 1049599207.0: 60, 1131395653.0: 61, 1135887503.0: 62, 1150786304.0: 63, 1229170577.0: 64, 1230742932.0: 65, 1252826409.0: 66, 1264104144.0: 67, 1266677118.0: 68, 1277843441.0: 69, 1301941636.0: 70, 1303067116.0: 71, 1379478425.0: 72, 1383944571.0: 73, 1412059160.0: 74, 1444290179.0: 75, 1472924849.0: 76, 1479944845.0: 77, 1501617769.0: 78, 1509678193.0: 79, 1514188848.0: 80, 1519435996.0: 81, 1565826303.0: 82, 1599948065.0: 83, 1615653514.0: 84, 1684325040.0: 85, 1705184133.0: 86, 1705543801.0: 87, 1723067856.0: 88, 1732187885.0: 89, 1733942901.0: 90, 1737319721.0: 91, 1744917525.0: 92, 1822983426.0: 93, 1855372604.0: 94, 1877464402.0: 95, 1903292387.0: 96, 1906081943.0: 97, 1965550008.0: 98, 1970028622.0: 99, 1971344674.0: 100, 1990682308.0: 101, 2021470578.0: 102, 2032881756.0: 103, 2046499943.0: 104, 2052821654.0: 105, 2059410989.0: 106, 2081176863.0: 107, 2129020949.0: 108, 2137141061.0: 109, 2140965185.0: 110, 2141759096.0: 111, 2149714801.0: 112, 2179109143.0: 113, 2185543202.0: 114, 2219141848.0: 115, 2225957936.0: 116, 2227358946.0: 117, 2236863473.0: 118, 2237218368.0: 119, 2274662888.0: 120, 2289208681.0: 121, 2291829392.0: 122, 2297044089.0: 123, 2304817352.0: 124, 2320419972.0: 125, 2355851193.0: 126, 2374151408.0: 127, 2391364880.0: 128, 2427146600.0: 129, 2428110460.0: 130, 2484243389.0: 131, 2486560480.0: 132, 2500341399.0: 133, 2525382830.0: 134, 2525804511.0: 135, 2543502991.0: 136, 2570404225.0: 137, 2594969509.0: 138, 2605828515.0: 139, 2614965780.0: 140, 2629663898.0: 141, 2660226368.0: 142, 2680700989.0: 143, 2698023017.0: 144, 2704150950.0: 145, 2704391337.0: 146, 2705344731.0: 147, 2718511297.0: 148, 2777927614.0: 149, 2784562539.0: 150, 2790415716.0: 151, 2802803537.0: 152, 2837906509.0: 153, 2882982840.0: 154, 2891941146.0: 155, 2897068474.0: 156, 2911799538.0: 157, 2921381126.0: 158, 2922246272.0: 159, 2928445002.0: 160, 2929283935.0: 161, 2943733342.0: 162, 2946616011.0: 163, 2946753075.0: 164, 2968130490.0: 165, 2972234353.0: 166, 2986510902.0: 167, 3007168437.0: 168, 3013307454.0: 169, 3035916902.0: 170, 3044351403.0: 171, 3050114098.0: 172, 3054593790.0: 173, 3055157402.0: 174, 3081187861.0: 175, 3083034865.0: 176, 3084850148.0: 177, 3106646587.0: 178, 3115054711.0: 179, 3135487633.0: 180, 3136767196.0: 181, 3142142030.0: 182, 3151460722.0: 183, 3159900262.0: 184, 3161081293.0: 185, 3170319941.0: 186, 3175198032.0: 187, 3196150197.0: 188, 3228538363.0: 189, 3238683597.0: 190, 3238721665.0: 191, 3271835324.0: 192, 3355731387.0: 193, 3373371030.0: 194, 3377852338.0: 195, 3389968417.0: 196, 3399552473.0: 197, 3399686005.0: 198, 3413706075.0: 199, 3419816900.0: 200, 3442663479.0: 201, 3449926704.0: 202, 3456585449.0: 203, 3479035876.0: 204, 3486515508.0: 205, 3487760025.0: 206, 3489681553.0: 207, 3500039813.0: 208, 3504220298.0: 209, 3504567967.0: 210, 3560205868.0: 211, 3566038745.0: 212, 3571740086.0: 213, 3578160045.0: 214, 3583243144.0: 215, 3587950132.0: 216, 3617796739.0: 217, 3627149283.0: 218, 3630120526.0: 219, 3644545499.0: 220, 3668887089.0: 221, 3674889938.0: 222, 3779797910.0: 223, 3781602543.0: 224, 3787739279.0: 225, 3811281256.0: 226, 3812506524.0: 227, 3820396918.0: 228, 3831898384.0: 229, 3850168202.0: 230, 3892791767.0: 231, 3909865880.0: 232, 3911173544.0: 233, 3911423663.0: 234, 3950675667.0: 235, 3968181327.0: 236, 3976693656.0: 237, 4026731070.0: 238, 4029075826.0: 239, 4038959242.0: 240, 4041613553.0: 241, 4043792187.0: 242, 4053401639.0: 243, 4054125678.0: 244, 4086336312.0: 245, 4093368023.0: 246, 4108133746.0: 247, 4117487106.0: 248, 4141746538.0: 249, 4172474564.0: 250, 4210444082.0: 251, 4214835180.0: 252, 4231158915.0: 253, 4231211930.0: 254, 4247169298.0: 255, 4250999620.0: 256, 4255704155.0: 257, 4289499319.0: 258, 2631457595.0: 259}, {0.0: 0, 2.0: 1, 5.0: 2, 6.67: 3, 7.0: 4, 7.5: 5, 8.0: 6, 8.33: 7, 8.51: 8, 9.0: 9, 9.09: 10, 9.52: 11, 9.76: 12, 10.0: 13, 11.11: 14, 11.36: 15, 11.54: 16, 12.0: 17, 12.24: 18, 12.77: 19, 13.04: 20, 13.21: 21, 13.51: 22, 14.0: 23, 14.29: 24, 14.55: 25, 14.58: 26, 14.71: 27, 14.89: 28, 15.0: 29, 15.09: 30, 15.22: 31, 15.38: 32, 15.52: 33, 15.56: 34, 15.91: 35, 16.0: 36, 16.07: 37, 16.28: 38, 16.36: 39, 16.67: 40, 16.98: 41, 17.0: 42, 17.02: 43, 17.24: 44, 17.31: 45, 17.39: 46, 17.5: 47, 17.65: 48, 17.78: 49, 18.0: 50, 18.18: 51, 18.37: 52, 18.6: 53, 18.75: 54, 19.0: 55, 19.05: 56, 19.15: 57, 19.44: 58, 19.57: 59, 19.61: 60, 20.0: 61, 20.45: 62, 20.51: 63, 20.83: 64, 20.93: 65, 21.0: 66, 21.28: 67, 21.43: 68, 22.0: 69, 23.0: 70, 23.81: 71, 24.0: 72, 25.0: 73, 25.64: 74, 27.0: 75, 27.78: 76, 28.0: 77, 30.0: 78, 31.58: 79, 33.33: 80, 35.0: 81, 40.0: 82, 45.0: 83, 50.0: 84, 55.0: 85, 58.0: 86, 60.0: 87, 70.0: 88, 75.0: 89, 80.0: 90, 90.0: 91, 95.0: 92, 100.0: 93, 1684325040.0: 94}, {0.0: 0, 1.0: 1, 2.0: 2, 3.0: 3, 5.0: 4, 5.13: 5, 7.0: 6, 8.0: 7, 10.0: 8, 10.53: 9, 10.87: 10, 11.11: 11, 12.0: 12, 12.5: 13, 13.0: 14, 13.46: 15, 13.95: 16, 14.0: 17, 14.29: 18, 14.53: 19, 14.71: 20, 15.0: 21, 15.09: 22, 15.22: 23, 15.56: 24, 15.69: 25, 16.0: 26, 16.28: 27, 16.33: 28, 16.36: 29, 16.67: 30, 16.98: 31, 17.0: 32, 17.02: 33, 17.24: 34, 17.31: 35, 17.39: 36, 17.5: 37, 17.65: 38, 17.78: 39, 17.86: 40, 17.95: 41, 18.0: 42, 18.18: 43, 18.37: 44, 18.75: 45, 18.87: 46, 18.92: 47, 19.0: 48, 19.05: 49, 19.15: 50, 19.23: 51, 19.44: 52, 19.51: 53, 19.57: 54, 20.0: 55, 20.41: 56, 20.45: 57, 20.83: 58, 20.93: 59, 21.0: 60, 21.28: 61, 21.74: 62, 22.0: 63, 22.5: 64, 22.73: 65, 23.0: 66, 23.08: 67, 23.81: 68, 24.0: 69, 25.0: 70, 26.0: 71, 30.0: 72, 32.0: 73, 35.0: 74, 40.0: 75, 47.0: 76, 60.0: 77, 1684325040.0: 78}, {0.0: 0, 1.0: 1, 2.0: 2, 5.0: 3, 8.0: 4, 10.0: 5, 11.11: 6, 14.71: 7, 15.0: 8, 15.22: 9, 15.38: 10, 15.79: 11, 16.0: 12, 16.33: 13, 16.67: 14, 16.98: 15, 17.0: 16, 17.02: 17, 17.24: 18, 17.31: 19, 17.39: 20, 17.5: 21, 17.65: 22, 17.78: 23, 17.86: 24, 18.0: 25, 18.18: 26, 18.37: 27, 18.6: 28, 18.75: 29, 18.87: 30, 19.0: 31, 19.05: 32, 19.15: 33, 19.23: 34, 19.44: 35, 19.51: 36, 19.57: 37, 20.0: 38, 20.41: 39, 20.45: 40, 20.51: 41, 20.83: 42, 21.0: 43, 21.28: 44, 21.43: 45, 21.62: 46, 22.0: 47, 22.22: 48, 22.73: 49, 23.0: 50, 23.08: 51, 23.26: 52, 23.81: 53, 24.79: 54, 25.0: 55, 27.0: 56, 27.27: 57, 28.0: 58, 30.0: 59, 35.0: 60, 40.0: 61, 42.86: 62, 45.0: 63, 50.0: 64, 1684325040.0: 65}, {0.0: 0, 1.0: 1, 2.0: 2, 3.0: 3, 5.0: 4, 8.0: 5, 9.52: 6, 10.0: 7, 11.11: 8, 12.0: 9, 12.5: 10, 12.77: 11, 12.82: 12, 13.0: 13, 13.51: 14, 13.64: 15, 14.0: 16, 14.29: 17, 14.58: 18, 14.63: 19, 14.71: 20, 15.0: 21, 15.56: 22, 15.69: 23, 16.0: 24, 16.28: 25, 16.33: 26, 16.67: 27, 16.98: 28, 17.0: 29, 17.02: 30, 17.09: 31, 17.24: 32, 17.31: 33, 17.39: 34, 17.78: 35, 17.86: 36, 17.95: 37, 18.0: 38, 18.18: 39, 18.37: 40, 18.6: 41, 18.75: 42, 18.87: 43, 19.0: 44, 19.05: 45, 19.15: 46, 19.23: 47, 19.57: 48, 20.0: 49, 20.41: 50, 20.45: 51, 20.51: 52, 20.83: 53, 21.05: 54, 21.28: 55, 21.43: 56, 22.0: 57, 22.5: 58, 23.0: 59, 23.26: 60, 23.81: 61, 24.0: 62, 25.0: 63, 27.0: 64, 27.78: 65, 30.0: 66, 35.0: 67, 40.0: 68, 45.0: 69, 50.0: 70, 1684325040.0: 71}, {0.0: 0, 1.0: 1, 2.0: 2, 2.33: 3, 2.38: 4, 2.56: 5, 2.78: 6, 3.0: 7, 4.0: 8, 4.76: 9, 5.0: 10, 5.98: 11, 6.0: 12, 6.25: 13, 6.38: 14, 6.67: 15, 7.0: 16, 8.0: 17, 9.0: 18, 9.52: 19, 9.62: 20, 10.0: 21, 10.26: 22, 10.53: 23, 10.87: 24, 11.0: 25, 11.11: 26, 11.36: 27, 11.54: 28, 11.63: 29, 11.9: 30, 12.0: 31, 12.5: 32, 12.77: 33, 13.0: 34, 13.04: 35, 13.21: 36, 13.33: 37, 13.46: 38, 13.51: 39, 13.64: 40, 13.79: 41, 13.95: 42, 14.0: 43, 14.29: 44, 14.81: 45, 14.89: 46, 15.0: 47, 15.22: 48, 15.38: 49, 15.56: 50, 15.69: 51, 16.0: 52, 16.28: 53, 16.33: 54, 16.36: 55, 16.67: 56, 16.98: 57, 17.0: 58, 17.24: 59, 17.31: 60, 17.65: 61, 17.78: 62, 17.86: 63, 17.95: 64, 18.0: 65, 18.18: 66, 18.37: 67, 18.75: 68, 18.87: 69, 19.0: 70, 19.05: 71, 19.15: 72, 19.23: 73, 19.51: 74, 19.57: 75, 20.0: 76, 20.41: 77, 20.59: 78, 25.0: 79, 30.0: 80, 53.0: 81, 1684325040.0: 82}, {0.0: 0, 1.0: 1, 2.0: 2, 2.27: 3, 2.38: 4, 2.78: 5, 3.0: 6, 4.0: 7, 5.0: 8, 6.0: 9, 6.12: 10, 6.67: 11, 7.0: 12, 7.5: 13, 7.62: 14, 8.0: 15, 8.33: 16, 8.51: 17, 9.0: 18, 9.09: 19, 9.52: 20, 10.0: 21, 10.26: 22, 10.53: 23, 10.64: 24, 10.87: 25, 11.0: 26, 11.11: 27, 11.36: 28, 11.54: 29, 11.63: 30, 11.9: 31, 12.0: 32, 12.5: 33, 12.77: 34, 13.0: 35, 13.04: 36, 13.21: 37, 13.33: 38, 13.46: 39, 13.64: 40, 13.73: 41, 14.0: 42, 14.29: 43, 14.55: 44, 14.89: 45, 15.0: 46, 15.09: 47, 15.22: 48, 15.38: 49, 15.52: 50, 15.56: 51, 15.69: 52, 16.0: 53, 16.28: 54, 16.33: 55, 16.36: 56, 16.67: 57, 16.98: 58, 17.0: 59, 17.07: 60, 17.09: 61, 17.24: 62, 17.31: 63, 17.39: 64, 17.78: 65, 18.0: 66, 18.18: 67, 18.52: 68, 18.75: 69, 18.92: 70, 19.0: 71, 19.15: 72, 19.23: 73, 19.57: 74, 20.0: 75, 20.51: 76, 20.59: 77, 21.0: 78, 21.28: 79, 22.0: 80, 22.22: 81, 23.81: 82, 25.0: 83, 30.0: 84, 1684325040.0: 85}, {42326737.0: 0, 3065050794.0: 1, 3805456058.0: 2}, {42326737.0: 0, 3065050794.0: 1, 3805456058.0: 2}, {42326737.0: 0, 3065050794.0: 1, 3805456058.0: 2}, {42326737.0: 0, 3065050794.0: 1, 3805456058.0: 2}, {42326737.0: 0, 3065050794.0: 1, 3805456058.0: 2}, {42326737.0: 0, 3065050794.0: 1, 3805456058.0: 2}, {0.0: 0, 1.0: 1, 2.0: 2, 3.0: 3, 4.0: 4, 5.0: 5, 6.0: 6, 6.5: 7, 7.0: 8, 8.0: 9, 9.0: 10, 9.5: 11, 9.9: 12, 10.0: 13, 10.5: 14, 1684325040.0: 15, 7.5: 16}, {0.0: 0, 1.0: 1, 2.0: 2, 3.0: 3, 4.0: 4, 4.5: 5, 5.0: 6, 6.0: 7, 7.0: 8, 8.0: 9, 9.0: 10, 10.0: 11, 1684325040.0: 12, 8.5: 13}, {0.0: 0, 1.0: 1, 2.0: 2, 3.0: 3, 4.0: 4, 5.0: 5, 6.0: 6, 6.5: 7, 7.0: 8, 8.0: 9, 9.0: 10, 10.0: 11, 1684325040.0: 12, 7.5: 13, 8.5: 14}, {0.0: 0, 1.0: 1, 2.0: 2, 3.0: 3, 4.0: 4, 5.0: 5, 5.5: 6, 6.0: 7, 7.0: 8, 8.0: 9, 9.0: 10, 10.0: 11, 1684325040.0: 12, 9.5: 13, 6.5: 14}, {0.0: 0, 1.0: 1, 2.0: 2, 3.0: 3, 4.0: 4, 5.0: 5, 5.5: 6, 6.0: 7, 7.0: 8, 8.0: 9, 9.0: 10, 10.0: 11, 1684325040.0: 12, 9.5: 13}, {0.0: 0, 1.0: 1, 2.0: 2, 3.0: 3, 4.0: 4, 5.0: 5, 6.0: 6, 6.5: 7, 7.0: 8, 8.0: 9, 8.5: 10, 9.0: 11, 10.0: 12, 1684325040.0: 13, 7.5: 14}, {1852959419.0: 0, 3336003742.0: 1, 4273261354.0: 2}, {1852959419.0: 0, 3336003742.0: 1, 4273261354.0: 2}, {1852959419.0: 0, 3336003742.0: 1, 4273261354.0: 2}, {1852959419.0: 0, 3336003742.0: 1, 4273261354.0: 2}, {1852959419.0: 0, 3336003742.0: 1, 4273261354.0: 2}, {1852959419.0: 0, 3336003742.0: 1, 4273261354.0: 2}, {0.0: 0, 2.0: 1, 5.0: 2, 6.67: 3, 7.0: 4, 7.5: 5, 8.0: 6, 8.33: 7, 8.51: 8, 9.0: 9, 9.09: 10, 9.52: 11, 9.76: 12, 10.0: 13, 11.11: 14, 11.36: 15, 11.54: 16, 12.0: 17, 12.24: 18, 12.77: 19, 13.04: 20, 13.21: 21, 13.51: 22, 14.0: 23, 14.29: 24, 14.55: 25, 14.58: 26, 14.71: 27, 14.89: 28, 15.0: 29, 15.09: 30, 15.22: 31, 15.38: 32, 15.52: 33, 15.56: 34, 15.91: 35, 16.0: 36, 16.07: 37, 16.28: 38, 16.36: 39, 16.67: 40, 16.98: 41, 17.0: 42, 17.02: 43, 17.24: 44, 17.31: 45, 17.39: 46, 17.5: 47, 17.65: 48, 17.78: 49, 18.0: 50, 18.18: 51, 18.37: 52, 18.6: 53, 18.75: 54, 19.0: 55, 19.05: 56, 19.15: 57, 19.44: 58, 19.57: 59, 19.61: 60, 20.0: 61, 20.45: 62, 20.51: 63, 20.83: 64, 20.93: 65, 21.0: 66, 21.28: 67, 21.43: 68, 22.0: 69, 23.0: 70, 23.81: 71, 24.0: 72, 25.0: 73, 25.64: 74, 27.0: 75, 27.78: 76, 28.0: 77, 30.0: 78, 31.58: 79, 33.33: 80, 35.0: 81, 40.0: 82, 45.0: 83, 50.0: 84, 55.0: 85, 58.0: 86, 60.0: 87, 70.0: 88, 75.0: 89, 80.0: 90, 90.0: 91, 95.0: 92, 100.0: 93, 1684325040.0: 94}, {0.0: 0, 1.0: 1, 2.0: 2, 3.0: 3, 5.0: 4, 5.13: 5, 7.0: 6, 8.0: 7, 10.0: 8, 10.53: 9, 10.87: 10, 11.11: 11, 12.0: 12, 12.5: 13, 13.0: 14, 13.46: 15, 13.95: 16, 14.0: 17, 14.29: 18, 14.53: 19, 14.71: 20, 15.0: 21, 15.09: 22, 15.22: 23, 15.56: 24, 15.69: 25, 16.0: 26, 16.28: 27, 16.33: 28, 16.36: 29, 16.67: 30, 16.98: 31, 17.0: 32, 17.02: 33, 17.24: 34, 17.31: 35, 17.39: 36, 17.5: 37, 17.65: 38, 17.78: 39, 17.86: 40, 17.95: 41, 18.0: 42, 18.18: 43, 18.37: 44, 18.75: 45, 18.87: 46, 18.92: 47, 19.0: 48, 19.05: 49, 19.15: 50, 19.23: 51, 19.44: 52, 19.51: 53, 19.57: 54, 20.0: 55, 20.41: 56, 20.45: 57, 20.83: 58, 20.93: 59, 21.0: 60, 21.28: 61, 21.74: 62, 22.0: 63, 22.5: 64, 22.73: 65, 23.0: 66, 23.08: 67, 23.81: 68, 24.0: 69, 25.0: 70, 26.0: 71, 30.0: 72, 32.0: 73, 35.0: 74, 40.0: 75, 47.0: 76, 60.0: 77, 1684325040.0: 78}, {0.0: 0, 1.0: 1, 2.0: 2, 5.0: 3, 8.0: 4, 10.0: 5, 11.11: 6, 14.71: 7, 15.0: 8, 15.22: 9, 15.38: 10, 15.79: 11, 16.0: 12, 16.33: 13, 16.67: 14, 16.98: 15, 17.0: 16, 17.02: 17, 17.24: 18, 17.31: 19, 17.39: 20, 17.5: 21, 17.65: 22, 17.78: 23, 17.86: 24, 18.0: 25, 18.18: 26, 18.37: 27, 18.6: 28, 18.75: 29, 18.87: 30, 19.0: 31, 19.05: 32, 19.15: 33, 19.23: 34, 19.44: 35, 19.51: 36, 19.57: 37, 20.0: 38, 20.41: 39, 20.45: 40, 20.51: 41, 20.83: 42, 21.0: 43, 21.28: 44, 21.43: 45, 21.62: 46, 22.0: 47, 22.22: 48, 22.73: 49, 23.0: 50, 23.08: 51, 23.26: 52, 23.81: 53, 24.79: 54, 25.0: 55, 27.0: 56, 27.27: 57, 28.0: 58, 30.0: 59, 35.0: 60, 40.0: 61, 42.86: 62, 45.0: 63, 50.0: 64, 1684325040.0: 65}, {0.0: 0, 1.0: 1, 2.0: 2, 3.0: 3, 5.0: 4, 8.0: 5, 9.52: 6, 10.0: 7, 11.11: 8, 12.0: 9, 12.5: 10, 12.77: 11, 12.82: 12, 13.0: 13, 13.51: 14, 13.64: 15, 14.0: 16, 14.29: 17, 14.58: 18, 14.63: 19, 14.71: 20, 15.0: 21, 15.56: 22, 15.69: 23, 16.0: 24, 16.28: 25, 16.33: 26, 16.67: 27, 16.98: 28, 17.0: 29, 17.02: 30, 17.09: 31, 17.24: 32, 17.31: 33, 17.39: 34, 17.78: 35, 17.86: 36, 17.95: 37, 18.0: 38, 18.18: 39, 18.37: 40, 18.6: 41, 18.75: 42, 18.87: 43, 19.0: 44, 19.05: 45, 19.15: 46, 19.23: 47, 19.57: 48, 20.0: 49, 20.41: 50, 20.45: 51, 20.51: 52, 20.83: 53, 21.05: 54, 21.28: 55, 21.43: 56, 22.0: 57, 22.5: 58, 23.0: 59, 23.26: 60, 23.81: 61, 24.0: 62, 25.0: 63, 27.0: 64, 27.78: 65, 30.0: 66, 35.0: 67, 40.0: 68, 45.0: 69, 50.0: 70, 1684325040.0: 71}, {0.0: 0, 1.0: 1, 2.0: 2, 2.33: 3, 2.38: 4, 2.56: 5, 2.78: 6, 3.0: 7, 4.0: 8, 4.76: 9, 5.0: 10, 5.98: 11, 6.0: 12, 6.25: 13, 6.38: 14, 6.67: 15, 7.0: 16, 8.0: 17, 9.0: 18, 9.52: 19, 9.62: 20, 10.0: 21, 10.26: 22, 10.53: 23, 10.87: 24, 11.0: 25, 11.11: 26, 11.36: 27, 11.54: 28, 11.63: 29, 11.9: 30, 12.0: 31, 12.5: 32, 12.77: 33, 13.0: 34, 13.04: 35, 13.21: 36, 13.33: 37, 13.46: 38, 13.51: 39, 13.64: 40, 13.79: 41, 13.95: 42, 14.0: 43, 14.29: 44, 14.81: 45, 14.89: 46, 15.0: 47, 15.22: 48, 15.38: 49, 15.56: 50, 15.69: 51, 16.0: 52, 16.28: 53, 16.33: 54, 16.36: 55, 16.67: 56, 16.98: 57, 17.0: 58, 17.24: 59, 17.31: 60, 17.65: 61, 17.78: 62, 17.86: 63, 17.95: 64, 18.0: 65, 18.18: 66, 18.37: 67, 18.75: 68, 18.87: 69, 19.0: 70, 19.05: 71, 19.15: 72, 19.23: 73, 19.51: 74, 19.57: 75, 20.0: 76, 20.41: 77, 20.59: 78, 25.0: 79, 30.0: 80, 53.0: 81, 1684325040.0: 82}, {0.0: 0, 1.0: 1, 2.0: 2, 2.27: 3, 2.38: 4, 2.78: 5, 3.0: 6, 4.0: 7, 5.0: 8, 6.0: 9, 6.12: 10, 6.67: 11, 7.0: 12, 7.5: 13, 7.62: 14, 8.0: 15, 8.33: 16, 8.51: 17, 9.0: 18, 9.09: 19, 9.52: 20, 10.0: 21, 10.26: 22, 10.53: 23, 10.64: 24, 10.87: 25, 11.0: 26, 11.11: 27, 11.36: 28, 11.54: 29, 11.63: 30, 11.9: 31, 12.0: 32, 12.5: 33, 12.77: 34, 13.0: 35, 13.04: 36, 13.21: 37, 13.33: 38, 13.46: 39, 13.64: 40, 13.73: 41, 14.0: 42, 14.29: 43, 14.55: 44, 14.89: 45, 15.0: 46, 15.09: 47, 15.22: 48, 15.38: 49, 15.52: 50, 15.56: 51, 15.69: 52, 16.0: 53, 16.28: 54, 16.33: 55, 16.36: 56, 16.67: 57, 16.98: 58, 17.0: 59, 17.07: 60, 17.09: 61, 17.24: 62, 17.31: 63, 17.39: 64, 17.78: 65, 18.0: 66, 18.18: 67, 18.52: 68, 18.75: 69, 18.92: 70, 19.0: 71, 19.15: 72, 19.23: 73, 19.57: 74, 20.0: 75, 20.51: 76, 20.59: 77, 21.0: 78, 21.28: 79, 22.0: 80, 22.22: 81, 23.81: 82, 25.0: 83, 30.0: 84, 1684325040.0: 85}, {42326737.0: 0, 3065050794.0: 1, 3805456058.0: 2}, {42326737.0: 0, 3065050794.0: 1, 3805456058.0: 2}, {42326737.0: 0, 3065050794.0: 1, 3805456058.0: 2}, {42326737.0: 0, 3065050794.0: 1, 3805456058.0: 2}, {42326737.0: 0, 3065050794.0: 1, 3805456058.0: 2}, {42326737.0: 0, 3065050794.0: 1, 3805456058.0: 2}, {2.0: 0, 3.0: 1, 4.0: 2, 5.0: 3, 6.0: 4, 7.0: 5, 8.0: 6, 9.0: 7, 10.0: 8, 1684325040.0: 9}, {2.0: 0, 3.0: 1, 4.0: 2, 5.0: 3, 6.0: 4, 7.0: 5, 8.0: 6, 9.0: 7, 10.0: 8, 1684325040.0: 9}, {2.0: 0, 3.0: 1, 4.0: 2, 5.0: 3, 6.0: 4, 7.0: 5, 8.0: 6, 9.0: 7, 10.0: 8, 1684325040.0: 9}, {3.0: 0, 4.0: 1, 5.0: 2, 6.0: 3, 7.0: 4, 8.0: 5, 9.0: 6, 10.0: 7, 1684325040.0: 8}, {2.0: 0, 3.0: 1, 4.0: 2, 5.0: 3, 6.0: 4, 7.0: 5, 8.0: 6, 9.0: 7, 10.0: 8, 1684325040.0: 9}, {1852959419.0: 0, 3336003742.0: 1, 4273261354.0: 2}, {1852959419.0: 0, 3336003742.0: 1, 4273261354.0: 2}, {1852959419.0: 0, 3336003742.0: 1, 4273261354.0: 2}, {1852959419.0: 0, 3336003742.0: 1, 4273261354.0: 2}, {1852959419.0: 0, 3336003742.0: 1, 4273261354.0: 2}, {0.0: 0, 1.0: 1, 2.0: 2, 3.0: 3, 3.5: 4, 4.0: 5, 5.0: 6, 6.0: 7, 6.5: 8, 7.0: 9, 7.5: 10, 8.0: 11, 9.0: 12, 9.5: 13, 10.0: 14, 1684325040.0: 15, 9.9: 16, 8.5: 17}, {0.0: 0, 1.0: 1, 2.0: 2, 3.0: 3, 4.0: 4, 4.5: 5, 5.0: 6, 6.0: 7, 7.0: 8, 7.5: 9, 8.0: 10, 9.0: 11, 10.0: 12, 1684325040.0: 13, 8.5: 14}, {0.0: 0, 1.0: 1, 2.0: 2, 3.0: 3, 4.0: 4, 5.0: 5, 6.0: 6, 7.0: 7, 7.5: 8, 8.0: 9, 9.0: 10, 10.0: 11, 1684325040.0: 12, 6.5: 13, 8.5: 14, 5.5: 15}, {0.0: 0, 1.0: 1, 2.0: 2, 3.0: 3, 4.0: 4, 5.0: 5, 5.5: 6, 6.0: 7, 7.0: 8, 7.5: 9, 8.0: 10, 9.0: 11, 10.0: 12, 1684325040.0: 13, 9.5: 14, 6.5: 15, 8.5: 16}, {0.0: 0, 1.0: 1, 2.0: 2, 3.0: 3, 4.0: 4, 5.0: 5, 5.5: 6, 6.0: 7, 7.0: 8, 7.5: 9, 8.0: 10, 9.0: 11, 10.0: 12, 1684325040.0: 13, 9.5: 14, 8.5: 15}, {0.0: 0, 1.0: 1, 2.0: 2, 3.0: 3, 4.0: 4, 5.0: 5, 5.5: 6, 6.0: 7, 6.5: 8, 7.0: 9, 7.5: 10, 8.0: 11, 9.0: 12, 10.0: 13, 1684325040.0: 14, 8.5: 15}, {1852959419.0: 0, 3336003742.0: 1, 4273261354.0: 2}, {1852959419.0: 0, 3336003742.0: 1, 4273261354.0: 2}, {1852959419.0: 0, 3336003742.0: 1, 4273261354.0: 2}, {1852959419.0: 0, 3336003742.0: 1, 4273261354.0: 2}, {1852959419.0: 0, 3336003742.0: 1, 4273261354.0: 2}, {1852959419.0: 0, 3336003742.0: 1, 4273261354.0: 2}, {1.0: 0, 2.0: 1, 3.0: 2, 4.0: 3, 5.0: 4, 6.0: 5, 7.0: 6, 8.0: 7, 9.0: 8, 10.0: 9, 1684325040.0: 10}, {1.0: 0, 2.0: 1, 3.0: 2, 4.0: 3, 5.0: 4, 6.0: 5, 7.0: 6, 8.0: 7, 9.0: 8, 10.0: 9, 1684325040.0: 10}, {1.0: 0, 2.0: 1, 3.0: 2, 4.0: 3, 5.0: 4, 6.0: 5, 7.0: 6, 8.0: 7, 9.0: 8, 10.0: 9, 1684325040.0: 10}, {1.0: 0, 2.0: 1, 3.0: 2, 4.0: 3, 5.0: 4, 6.0: 5, 7.0: 6, 8.0: 7, 9.0: 8, 10.0: 9, 1684325040.0: 10}, {0.0: 0, 1.0: 1, 2.0: 2, 3.0: 3, 4.0: 4, 5.0: 5, 6.0: 6, 7.0: 7, 8.0: 8, 9.0: 9, 10.0: 10, 1684325040.0: 11}, {0.0: 0, 1.0: 1, 2.0: 2, 3.0: 3, 4.0: 4, 5.0: 5, 6.0: 6, 7.0: 7, 8.0: 8, 9.0: 9, 10.0: 10, 1684325040.0: 11}, {0.0: 0, 1.0: 1, 2.0: 2, 3.0: 3, 4.0: 4, 5.0: 5, 6.0: 6, 7.0: 7, 8.0: 8, 9.0: 9, 10.0: 10, 1684325040.0: 11}, {0.0: 0, 1.0: 1, 2.0: 2, 3.0: 3, 4.0: 4, 5.0: 5, 6.0: 6, 7.0: 7, 8.0: 8, 9.0: 9, 10.0: 10, 14.0: 11, 1684325040.0: 12}, {0.0: 0, 1.0: 1, 2.0: 2, 3.0: 3, 4.0: 4, 5.0: 5, 6.0: 6, 7.0: 7, 8.0: 8, 9.0: 9, 10.0: 10, 1684325040.0: 11}, {1.0: 0, 2.0: 1, 3.0: 2, 4.0: 3, 5.0: 4, 6.0: 5, 7.0: 6, 8.0: 7, 9.0: 8, 10.0: 9, 13.0: 10, 1684325040.0: 11}, {1.0: 0, 2.0: 1, 3.0: 2, 4.0: 3, 5.0: 4, 6.0: 5, 7.0: 6, 8.0: 7, 9.0: 8, 10.0: 9, 1684325040.0: 10}, {0.0: 0, 1.0: 1, 2.0: 2, 3.0: 3, 4.0: 4, 5.0: 5, 6.0: 6, 7.0: 7, 8.0: 8, 9.0: 9, 10.0: 10, 1684325040.0: 11}, {0.0: 0, 2.0: 1, 3.0: 2, 4.0: 3, 5.0: 4, 6.0: 5, 7.0: 6, 8.0: 7, 9.0: 8, 10.0: 9, 1684325040.0: 10}, {0.0: 0, 1.0: 1, 2.0: 2, 3.0: 3, 4.0: 4, 5.0: 5, 6.0: 6, 7.0: 7, 8.0: 8, 9.0: 9, 10.0: 10, 1684325040.0: 11}, {1.0: 0, 2.0: 1, 3.0: 2, 4.0: 3, 5.0: 4, 6.0: 5, 7.0: 6, 8.0: 7, 9.0: 8, 10.0: 9, 1684325040.0: 10}, {1.0: 0, 2.0: 1, 3.0: 2, 4.0: 3, 5.0: 4, 6.0: 5, 7.0: 6, 8.0: 7, 9.0: 8, 10.0: 9, 1684325040.0: 10}, {0.0: 0, 1.0: 1, 2.0: 2, 3.0: 3, 4.0: 4, 5.0: 5, 6.0: 6, 7.0: 7, 8.0: 8, 9.0: 9, 10.0: 10, 1684325040.0: 11}, {1852959419.0: 0, 3336003742.0: 1, 4273261354.0: 2}, {1852959419.0: 0, 3336003742.0: 1, 4273261354.0: 2}, {1852959419.0: 0, 3336003742.0: 1, 4273261354.0: 2}, {1852959419.0: 0, 3336003742.0: 1, 4273261354.0: 2}, {1852959419.0: 0, 3336003742.0: 1, 4273261354.0: 2}, {1852959419.0: 0, 3336003742.0: 1, 4273261354.0: 2}, {1852959419.0: 0, 3336003742.0: 1, 4273261354.0: 2}, {1852959419.0: 0, 3336003742.0: 1, 4273261354.0: 2}, {1852959419.0: 0, 3336003742.0: 1, 4273261354.0: 2}, {1852959419.0: 0, 3336003742.0: 1, 4273261354.0: 2}, {1852959419.0: 0, 3336003742.0: 1, 4273261354.0: 2}, {1852959419.0: 0, 3336003742.0: 1, 4273261354.0: 2}, {1852959419.0: 0, 3336003742.0: 1, 4273261354.0: 2}, {1852959419.0: 0, 3336003742.0: 1, 4273261354.0: 2}, {1852959419.0: 0, 3336003742.0: 1, 4273261354.0: 2}, {1852959419.0: 0, 3336003742.0: 1, 4273261354.0: 2}, {1852959419.0: 0, 3336003742.0: 1, 4273261354.0: 2}, {-0.73: 0, -0.7: 1, -0.64: 2, -0.63: 3, -0.61: 4, -0.59: 5, -0.58: 6, -0.57: 7, -0.56: 8, -0.55: 9, -0.54: 10, -0.52: 11, -0.51: 12, -0.5: 13, -0.49: 14, -0.48: 15, -0.47: 16, -0.46: 17, -0.45: 18, -0.43: 19, -0.42: 20, -0.41: 21, -0.4: 22, -0.39: 23, -0.38: 24, -0.37: 25, -0.36: 26, -0.35: 27, -0.34: 28, -0.33: 29, -0.32: 30, -0.31: 31, -0.3: 32, -0.29: 33, -0.28: 34, -0.27: 35, -0.26: 36, -0.25: 37, -0.24: 38, -0.23: 39, -0.22: 40, -0.21: 41, -0.2: 42, -0.19: 43, -0.18: 44, -0.17: 45, -0.16: 46, -0.15: 47, -0.14: 48, -0.13: 49, -0.12: 50, -0.11: 51, -0.1: 52, -0.09: 53, -0.08: 54, -0.07: 55, -0.06: 56, -0.05: 57, -0.04: 58, -0.03: 59, -0.02: 60, -0.01: 61, 0.0: 62, 0.01: 63, 0.02: 64, 0.03: 65, 0.04: 66, 0.05: 67, 0.06: 68, 0.07: 69, 0.08: 70, 0.09: 71, 0.1: 72, 0.11: 73, 0.12: 74, 0.13: 75, 0.14: 76, 0.15: 77, 0.16: 78, 0.17: 79, 0.18: 80, 0.19: 81, 0.2: 82, 0.21: 83, 0.22: 84, 0.23: 85, 0.24: 86, 0.25: 87, 0.26: 88, 0.27: 89, 0.28: 90, 0.29: 91, 0.3: 92, 0.31: 93, 0.32: 94, 0.33: 95, 0.34: 96, 0.35: 97, 0.36: 98, 0.37: 99, 0.38: 100, 0.39: 101, 0.4: 102, 0.41: 103, 0.42: 104, 0.43: 105, 0.44: 106, 0.45: 107, 0.46: 108, 0.47: 109, 0.48: 110, 0.49: 111, 0.5: 112, 0.51: 113, 0.52: 114, 0.53: 115, 0.54: 116, 0.55: 117, 0.56: 118, 0.57: 119, 0.58: 120, 0.59: 121, 0.6: 122, 0.61: 123, 0.62: 124, 0.63: 125, 0.64: 126, 0.65: 127, 0.66: 128, 0.67: 129, 0.68: 130, 0.69: 131, 0.7: 132, 0.71: 133, 0.72: 134, 0.73: 135, 0.74: 136, 0.75: 137, 0.76: 138, 0.77: 139, 0.78: 140, 0.79: 141, 0.8: 142, 0.81: 143, 0.82: 144, 0.83: 145, 0.84: 146, 0.85: 147, 0.88: 148, 0.9: 149, 0.91: 150, 1684325040.0: 151, -0.44: 152, -0.62: 153, 0.87: 154}, {531012540.0: 0, 1483731064.0: 1, 1548018671.0: 2}, {1.0: 0, 2.0: 1, 3.0: 2, 4.0: 3, 5.0: 4, 6.0: 5, 7.0: 6, 8.0: 7, 9.0: 8, 10.0: 9, 1684325040.0: 10}, {0.0: 0, 1.0: 1, 2.0: 2, 3.0: 3, 4.0: 4, 5.0: 5, 6.0: 6, 7.0: 7, 8.0: 8, 9.0: 9, 10.0: 10, 12.0: 11, 13.0: 12, 14.0: 13, 15.0: 14, 18.0: 15, 19.0: 16, 20.0: 17, 1684325040.0: 18}, {0.0: 0, 0.5: 1, 1.0: 2, 1.5: 3, 2.0: 4, 2.5: 5, 3.0: 6, 3.4: 7, 4.0: 8, 5.0: 9, 6.0: 10, 7.0: 11, 8.0: 12, 9.0: 13, 10.0: 14, 12.0: 15, 18.0: 16, 1684325040.0: 17}, {2045239039.0: 0, 3796330715.0: 1, 3887069803.0: 2}, {1838306074.0: 0, 2834197676.0: 1, 3714257777.0: 2}, {2985647597.0: 0, 3422422935.0: 1, 3959514308.0: 2}, {0.0: 0, 1.0: 1, 2.0: 2, 3.0: 3, 4.0: 4, 4.5: 5, 5.0: 6, 6.0: 7, 6.5: 8, 7.0: 9, 7.5: 10, 8.0: 11, 8.5: 12, 9.0: 13, 9.5: 14, 10.0: 15, 1684325040.0: 16, 9.7: 17}, {0.0: 0, 1.0: 1, 2.0: 2, 3.0: 3, 4.0: 4, 4.5: 5, 5.0: 6, 6.0: 7, 6.5: 8, 7.0: 9, 7.5: 10, 8.0: 11, 8.5: 12, 9.0: 13, 10.0: 14, 1684325040.0: 15, 9.5: 16}, {1852959419.0: 0, 3336003742.0: 1, 4273261354.0: 2}, {2045239039.0: 0, 3796330715.0: 1, 3887069803.0: 2}, {0.0: 0, 1.0: 1, 6.0: 2, 7.0: 3, 8.0: 4, 1684325040.0: 5}]
target = ''
target_column = 122
important_idxs = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121]
ignore_idxs = []
classifier_type = 'NN'
num_attr = 122
n_classes = 2
model_cap = 111
w_h = np.array([[0.03172071650624275, 0.022347427904605865, 0.06600615382194519, 0.04284059628844261, 0.09248671680688858, 0.0121199581772089, 0.22565096616744995, -0.3140678107738495, -0.009409981779754162, 0.04386468604207039, -0.05459338799118996, -0.016181597486138344, 0.0627146065235138, -0.08765362948179245, 0.2214459925889969, 0.07551193237304688, -0.9032500982284546, 0.1887200027704239, -0.6349093317985535, -0.20273515582084656], [-0.21756942570209503, -0.28839635848999023, 0.004797517787665129, 0.17733095586299896, -0.02201010473072529, 0.006197101436555386, 0.09058120846748352, -0.11057061702013016, -0.21000109612941742, 0.03516874462366104, 0.23575758934020996, 0.2032109797000885, 0.12638677656650543, -0.16385121643543243, -0.950437068939209, 0.7546932697296143, -0.3011815845966339, -0.05301854386925697, -0.1982385218143463, 0.9081494808197021], [-0.5631998777389526, -0.12532071769237518, 0.06590565294027328, -0.1424633413553238, 0.049519892781972885, 0.01890917681157589, 0.07378421723842621, -0.034198373556137085, -0.2692680060863495, -0.06792768090963364, 0.008158120326697826, 0.2546142339706421, 0.17668838798999786, -0.36547380685806274, 0.026587067171931267, -0.30541881918907166, -0.4933927059173584, 0.019300108775496483, 0.42251813411712646, 0.037062156945466995], [0.007201995700597763, 0.006903595291078091, 0.005463860929012299, 0.001275553135201335, -0.005240597762167454, 0.008171526715159416, 0.003962209913879633, -0.03221093863248825, -0.003594518406316638, -0.0013878203462809324, 0.001217881217598915, -0.028481315821409225, 0.0011584035819396377, 0.006554423365741968, 0.14064720273017883, -0.6310312747955322, -0.20905877649784088, 0.15640060603618622, 0.17056046426296234, -0.1899404078722], [-0.3443678021430969, 0.043163977563381195, 0.06033340469002724, -0.15346366167068481, 0.11565279215574265, 0.01017620600759983, 0.03596791625022888, 0.015146293677389622, -0.12936170399188995, -0.13617780804634094, -0.1006244495511055, 0.1451757401227951, 0.10222823172807693, -0.2123633176088333, 0.4331216812133789, -0.4252193868160248, -0.2906654477119446, 0.0139295170083642, 0.46561649441719055, -0.21722063422203064]])
b_h = np.array([2.8910224437713623, -4.478501319885254, 0.39348432421684265, 4.278883934020996, -1.4546891450881958])
w_o = np.array([[0.09663565456867218, -0.10236834734678268, 0.13361716270446777, -0.44202518463134766, -0.17488010227680206]])
b_o = np.array(-0.7709197998046875)


class PredictorError(Exception):

    def __init__(self, msg, code):
        self.msg = msg
        self.code = code

    def __str__(self):
        return self.msg
def __column_norm(column, mappings):
    normalized_col = np.zeros(column.shape[0])
    for i, val in enumerate(column.reshape(-1)):
        if val not in mappings:
            mappings[val] = int(max(mappings.values())) + 1
        normalized_col[i] = mappings[val]
    return normalized_col


def __normalize(arr):
    for i,mapping in zip(list_of_cols_to_normalize, column_mappings):
        if i >= arr.shape[1]:
            break
        col = arr[:, i]
        normcol = __column_norm(col, mapping)
        arr[:, i] = normcol
    return arr

def __transform(X):
    mean = np.array([0.8759746588693957, 11.255847953216374, 0.5075536062378168, 8.601364522417153, 8.54775828460039, 4.2480506822612085, 1.5180311890838207, 1.2675438596491229, 1.2850877192982457, 0.4030214424951267, 3.810672514619883, 2.7521929824561404, 1.0699317738791423, 1.094785575048733, 115.21345029239767, 52.61208576998051, 39.77509746588694, 35.114522417154, 34.79385964912281, 31.261939571150098, 35.698830409356724, 1.003898635477583, 1.273391812865497, 1.1990740740740742, 1.2965399610136452, 1.1812865497076024, 1.1917641325536061, 6.894249512670565, 8.257553606237817, 8.22928849902534, 7.307261208576998, 7.943957115009747, 6.8089668615984404, 0.8245614035087719, 0.5689571150097466, 0.5104775828460039, 0.780214424951267, 0.7707115009746589, 1.178849902534113, 52.93396686159844, 39.44005847953216, 35.085769980506825, 34.842592592592595, 31.273391812865498, 35.41812865497076, 0.9809941520467836, 1.2675438596491229, 1.1915204678362572, 1.3118908382066277, 1.179093567251462, 1.195662768031189, 5.128167641325536, 6.317982456140351, 5.732456140350878, 5.440058479532164, 5.618908382066277, 0.3937621832358674, 0.5813840155945419, 0.5046296296296297, 0.5151072124756335, 0.6232943469785575, 8.043615984405458, 8.723684210526315, 7.998538011695906, 7.663986354775829, 8.32724171539961, 7.461013645224171, 0.8148148148148148, 0.5657894736842105, 0.503167641325536, 0.7587719298245614, 0.7385477582846004, 1.1715399610136452, 5.457846003898635, 3.621588693957115, 5.270711500974659, 6.810672514619883, 7.014376218323587, 6.744152046783626, 5.775584795321637, 3.8988791423001947, 5.780458089668616, 6.692982456140351, 4.371101364522417, 6.844054580896686, 6.966861598440546, 6.841861598440546, 6.844785575048733, 4.6644736842105265, 4.408625730994152, 0.969541910331384, 1.3464912280701755, 0.9117933723196882, 0.6298732943469786, 0.7358674463937622, 0.8218810916179338, 1.04093567251462, 1.500243664717349, 0.9590643274853801, 0.7200292397660819, 1.0865009746588694, 0.8092105263157895, 0.5921052631578947, 0.7626705653021443, 0.6559454191033138, 1.1218323586744638, 1.4030214424951266, 83.11647173489278, 0.9349415204678363, 4.624025341130604, 15.211013645224172, 7.397417153996101, 0.9624756335282652, 1.0346003898635479, 0.8096978557504874, 7.980506822612086, 6.62962962962963, 0.7677875243664717, 1.0857699805068226, 0.26973684210526316, 0.42422027290448344, 0.4161793372319688])
    components = np.array([[0.0002214073864078963, 0.0013838388030215636, -0.0004565754011651763, -0.0003178966312134118, 0.0012338090744313203, -0.0023154629982436122, -6.984608012298601e-05, -0.0015739541950157076, -2.9505327624306756e-06, -3.5449071750087106e-05, -0.0012167819827178985, 0.0017496599206135695, 0.00032117440051559353, -0.0007046474791775767, 0.9977947967556209, -0.0035070978812092716, 0.0010253923681977444, -0.0017088008803308533, -0.006833193205382629, -0.000554969359902158, 0.014073778052714186, 2.1302463742995482e-05, -5.001644789617424e-05, -0.00028206042757155574, 0.0002224795497908468, -5.516068058499762e-05, 0.00016877036420257028, 0.0007545094974627653, -0.0004667534928415565, -0.001214027344028705, 0.00012492278430277623, -0.001064315353740367, -6.857681176641346e-05, -0.00038462687956081177, -0.00010779067000528926, -0.00029491024103914503, 0.00011113463651038252, 5.114333414684397e-05, -0.00025293634247254093, -0.03371422893337065, -0.0023110544605681807, -0.006968710427137589, -0.010448210082422176, 0.043251567953387436, 0.029266358370823913, 0.0005154764621109981, 0.00015665960888433994, 0.0007128052029678207, 0.0007744998690330322, 0.000603467139390248, 0.0003600701907314693, 0.00014448832929297048, 0.00047561527143584855, -0.0006469195229754155, -0.0006147635951800368, -0.000528111219959304, -0.0007643019309939336, -0.00011995898934996253, -0.0005740328271457481, -0.0005756380085361768, -0.0002494451114599342, -0.0021903987124500695, -0.0013403640092932358, -0.0007572091385022973, -0.0011487353854702598, -0.0009631997970743978, 0.000724106708148454, 0.0004964508241362958, -0.00038898176469009737, -0.00024665465043291024, -0.0003661815063608783, 0.00039810528248163677, 0.0001537194372291918, 0.0014921270622856567, 0.0012646219416003594, -0.000163955207154111, 0.00042698848012821605, 0.001141783699909309, 0.0008863477168360544, 0.0021038776634743042, -0.002482221640577904, -0.0009187521077365081, 0.00033879190565577305, -0.0012556815661347812, 0.0006268406370522728, -0.00013628001391024426, 0.0010699878344844138, 0.0008639718869880952, -0.000689307715802188, 6.390964173333734e-05, -0.0003507299621357057, -0.00020179783156524717, -0.00021785786198549016, -0.0002514881498705455, -0.0005787928431171467, -0.0005012389525982536, -0.0008021992107370709, 0.0003294035951421823, -0.00034128211634556127, 0.00024918086858782585, 0.0008819716411524564, 0.000240230422055078, -0.0001485032545396868, 1.5627663936869436e-05, -0.0008614405601883991, 0.00012546020300368071, -0.00045316643302990357, 0.004435870834246875, -0.0002597789900397157, 0.00038603314436380914, 0.005565166078510042, -0.0008721067988610521, -0.00017660233638711623, -0.0001512824681553513, -0.00015409769755226314, -0.0019349120964628685, -0.00019289456739893896, 1.6513351700424472e-07, -0.0003055750626932846, 0.00016413275844626949, -0.00025908828793666473, 0.00012442302667885015], [-0.0007749727571206951, 0.006422813488305869, 0.005334627243315984, -0.014121523841018079, -0.017305217434451632, -0.023657240549290675, -0.00028022035663089005, -0.0004776414708134237, -0.0012088721923337949, 0.0002862876322100256, -0.000838952965523304, -0.013568811618146536, -0.0017938671818698087, 0.0015948022566835108, 0.04319840736469189, -0.10598051248568664, 0.0129118518767665, -0.00032886131524939, -0.05713540508376458, 0.049459335415908454, -0.012775442226324622, 0.0007618472190491222, -0.0007692114648751455, -0.0005831424600811557, -0.001178536054340704, -8.646739275101435e-07, -0.0001876727308034696, 0.002981262581505794, -0.0028907383590277983, -0.002164514730513493, 0.0013470042463331465, 0.0010315584126816804, -0.0005550542444478902, -0.0009918487611878812, 0.0011714564466137431, 0.0007048807277663886, -1.925405209220776e-05, -0.0003552387806851391, -0.0001821048004680568, 0.4835163151345828, -0.23574841806847352, -0.07191443020616832, 0.03547800926375701, -0.30569496561801973, -0.4035212163253605, -0.008976642193888532, -0.0023545821787357276, -0.00291582399255039, -0.0035076299632458845, -0.0027045591396741, -0.0035358488398249776, 0.0046993288266707145, -0.008346896745951626, 0.00214146835769886, -0.000540382318166774, 0.00021550241187718217, -0.0027818419108290703, -0.0015232614425440638, -0.00047542522214178627, -0.0011189435443348706, -0.00013059775764236316, -0.0001902800753879125, -6.119356010026586e-05, -0.003150350710909572, -4.976224107321918e-05, -0.005365038707551015, -0.004989797818930045, -0.0001460900304813138, -0.0002616479234360031, 0.0006517949971419677, 0.00016563047785634285, 0.00031557765543202917, 0.001060705739610079, 0.01182544786709455, 0.014306986029989508, 0.0024695194583847445, -0.007497681546081499, -0.01727645408583312, -0.016136873293325575, -0.006880439631586079, 0.008920521407721711, 8.270562450605214e-07, -0.013878341573274274, -0.0012237214992300404, -0.01938474577482918, -0.010789678507828852, -0.0130197628289531, -0.008264513860707002, -0.002790215918210279, -0.013436304792661547, -0.0024217286922469093, -0.0037076941774333723, -0.0018834075899049505, -0.00026191102699552326, 0.002997038801683805, 0.0025380415891759368, 0.0008893134362670154, -0.003498181900543204, -0.0016974733982281166, -0.0005021457414780731, -0.0023040864817087886, 0.002977560138388168, -0.00038618686165398666, 0.0017527314809876189, 0.00019878460153015078, -0.0009581479309948788, 0.0011016288911397006, -0.6515610049485671, 0.012579109106758333, 0.000637861317666249, -0.011856634905574136, -0.0023782194589870792, -0.0027372871742570547, 0.0006265713430432536, 0.00017838768975046807, -0.0015040527391703504, 0.002513175376442388, -3.6076960306546364e-05, -0.0004351958839490258, -0.0007805117306140925, -0.00048417509472416535, 0.0006821678390012698], [-0.0009280485220202437, 0.0071752541961860915, -0.007271835540151915, -0.012013506170121133, -0.006682680119687025, -0.01333195973824325, 0.0005097466411207832, -0.0004911674541592811, 0.0004889205193990631, 0.00016020695930647397, 0.0029016053094597454, 0.010956081076661671, -0.0011901222732616972, -0.0033901966348103257, -0.005277491885025321, 0.5667324803468318, -0.2482307976750081, -0.07758812289825219, 0.049625088454434065, -0.3637031871698978, -0.447904617835656, -0.010520138644673799, -0.0023702292052691187, -0.003329923178460199, -0.004039077199849398, -0.003241520776869508, -0.004004549913558004, 0.0012611448251500428, 0.001430509335341384, -0.002300564800682297, 0.0008087951156898598, -0.005292868274403324, -0.003751443895326452, 0.00034530560078912213, -0.0003865018721612901, 0.0002452628836777859, 0.00018871693189698703, 0.0004594355085202413, 0.000543407519018813, -0.21935493738671055, 0.08885222171628886, 0.013395108579150342, -0.0639826858343928, 0.11976604779525357, 0.09601401260099054, 0.0033085588992060435, -0.0004600493663214288, 0.0005275513686608458, -0.00025967226309583143, 0.00022704235996762323, 0.0007123113183343282, -0.002633103992093351, 0.0022699509579794143, 2.2076862335214225e-05, -0.0029664966982186894, 0.0002215133915272531, -0.00012811475156800187, 0.0004333336370862467, -0.00014236485280465284, -0.0012711071161430184, -0.0015926686307547243, 0.0034448717205180822, -0.0031826267097338507, -0.00011722041147034353, 0.0023718951400632203, 0.004130309891472391, 0.002014934967059057, -0.0009415590394681924, 0.0008048230472384974, 0.0007173868418669021, -9.455491091759486e-05, -0.00012830799892091856, -0.0007192763194799511, -0.010200081502369127, -0.0011526489626030414, 0.00016916398101549793, 0.0023164780358560103, 0.00019038720264987025, 0.0005185530072605132, 0.001422276041482154, -0.0009305061733082511, 0.001262929589880027, -0.002506830925678392, 0.010871730848895067, 0.008801546810748757, 0.0015223078284139862, 0.003339497235663967, -0.000456590878528375, 0.011659031962636882, 0.007989799356556629, 0.0023138942231177976, -0.0006386111415536638, -0.00018889655941495905, -0.0004728977938271781, 0.00017943528768185613, -0.00022415917573189353, -0.0008950785497353113, -0.00039031522444764956, -0.0006314910167787881, 0.0003424092454482605, -0.0027645955533934685, -0.0010939127756108076, 0.00029538817141587563, -0.0017385344546715406, 0.00011089698743168112, -0.0022519511908711642, -0.002698332469784163, -0.436065449825939, 0.00850571551396479, -0.005796964152547658, -0.007896572381848628, -0.010997909543250951, 0.0019553341184897033, -0.000308438205142306, -0.0010352248615050936, 0.000953042670545015, -0.0007855638302926349, -0.0011392388242829148, 0.00017042837152848382, -0.0007170273645458579, 0.000684531765358198, -0.00031275055090171036], [0.0006072127837060177, -0.021415216249615687, -0.00047226380993669616, -0.010120713520537103, -0.007878863392131355, -0.015069083602408847, -0.0007983692785344701, -0.0035142050245003413, -0.002412033742406084, -0.0004882268366620415, 0.0035546789547773574, 0.004540694778802681, -0.0021730646550149287, -0.00259725162658054, -0.040190542789286174, -0.32436927187242126, 0.04378446573802545, -0.10484709497151297, -0.06901293471224815, 0.20520574078586334, 0.33113081186799165, 0.006896149690974323, 0.002973850338214552, 0.0052531169517020665, 0.004372935506399301, 0.0035828327817226907, 0.0034710814461891113, -0.006090742518002213, 0.001099727983269958, -0.0009479777288789941, -0.004337119905316326, -0.0012451896076119818, -0.0037257704372467945, 0.0005137812768060795, -0.00018488044958208207, -0.00066788011937205, 6.537805723693592e-05, -0.00010666872051756555, 0.001321824837612414, -0.39017858916356557, 0.04319260160221599, -0.10778475344027415, -0.05530811400028516, 0.24078982178156388, 0.39149034550832396, 0.008485464390758223, 0.0034783381212192123, 0.006142325577019231, 0.0046096065574813255, 0.0037458489517056214, 0.004088402736521362, -0.00442738947868029, 0.0019503353358973944, -0.002504231618889276, 0.00045798091182455556, 0.0013401434587360054, 0.0013474650592032841, -0.0006565456821109442, -0.00047281754321868054, 0.0005967667938879683, -0.0017564727203361267, -0.007462572833621615, 0.0015166030996336204, -0.0019839816659062313, -0.0035691517912253327, 0.0006743815319378323, -0.002700597529471322, 0.0008427149573788337, -0.0002558504009925538, -0.0007099063858459541, -0.00010642350036625203, -2.3787909905232162e-05, 0.0006526684926084625, -0.0012690690722133233, 0.008562381584593092, -0.0036680179959943725, -0.004746560304159994, -0.0047350815282730975, -0.007567251318218396, 0.000507252911641679, 0.009789790445333367, -0.00018049475564973233, -0.006160688063098581, 0.007333231952859486, -0.0023094992412745945, -0.0037312730919802192, -0.002894127884396696, -0.0033849417973456095, -0.0022758268699109305, -0.0011502395797257634, 3.4428715076907473e-05, -0.0038819313894956483, -0.0009357096220784329, -0.0020521203812595493, 0.0005972589079891169, 0.0006442814432641055, -0.0009000375800539472, -0.0036369439340013954, -0.002125577992003272, 1.249741215485419e-06, -0.0018712262016151442, -0.0021015888672270386, -0.0011586248840060685, 0.00012735405236773242, -0.0014748902177794975, 0.00016295224231908196, -0.0013288268016495614, -0.5841697654869128, 0.011884630381772178, -0.0018770446214758563, 0.011986856962924718, 0.015445044694728868, -0.00022307908895089943, -0.0006950564443013585, -0.002411881785268322, -0.005194518576245858, -0.0019808055437084645, 0.0007223670689655298, -0.0002094388259741304, -0.0018903015426305352, 2.5915104119955918e-06, -0.00024332777292686351], [8.530739639589846e-05, -0.0005260227632563595, -0.003985387784327442, -0.005813652664729313, 0.004545809137111769, -0.000912944285252208, -0.0004062902970530748, 0.001628506049210199, -0.0014735936418000621, -0.00021705988307461335, -0.0023867763777033323, 6.833617571143561e-05, 0.0005220943685601555, 0.0007833638249372787, 0.00010481652493667736, 0.13148002263811334, -0.2950269768797618, -0.07798675758835098, -0.23307782111626815, -0.17011136849656866, 0.5186422331348567, -0.001543723230522817, 0.0008208878908636549, 0.0001455250361561496, 0.0004704875940169585, -0.0024844682796929586, 0.003885068472312456, 0.0017311119073836027, -0.001987911685567937, -0.005741438660531896, 0.0016817938889074095, -0.006081998247789139, 0.0001348330385752821, -0.0016554623437457048, -0.0002497218408338358, -0.0013201495046849274, -0.0018071702644876582, 0.00034465424123950554, -0.0007052280328505136, -0.1808860198703833, 0.34793303721380836, 0.10801403716026442, 0.2803981673600547, 0.12434920212653162, -0.5256488124738716, 0.002432965284594925, -0.0006670180359480308, -0.00039601372523468195, -0.0009691937484475562, 0.0015782819607288046, -0.004210908698386637, -0.001654003775011917, 0.007022857025791021, 0.00485351600701223, -0.0031953179112972157, -0.0026420415548941904, -0.0006205466495786063, 0.0010108502092626111, 0.0005108139752372873, -0.0012230752589508934, -0.0007386761547305913, -0.003846351310302308, 0.0013149435892255395, 0.00443968408961216, -0.0017084008622283613, 0.004859942226166391, -0.003656648738805606, 0.0011051461963956781, 0.0008693284794171284, 0.0011552461738902188, 0.0015033629904498344, 0.00014240655258741116, 0.0004969771069700129, -0.00714028788158474, -0.006865036307955529, -0.0001642510549064678, 0.002726148257933166, 0.007152768644625098, 0.0062200556839476975, 0.0025823288383785923, -0.008203106377851696, 0.007332473935527602, 0.004097322346655256, 0.0018639640673083389, 0.010032561271031712, 0.005954330520094849, 0.0011414196306909583, 0.0036104152121275994, 0.009498093658733562, 0.0037974582020233955, 0.0004526056806525927, 0.0012790455726027195, 0.00036888604647444925, 0.0004451228198758274, -0.0002072474592505407, -0.0009686712388224859, -0.0006477084850318213, 0.0016475838087732725, -0.00235351298477708, -0.0015959402188344036, 0.000756519891426254, 5.168966182475118e-05, -0.000353854088655873, -0.0006910881772244401, 0.0002175610706530976, -0.0003910149897570999, -0.0008810185538511618, -0.020883779284443297, 0.00029870906922768823, 0.00031545054182088975, -0.005326382866582107, -0.001893796805825103, -0.0003756331905640421, 0.0008257701409348036, -0.0005484579763458414, -0.0017813722129158137, -0.002783901723118494, 0.0006807100751065605, 0.0005122040373555638, 0.0005535190369851629, -0.0009633161843399454, 0.0010960643088161446], [-0.0006095978331139726, -0.010933959147673105, 0.001288792044090989, 0.006143781693966072, -0.002029068061308449, -0.007742455975823566, 0.0009803106887135537, -0.0012242661821829969, 0.0004195519536869745, -0.0007490345009061068, -0.013026632857149873, -0.008939507704569473, 0.0024992547449089403, 0.0023092902283657524, 0.017125735972223072, -0.1795848683218864, 0.406754510831506, 0.06778259957932181, 0.09898876911381715, 0.10332294120598867, -0.31964031143163557, 0.0036967863517525235, -0.0002556257801720305, 0.0009758304858433704, 0.0006649401899401794, 0.0011480201109186493, -0.0023202715449187608, -0.00861404308840511, 0.0019024252582585856, 0.0009573059869312733, -0.005394613116695591, -0.0029199929910068644, -0.009531241809997332, 0.002277209696097525, -0.0007592385123395774, 0.0005385958536895606, 0.00029195192672199345, -0.0002881619908540824, 0.0009802295992448913, -0.15117159693690216, 0.7391905450790108, -0.01839990000407976, 0.0022956236531256583, -0.2365180671206777, -0.1892035010079574, 0.003023299877530313, -0.0036983194906551084, 0.001189972774402172, -4.744577412830512e-05, -0.0019867818124418607, -0.0018213537683758343, -0.011085518362617145, 0.014876838385759738, -0.007935139046479281, -0.002574233465880766, -0.017994146314825942, 0.0010675997385222848, 0.0013837630402305265, 0.001098140603869078, -0.001096018533612037, 0.0014759269973647867, 0.001265775520532078, 0.0023073418194991574, 0.00039411606589579725, 0.0023191031475566512, -0.001375633240438329, -0.0002894716876099419, -0.0008024635601751457, -0.0015531141876797057, -0.0012076959623019629, -0.0013817939079504278, -0.0006381839058894459, -0.0002441256890437804, -0.0009775165754685948, 0.0015418190941914325, -0.010660340982604963, -0.006791366623901372, -0.003588655989495165, -0.00693341802085165, 0.0030315015961986883, -0.0023365145278503637, -0.00771980317041135, 0.0007748165033855434, -4.3101629460343007e-05, -0.0015085539899492176, 4.168145026294189e-05, -0.001487146517467947, -0.000976159612314435, -0.012848762555416544, -0.0041924421344782525, 0.00014473505789913856, -0.0016543917592072822, 0.0019110585965895232, -0.0008710681855835874, 0.000334666450769467, 0.0007549124407112032, -0.0005087553514909551, -0.0007674138715487173, 0.0017544941008983059, 0.00045906709839855847, 0.00029516060143420917, 8.615466165441686e-05, -0.00162971530921758, -0.0010458851318798504, -0.000550470234938557, 0.003891258631247572, 0.00038923923566600596, -0.1048135687233302, 0.002205349782853005, -9.70753268839294e-05, -0.01292782667567416, -0.014352655803677132, -0.0008444988219527663, 0.0013516658491712903, 0.002345136600250195, 0.0030680241682508875, -0.0018491634440853137, -0.0012750986998991234, 0.0005621042839329263, -0.0010244140467682169, 0.000752774629491193, -0.0010160952765821522], [0.0005768940066541657, -0.019922424787523502, 0.002786716785666693, 0.00487022209720698, -0.015134590872711417, 0.000604448592091123, 0.0006251757972402907, -0.000572337982735619, 0.002875868098422861, 0.00014927191344323192, -0.0027388117919145577, -0.01002897534984689, 0.0013925503451529826, 0.003160291471884654, 0.007112863944011416, -0.0828200365800097, -0.651746628872955, -0.001967900761543178, 0.31059471386600845, 0.6061146804516203, -0.23001044070648313, 0.0016962359354618566, 0.006568010196924794, 0.0017462423769636455, 0.0024779248807278737, 0.007233016865543005, -0.0013295601962238857, 0.0018341056518725236, 0.004533627690183625, 0.005534686609380259, 0.004086291140321406, 0.002462127824706525, -0.0007912636264436721, 7.330067431412765e-05, 0.0007263196054846238, 0.00036890634912436674, -0.00024553268728765004, -0.0009552810807595829, -0.001205589810975332, 0.002461902455808294, 0.1118252013841956, -0.0893525234482211, 0.13577375501914407, 0.05532887081076682, -0.07724709900412315, 0.00096074595756244, 0.000808208359038163, 0.0011221574460031397, 0.0003822957720838656, 0.0007785775898671706, -0.0009448857294863056, -0.0007313933399971942, 0.001063006526452872, 0.0015434048918148522, -0.0008959564566949445, -0.00030536288042326716, 0.001300594362339559, -0.0006223982458630013, 0.0014210043816176808, 0.00010433257180277963, 1.1378279893346047e-05, 0.021737951373025765, 0.004485041385472206, 0.0016572421927095514, 0.01542571788239715, 0.007484674384648196, 0.013495621440283233, -0.004097142039389039, -0.0010397868498755766, -0.0005040681363461282, -0.002386453171610434, -0.000567822643587575, -0.002346720200294615, 0.003490291199089062, 0.007055895552558565, 0.0018059151033781482, -0.0016408770287248133, -0.003276443736129891, -0.0019119076044096983, 0.0028264364170386153, -0.00024457190114175346, 0.0019563026864713408, -0.002188479486658266, -0.0024651542366780914, -0.004565013558961471, -0.00046392133281056514, -0.001662585052420533, 0.0009910112242611715, -0.004786499238759633, -0.0012300299433810665, 0.0006037653886528377, -0.001439893103334214, -0.000818098750566002, -0.0003067206937819371, 0.0025086030640394143, 0.0011963704044839478, 0.0005699634090797259, 0.0010630290098573969, -0.0003174342653254961, 6.237694367546305e-05, 0.0014090537186370639, 0.001965947296116937, -0.0002731542478165376, 0.0013746955502601562, 0.0008208816749819928, 0.0012174841520246882, 0.0008893430811551836, 0.02527296648962953, 2.3156987893735972e-05, 0.0017692891757738534, 0.008467844625518176, 0.021123131361105166, -5.061186439043388e-05, -0.0008392449043827702, 0.0007526329654922679, 0.014493321700044899, 0.007291562289518202, -0.002410855799915576, -0.0008133230594806583, 0.0002601333279613592, 0.0023004385164065795, -0.0005780099526492339], [0.00014208910539288434, 0.033457257556642986, 0.0021017833877635234, 0.014377720431068254, 0.0007770178006238876, 0.005993989720531459, 0.00024151664860318063, -0.0015399614500898687, 8.981074249280524e-05, -0.000349540928954998, -0.009642837651815082, -0.0066772277973853, 0.0025810142674820027, 0.0018451633877577948, 0.012659060494248245, 0.12511271468756827, -0.34148945384072715, 0.04256810605704169, -0.1774162396920026, -0.040247229441079814, 0.27615081180296364, -0.0027982006161198277, -0.00015440468395604368, -0.0014179573740206106, -0.000378741416567925, -0.0014338476728857855, 0.0025155092713823354, -0.014868028838460366, -0.0020169010168115415, -0.0032589219258949407, -0.011798822256907327, -0.0050682421229811345, -0.005833170212593082, 0.004180855277821485, 0.0009752400553120068, 0.0009181907003955686, 0.002995442459513047, 0.0014401084497877462, 0.0020280651100181503, 0.17900083792167898, 0.31153919882461634, -0.049406169279204284, -0.3295037265495969, -0.5951492421961599, 0.39680212988566904, -0.0037633762616184905, -0.006026561530190451, -0.0011162368922016462, -0.0024755227193524057, -0.007324329452571858, 0.002452977972069354, -0.006964022626887856, 0.006151779256128803, -0.011571225863057482, 0.000406061887102996, -0.01707660967937869, 0.0019235858369404835, 0.0010926602586922862, 0.0012713468963591796, 0.00029418437613176415, 0.0040244040029558436, -0.0005289142852557875, -0.0076206358276459515, -0.006596010989520097, -0.0060319249185668096, -0.004389128295895295, 0.0012727012545315287, 0.0009676666053277483, 0.000999352150374661, 0.0003816560776348212, 0.0012963641402445548, 0.0018201376354649045, 0.0014557881267362662, 0.002936638207461344, 0.0037360857237891103, -0.01101706743229048, -0.0072803230428051, -0.004337431544430985, -0.00496415551712, -2.3699788345415804e-05, -0.0023890824635907143, -0.010398939742717132, -0.0019304798539000107, -0.0005289870817239756, -0.008028099379240556, -0.0009841829415644422, 0.006362095294720542, 0.0005796093801949838, -0.0182563064223277, -0.006592831334075742, 0.0003027462581507378, 0.00022274465978442765, 0.0026883574626144105, 0.0006409499237128649, -0.0003666684678134197, 0.0004774803488705718, 0.00032840287617675424, 0.0004694703920802978, 0.0039992533286066926, 0.003576706068745038, -0.00162412192255898, 0.0012562367366094871, -0.0004159267930775737, -0.0014396135195827657, 6.4061735925661e-05, 0.004038893157391744, 0.0007979837816721229, 0.022515071287111, -0.0004540285093653161, 0.0004111365561319599, -0.00047848957918335266, -0.017087115154031128, 0.00027133742261328976, -0.0004188892964388726, 0.003822790036421915, -0.003154537521004874, -0.008552424510951256, 0.0010414453765470511, 0.002372274155483318, -0.0001529263520295142, 0.0002402534504443855, -0.002456697700493779], [0.00024342386749908276, -0.001379814032051356, 0.0017443442270418106, -0.0031426625359584196, 0.0006577296054628442, -0.0028568733469007553, -0.0006756714295025727, -0.0018775186410496206, 0.0008712105049074424, 0.0003236082344373666, -0.007427361835249262, -0.0025078879854808114, 0.0017535208466017257, -9.058244417936861e-05, 0.0090456310177402, 0.22630238875595468, 0.12676912685589867, -0.16491676254794801, -0.47657340686193866, 0.3644199949404625, -0.15771452955333126, -0.0007025410197103977, -0.0008773726275968483, 0.005759204595191377, 0.003369633490319608, 0.004009099557687475, -0.0008473058120866901, -0.0027084104168527087, 0.002084173085260011, 0.003541887703442006, 0.002756418169036722, 0.0055585252612692, 0.0013558302280752017, 0.0004922603784656814, -0.000607590043050169, 0.0003163886787038728, -0.00014296464799916906, -0.0003639345644050247, -0.0024835590048490805, -0.25487030965894947, -0.1866281358103158, 0.23481886499260876, 0.4667792024355116, -0.3610609691702361, 0.12285260522842678, 0.00033955631617147526, 0.0006145850634822383, -0.007456394697785508, -0.003086619964621762, -0.003967002024003553, 0.0004152553848661512, -0.009390434341511066, -0.007100697899994822, -0.001429768382332146, -0.00010196588195934889, -0.01836177481493161, 0.0007337298459753798, -0.0005060442134299606, -6.703404980537893e-05, 0.0006560278799063074, 0.0016008655129513471, 0.0022416301161056564, -0.005040394888012487, -0.00615208646010602, -0.007799183021900619, -0.009809789045505876, -0.0058397954233605906, -0.0008574911067256146, 0.0007021809417661175, -0.0004403808308319679, 0.00035160817622913214, 0.0012740958518169356, 0.0031376290421485727, -0.008134732836090697, -0.005804432376131162, -0.014078414311389157, -0.005424867512998418, 0.0023070608813837157, -5.286292435517096e-05, -0.00016129542923475505, -0.004650386674889083, -0.008912778065259431, 0.002955044981732537, -0.008195740912249835, -0.0035375615882804012, -0.0017581182614808074, -0.001649602844153863, -0.0019359587267053751, -0.015667609541264907, -0.004946577016653882, 0.0030614120406088643, -0.0011102057402247718, 0.0018397992503895537, -0.0006162919327303723, -0.002080396813310896, -0.0005499101669587416, -5.6815825328078636e-05, 0.002373580710470591, 0.0028458708201054674, 0.001199923869768129, 0.000669479514534613, 0.0011485535753906675, -0.0012468214736536527, -0.00017265865302174593, 0.00022069926102921095, 0.0023770613428973383, 0.0009134851226373402, 0.010489070645670515, -0.0006021864490825409, 0.0018308611034532432, -0.007282290175094145, 0.016871864900943383, -0.0009087634477409629, 0.00036387554879935215, 0.0007628295242466571, -0.0018782731483725631, -0.0017772727759465627, 0.0001218637940070365, 0.0009947981720360758, -0.0005075775049462894, 0.00047799590436144304, -0.0005872136330531569], [-0.0010557159972942789, 0.0036737620383988016, -5.1208628240272936e-05, -0.010408639811970304, -0.013405478655359303, -0.015347274547632623, -0.0017149873691164428, -0.0011364006597204166, -1.8497345561639886e-05, 0.00114634297886254, -0.007046238502394178, -0.0012903289448693528, 0.0012319075990623067, -0.0004227379357805416, 0.009451713671368434, -0.31751444249670335, -0.17796624933472957, 0.4812309353851296, 0.3115577536778664, -0.3502798025029732, 0.0016483917288690406, -0.00045731987395239643, -0.000626789293242385, -0.012129608267407005, -0.0036708516391860103, -0.0035249168806644497, -7.542073073581972e-05, -0.0017914536347851833, -0.005835702726517339, -0.0031294682599373397, -0.00298681932434612, -0.004114022028780784, -0.0031682386131568637, -0.00032175309100418355, 0.0016812283221570498, -0.00018415813090861253, -6.60148071849761e-05, 0.0004608229107862313, 0.002311820134704644, -0.25949728224801466, -0.1474624057124556, 0.31374511993569276, 0.3409656939304219, -0.30729255817827433, 0.09466333665141859, -0.0002640071555876546, 0.0006205581829725902, -0.00760633362223824, -0.0030000953486832155, -0.0034653620479980487, 0.0006405563180520729, -0.00871381700921107, -0.006861544588793022, -0.0015574682134200015, 0.0006538145385163649, -0.015915352080962217, 0.0007274221609413936, -0.00083516358887488, -0.0012032351871323482, 0.0009475335332051777, 9.167456035417395e-05, -0.002397195577794712, -0.00812347844428568, -0.004677831903390525, -0.007191524056285782, -0.011038833709099664, -0.0068007708627138615, -0.00046370816602864397, 0.000912410185791191, 5.026537110786308e-05, 0.0006754901808745759, 0.0010863767499383324, 0.002185351209208249, -0.008221648327809134, -0.009117505333090503, -0.007871588809309509, -0.0019349044769840177, 0.002983516876134375, 0.0001801151548478744, -0.0019381341644218667, 0.00013315972474809668, -0.002043266714065185, 0.0008350378232355672, -0.003680581572069368, 0.0012771466228154891, 0.0043518644826508876, -6.66043504402455e-05, -0.0027671053568961734, -0.00735076259473021, -0.00010274277745312651, 0.0019140298610645014, 0.0006322173483295327, 0.0005150563620302729, 0.00032716880862092556, -0.002169604487708412, -0.0007505114182674732, 0.000658206579340902, -0.0003550547903951255, 0.0019694376299372895, 4.3045797439177055e-05, -0.0006389469072116305, 0.0004899041137015341, -0.0022428632992624125, -0.0020253498800125664, -0.0009976260597252416, 0.0009792245609850114, 0.0009760001453873172, -0.07367553520233165, -0.0006217198985668959, 0.0032363152155152316, -0.03153083993007658, 0.020860891999012244, -0.0014742305382268721, 4.8495533417292835e-05, -0.0006464890958207211, -0.004836907756503204, -0.0024876010060451655, 0.0007539602905933243, 0.0010372662712451117, -0.0011445602688068314, 0.0003319358392735794, 0.00047044732609457596], [0.00020510989478240773, -0.00016328885006688747, -0.0006755607868840062, 0.0031501155858883107, -0.006489419143025676, 0.002372682481378795, -0.001100011414088405, 0.004261699216844813, -0.0032746661427552858, 0.0003403330486096008, -0.0033320670592890387, 0.0007573255070199805, -0.00045515569208943513, -0.0008953844288120679, 0.00841414403705116, 0.08662078630266291, 0.08991429929311748, -0.5109468605360338, 0.4746624837814371, 0.09487405329924217, 0.1752297935961226, 0.004046314702440895, 0.003857815823455887, 0.015479530015563228, 0.0026382259275022856, 0.0013180942969257992, 0.0020937315247868135, -0.0006733562433717421, 0.0022927359084407095, 0.003156098035006894, 0.0019342007322622117, 0.0035898748173503548, 0.0027254323207875505, 0.0008697257213105918, 0.0005121856466245714, 0.0008773394835695225, 1.4812857062210472e-06, -0.0005120380724018613, 7.240481826954563e-05, -0.12914305417024832, -0.09051835578129556, 0.5489827827311284, -0.27959731929248066, -0.19125108299554414, -0.11698808607212682, -0.0028395861272652962, -0.003922128088629199, -0.01588864686883299, -0.003096363140229519, -0.0023182653680264296, -0.0015379095638202189, -0.0039493731106295315, -0.001437470255471072, -0.015435045810356027, 0.004002970777501301, -0.005593846789086081, 0.0003820087320560833, -9.55165733370578e-06, 0.00029580533431933844, 0.001304689111410532, 0.0013845330254241644, 0.001714407296712178, -0.002662968865829846, -0.004547248151624978, -0.00017715722499848422, -0.002590001669440804, 0.0016984529234595664, -5.8939609844322725e-05, 0.0004136195100960076, 0.0006499132463584498, 0.0002691500800196171, 0.0011308611164807041, -0.00010789852941351162, -0.015963304427618893, -0.02007010828873939, -0.004802768184102622, -0.00014817476632767343, 0.008992644560614063, 0.004466320269239518, -0.0109104746710998, -0.012021065642893632, -0.009892475228420723, 0.011366283078697572, -0.01224185986245576, 0.0023701202751437596, 0.0008849836650497643, -0.0021832594407311685, -0.005379446047948103, -0.010221914920469465, -0.0014452900708166701, 0.0011366073804756197, 0.004122385563684764, 0.0009014812816501461, 0.0014030625714610975, -0.0013663489465694544, -0.0011165094369110962, 0.00011596253561194715, 0.002224609676161366, 0.0042546045682304474, 0.0005565187004507448, 0.00164292610336404, -0.0008161469266222364, -0.0006913944216056472, -0.0011963526061101338, -0.00013784958824757855, 0.0024008068741573417, 0.0013082157265952735, -0.027192976686258637, 0.0008054981652318621, -0.007335295215730107, -0.007425514300894529, -0.0023095742643989272, 0.0019354082983653483, -0.00046997945711705556, 0.0006454116563090743, -0.0009224480120565076, -0.003549207129170197, 0.00031965643079452053, -0.0005862409039136357, 0.00015559071490729481, 0.0007435714116650094, -0.0007892050111298897], [0.0030130666995614726, 0.053083914865139595, 0.00032240985655537276, 0.005895848376466808, 0.002873512044979196, 0.03852888670531941, -0.0010793257375559908, -0.006669450105587095, -0.005284714126205087, 3.6989547726124513e-06, 0.0012178972295243892, -0.0036145057714280907, 0.0019521305332871346, 0.002310977972132487, 0.007016102447133691, 0.13030519552860434, 0.12448080889412438, -0.37227806497063204, 0.4161008963316988, -0.1597649351463302, 0.1730144638287088, 0.0011459983149926698, 0.0011820273073544591, 0.008530439958346432, -0.0005618955098351718, -0.001796432678479896, 0.0014967336248861598, 0.006344896552025071, 0.004685224620620225, 0.0020080302937833224, 0.005619897995262084, 0.0040045798709984, 0.007989620386902213, 0.0017604090143543958, 9.274265673724512e-06, 0.0007439319422422796, 0.0006409560866285303, -0.0003190965803186673, 0.0008116944066676495, 0.12120031459817242, 0.0585628041370477, -0.4708651786970588, 0.5338715745307372, -0.1554063924486306, 0.20230050525737178, 0.0012528733098450687, 0.002556666633378672, 0.010964992436418264, 0.000588049511525192, -0.0019495553793731288, 0.0019945258858182447, 0.0019805323142361633, 0.0004908171541875619, 0.017749521254223962, -0.004228979756947815, -0.005980328737748311, -5.058071060090017e-05, 0.00024864406598620127, -0.00012155471529055931, -0.000698599760002748, 0.00026580669509568635, 0.005374833419487012, 0.00629048849849769, 0.0008135371049905599, 0.006214085124470023, -0.0006529219344500299, 0.006327353199100105, 0.0012788226835817225, 0.00018207266203839814, 0.0011010730233483761, 0.0006336016553679038, 0.0010706999510821588, 0.0008723008332642234, 0.011541801556012542, 0.020498719837531095, 0.0037855785296875793, 0.00208890520138478, -0.002757223469207444, 0.0024856950188901386, 0.010793119522469728, 0.006277299835567514, 0.007009714105420257, -0.009610991119644176, 0.009795550150496374, -0.002388934323750349, 0.0008621525326055397, 0.006085583537074603, 0.00966405484972341, 0.009801391783595655, 0.009625152944882734, 0.0008149230449196961, -0.0033830594997572776, -0.0002546587638354646, -0.001187174623725786, 0.0017295308019305228, 6.509484698727018e-05, 0.001599755634260138, -0.00018782700724958456, -0.0027869810799781044, 0.0017729178651304898, -0.001242312296137088, 0.0022634784158827143, 0.0002303410432393556, 0.002383536158994066, 0.0012883900922755207, -0.0024416823860567934, -0.002402274087802012, 0.02591867738002833, 0.0022117880737026635, 0.009190629007198815, 0.04587676931155154, 0.01978313276395853, -0.000731965796827916, -0.000999435995401056, 0.0017406212003720127, 0.009689728494375, 0.015957239807438444, 0.0011148633401261753, -0.000678070980963064, 0.0023915490364237956, -0.00028938337666700937, -5.2326870289419855e-05], [-0.00023444042376616028, -0.016123248435428054, -0.0028652212564100306, -0.049554729156707784, 0.05665761531086832, 0.0169770266203, -0.0009795377095981573, -0.0033932471728507804, 0.007463031014842161, -0.00017137564191203194, -0.01698445879115895, -0.012767172332763232, -0.0027031128480209557, -0.003631900324811509, -0.00199963509481529, 0.46197369670371147, 0.20464326333179678, 0.4585966346329664, 0.2367069072402861, 0.2826553283108741, 0.2655857922332491, 0.003976035357931337, 0.001968348972152619, -0.004063374115092761, 0.00025235164470338356, -1.2408738965765143e-05, -0.0004616367163597269, 0.0013203156875203432, -0.0011439212188687582, -0.003550096505884608, -0.00031412898485628566, -0.0025777944465278993, -0.0020168825808324037, 0.00021106568293893286, -0.0005355278529584502, -0.00048037833044475056, 0.0012420903140937033, 0.00046946412032161227, 0.000898192270605467, -0.31686611355761696, -0.1762382704751696, -0.3047176008934163, -0.16680199416380526, -0.15488892284124176, -0.19618013643323418, -0.0025428691388201577, -0.0015124651053725626, 0.0029021834606409937, -0.0009529384756055262, 0.00015761482806452628, -7.824172044182971e-05, -0.011342172723614055, -0.002353617046734765, -0.004430529767989528, -0.00852812436243639, -0.0030429688655471882, -0.002538267840024133, -0.0020710082935134757, -0.0010685523193445941, -0.00440912353359114, -0.004047940933987941, -0.0004593627640129782, -0.002624202873305714, -0.0014723973979476083, 0.0015451803585191874, 0.003595034888450999, -0.00013632022846025746, -0.0008282525164596118, 0.0008048552755806382, 0.0015313525571393552, -0.0003610276183191978, 0.0007019221245586711, -0.001005716250604652, -0.010822788882586799, -0.007350510466618183, -0.009612596836058189, -0.010191991557478342, -0.016577004081381918, -0.01858301069902672, -0.020035409051877045, -0.018002857522128272, -0.010616879228724072, -0.01560433561089427, -0.008051394825137502, -0.013392948398073572, -0.014932136189060294, -0.014121813872542145, -0.010103046194096807, -0.011553022852007376, -0.020316376767473176, -0.002381303477649678, -0.0041269654422063495, -0.0059713417963390926, -0.004344133409741601, -0.002365355720704639, -0.0025721600702039984, -0.0011657475287657122, -0.00048208558315999153, -0.004455194283596656, -0.0032531623788968167, -0.005875922054112406, -0.0033520961938549028, -0.0030003638728362866, -0.0019796195101293625, -0.0052724051446730365, -0.0030246084049228967, -0.0014420263727707358, -0.026404956741904843, 0.0030728243802578543, -0.02003512783818342, -0.030791555668315547, -0.0213890420850038, -0.0003554531487622853, -7.246414366427987e-06, -0.0034275513206329157, 0.001671356149749072, -0.003799078550757315, -0.0012125211708834001, -8.047602891175163e-05, -0.0012848940724870695, 0.0005521441957940603, -6.994759693194681e-05], [-0.0009490279990735855, -0.03406269749397484, 0.0005971719363799085, 0.04660920741675815, 0.02743923980555917, 0.13124443597308594, -0.002637061484072295, 0.011066914201217729, 0.008243028559626189, -0.0017481304584970412, 0.03699451042797086, 0.02781630867045107, -0.00037849005077840567, 0.0012100040504146314, 0.0017996619369318818, 0.30543296383245644, 0.16339820392950652, 0.30730511094401053, 0.12881027930916808, 0.1993261273734785, 0.1732401059799933, 0.00324876903333919, 0.0009713854064457569, -0.0009486688683925887, 0.0006035862656878111, -0.00018544220041041598, 0.0004870462608971353, 0.0012954953075573566, -0.00016362061550764456, -0.003053839786487747, 0.001940509336887568, -0.0012452329226831232, 0.0034419349658217973, 0.0016236947831355126, 0.0015021500368716683, 0.0013911500558349717, 0.0023381457703224324, 0.0004645237629321794, 0.00015595867810082252, 0.44682613433892293, 0.23117301559569736, 0.4255690795363092, 0.23106643447141206, 0.2863173265768595, 0.2724055716111161, 0.0047434463513017985, 0.0018715227018043794, -0.0022079802418639985, 0.0002875934933150074, 6.463031068886673e-05, -4.997786590756624e-05, 0.016221671789820886, 0.005616536376876458, 0.008993027992330182, 0.010025658488849268, 0.0072643920013817425, 0.002518311824931152, 0.002748027611675043, 0.002582992437249424, 0.004082039985088236, 0.00409423083182689, -0.002025220949376927, -0.002775582395212254, -0.0037502008464871993, -0.003395759914292098, -0.0032518652315541856, -0.0035674077367930162, 0.0007531395714517233, 0.00044633394090593453, 0.00015097407743462263, 0.0017166741735702804, -0.0004030308076396135, 0.0007582953173664778, 0.013178700597265756, 0.031847475903502495, 0.015235181180832818, 0.010235839161873768, 0.01360041242988891, 0.016013458871999165, 0.017484777174925806, 0.043691334234511145, 0.024637289485919582, 0.012905848035038168, 0.03373759383229018, 0.013302922299697201, 0.012189149574825682, 0.017182619709454835, 0.009128003032338747, 0.025598578133247958, 0.024235848591581937, 0.004996872064092406, -0.001557033904406531, 0.006183257740527204, 0.005444605869864739, 0.006907770116184986, 0.00448558716524821, 0.0027295799462836758, -0.00513307191909944, 0.0016788510943795572, 0.006366657491057697, 0.0005950396517587822, 0.006995650192223766, 0.004200857669009511, 0.0016135644073852404, 0.006525117993034245, 0.0019866279971402635, 0.0020579329380598496, -0.14339941821306115, 0.0188263917869154, 0.02656465316882193, -0.03091731243646611, 0.007917064355227476, 0.00149767974673998, 0.0019829982042959826, 0.0019544494635752615, -0.002044202580358602, 0.0018859918343036325, 0.0015329143191039364, 0.00124417092489195, 0.002382273788107483, -0.0004557741999151123, -0.0007610858343566671], [-0.027453842557517826, -0.7058187228250302, 0.0006161000686413574, -0.10307523610953107, -0.08853719569892667, -0.0690396200402783, 0.005762479732125637, -0.0001783875410824847, 0.004402205588047943, -0.0010097506541545656, 0.010346266142917997, 0.029057489503371357, -0.004446307947866922, -0.007593017151013968, 0.004590287956189236, 0.0004676277059358493, -0.009630405840513246, -0.05871060859487068, 0.008708662137179801, -0.030186049509677914, 0.008197094867844484, 0.0004774029599601678, 0.0006456947524725767, 0.004176739577061982, -0.005234457123066164, 0.0005420229533114962, -0.001881450019867594, -0.03358172262080439, -0.004225435087051288, -0.009528757785947667, -0.025750969385397834, -0.014038159026392426, -0.011270522809131914, 0.0010389575453882817, -0.006354797209151304, -0.005812752228341743, 0.0001428821221653013, -0.0021000991450442286, 0.004260847833959638, 0.026291808046935997, 0.0034215257510736624, -0.04709459235190644, 0.02236699062188569, -0.010026774899160311, 0.026336584482051697, 0.0018095270181178297, 0.0009200172825406688, 0.006166908491469548, -0.004226361044883292, 0.0011162792551675244, -0.001419160250651907, -0.03013450676118959, -0.020824097899090774, -0.023151339642775007, -0.013053256565545374, -0.03900556286405197, 0.006358709017020303, -0.00465655145211613, 0.0025427039393424683, -0.00585100254356691, 0.0038019518250306597, -0.04134858089311032, -0.02568491930774032, -0.024652789568887737, -0.03975030070263845, -0.03319388331521975, -0.035781526409732305, 0.0016545372715162762, -0.004021579365762843, -0.003941395104964605, 0.003880720316594954, -0.00032956685890103455, 0.007185066317128268, -0.0036624918157207803, 0.01360552715571722, -0.00452514799352407, -0.027109369329998162, -0.03510036958040616, -0.045858719194351194, -0.01990670203835933, -0.005269979712010305, 0.01425663285748016, -0.01611117905903058, 0.006145652052890601, -0.017596352069059202, -0.008032588104338928, -0.013874417422589849, -0.022817942022217687, -0.03076539808388228, -0.00997682545187901, 0.005393431145091276, -0.0018306672238200775, -0.005477141056455282, 0.000552724776654244, 0.004349891290123567, 0.0069549946002563515, 0.006094405384222261, -1.9946240579284825e-05, -0.0033290833838374354, -0.006520209796846307, -0.002830391236082521, 0.002980068772834601, -0.006425676773163702, -0.005327267291970247, -0.006372575519905429, 0.007067570093917753, 0.0038558344426005992, 0.026488176316410927, 0.000748834510187344, -0.020350480143481686, -0.6615030911857214, -0.01621069607448307, 0.0033200931674016074, 0.010905789575455224, -0.009986756398816316, -0.035221894317725135, -0.07935892999707637, 0.0010370814503873446, 0.010566228153344745, -0.012031091193318386, -0.0027182913387501844, -0.0018512264294620435], [0.0005642580258448905, -0.13791341087699951, 0.0018655114785219272, 0.031174593676801487, 0.03367785805414886, 0.07064595693949353, -0.004155139531478775, 0.015558570626887109, 0.01645888570994755, 0.0029955203549980433, -0.019159723835014218, -0.006263112716910013, 0.0071848839539192175, 0.004015098875938771, 0.003356211315463839, -0.004480798542550917, 0.010554853022031588, 0.007284684038390965, -0.02553653521281334, -0.02482280291498247, 0.009099990302603233, 0.0024783515147130866, 0.0029681010389544056, 0.004040457886303268, 0.004076453106847891, 0.0015349427658055772, -0.0006855799036218177, 0.14609973200422013, 0.0931895361141729, 0.09296553583574473, 0.12969132119931384, 0.10593756999135522, 0.17605494679914976, -0.010748620468429233, -0.00043062790524572424, 0.004130417295481569, -0.013482326090144525, -0.006029278840078856, -0.01963758746111265, -0.02114692306300803, -0.00610437027075865, 0.005793237849655585, -0.028958885202437244, -0.03455792020589875, -0.004123727872219125, 0.005417032975873124, 0.0007240498176647766, 0.011220814449388872, 0.0025632601896056484, 0.0023222594067990672, 0.0017134530877402985, 0.031696996951407506, 0.015751024062620633, 0.043256916275179226, 0.020213977622235965, 0.01739955132302822, -0.006899622393483917, 0.0012205478426553587, 0.0007053674243917838, 0.0058036640139508796, -0.006090835490928156, 0.2962927563252309, 0.21474815322229637, 0.18826955388550407, 0.2999553144086697, 0.2339511438983045, 0.41583594598376794, -0.03255560435855747, -0.005538221825254805, 0.0010497798942213051, -0.0333014619255395, -0.014147310937982311, -0.04756723516595269, 0.06362525057396533, 0.05393867553759539, 0.03547736189343259, 0.024270037432853685, 0.024875703566376594, 0.02573332210526073, 0.035037897698496585, 0.040230877569984426, 0.04064182788070475, 0.03138511316515549, 0.01911074673008433, 0.029198938975220693, 0.011771855991525984, 0.0387955257643872, 0.030837532259402393, 0.01753669895258875, 0.034543081237637614, -0.008623433382866199, -0.011738209070568127, -0.004008985400300629, -0.000202532567289388, 0.0025594659704740413, -0.0021196717157805026, -0.008004318841625934, -0.010979886411622312, -0.0077347489183500345, -0.010705308472128755, -0.0035226893434066875, -0.009688452928494979, 0.0008213840060709003, -0.007154660560717736, 0.00041532245961984563, -0.003319618467123865, -0.008340222219981703, -0.008714341991274981, 0.004706327283818795, 0.0488538078180744, -0.06405802271762942, 0.28211234686601394, -0.016800402731574203, 0.0008120834403887612, 0.017820900376381957, 0.3803551888013346, 0.3373333792434509, -0.04898820624299344, -0.04611667188524123, 0.04772479386228814, 0.02541157059506161, 0.008779590331280515], [-0.005285568063768551, -0.006569510333856483, 0.00017329721510839948, 0.19486881998438102, 0.1709207361076072, 0.34448661445683687, -0.020662162746091263, -0.006940514279189136, 0.004765642533361633, 0.001154191343753748, 0.027181229650864235, 0.05829817160974486, 0.0004695321467647329, -0.009110123314573894, 0.0007901950314582047, -0.04533573125450392, -0.02387599825530268, -0.0191102684706087, -0.009806003200508484, -0.013517701677097958, -0.013466740128937008, -0.0091002887130306, -0.005322907739338005, -0.006044332897616734, -0.00576971768330857, -0.0040525736161313945, -0.003774324064330574, 0.11655678977301659, 0.0993998991878621, 0.09582800180247436, 0.11032779897404957, 0.09932992111146345, 0.1580550985364598, -0.004642890966102982, 0.001419447786360091, 0.0033081051356933754, -0.007701478370644149, 8.197086199735388e-05, -0.014295462934167861, -0.023306578970393906, -0.021803951078592638, -0.006204321726748619, 0.021046225716693127, -0.003412366927495648, -0.00021136190210983407, -0.011885568077484424, -0.006820677102145746, -0.0073193260418793725, -0.003866936235766122, -0.003671404952412135, -0.0017181098429362254, -0.03871130185764038, -0.005523974497314745, -0.030647587814631363, -0.022343585000729086, -0.009118782745128694, 0.006950423958099455, 0.003073674207928768, -0.002065712442646821, -0.0016439778144090415, 0.0007364038698019693, 0.09730809755111004, 0.07883384634601287, 0.06193998863572837, 0.07947828501234479, 0.07063853862781942, 0.05198329998679568, -0.0016642871342417165, 0.0022345410676305557, 0.004510615732632501, -0.0027192745126818976, -0.0013689917642176518, 0.008888030091925967, -0.05133668914469271, -0.014229156034307815, -0.03074475806139841, -0.05374320158787009, -0.0416244515349086, -0.06064305022011956, -0.0262085330425555, -0.042889408960009874, -0.09721391631451959, -0.008702547629724782, 0.002837566104145075, -0.04987121835592062, -0.031178528688908715, -0.06293713366290929, -0.022189570613415623, -0.043043790308059784, -0.04413371675122666, 0.015628952659227507, 0.005868561459392945, 0.016598374839893855, 0.01328079825756476, 0.003555803122733377, 0.014409345324054914, 0.017278854087650685, 0.01995084216221659, 0.03210889253206549, 0.007964947930119683, 0.011576774853904542, 0.013278284322935492, 0.004542690549471886, 0.007984844286769393, -0.005640965315544331, 0.02522592311172792, 0.01229459236911959, -0.01278603148876457, 0.010595038961853707, -0.032863020713230745, -0.0718969867814592, -0.7910146872014909, 0.01958530862224753, 0.004097861128527922, -0.02072846890966901, 0.08281653124160428, -0.07845856948409874, -0.0030572797908703406, 0.02767402193520026, 0.020185883739528086, -0.00883940809808602, 0.005313856433288718], [0.006554579288928523, -0.13158931007091884, -0.003152481244864711, 0.38569849189010186, 0.34114372336634324, 0.5679557691423219, -0.03740460511937583, 0.023347101528339315, 0.011506080008406265, 0.0009677210671864174, -0.07317106790092631, -0.03544501604840979, 0.02660373846552691, 0.01896022861079802, 0.0008116287691804074, -0.03592182968470362, -0.02634236934126691, -0.02193575389190776, -0.01965989957675859, -0.027656935214162848, -0.03396891293306334, -0.008255152538548326, -0.0007940470099553852, -0.0010640862961136279, -0.0019062299957956687, 0.001513596671899967, -2.7460531871277253e-05, 0.09590844463615274, 0.05370714492823562, 0.05113941060000957, 0.07590367080914591, 0.07900488059674819, 0.14883754384925846, -0.01939189225690643, -0.0033868471248848613, -0.00307529974147266, -0.0097295751042233, -0.005215069271681329, -0.0047603608798102316, -0.049152905756891345, -0.022015193234088067, -0.044636831685764766, -0.04428864671266532, -0.035735640373178716, -0.043988469874320896, -0.004145877013566133, -0.00039449539609878867, -0.0007511377556981571, -0.0067685306453758925, -0.000765244186241148, -0.005462044224324784, 0.04086989701201369, -0.016101944387852396, 0.012883373708172134, 0.001418595759709608, 0.004834303257955407, 0.0014996991606862635, 0.0011577388164673102, 0.00854905738135933, -0.0015476917900333915, 0.003489299450276444, -0.13758662890403134, -0.09520076656405571, -0.07505501413535057, -0.14745823876982111, -0.1189355666056309, -0.12196419229703453, 0.027179535960481574, 0.00371877293571345, 0.0014854235886254561, 0.027728721958390577, 0.009549003904546792, 0.022564770290032177, 0.012534517475678372, -0.024201525073331197, 0.03444187637553375, 0.013981888089013602, 0.04665217742169565, 0.05286589103945058, 0.0713852720088664, -0.05915216829840602, 0.03912723450461752, 0.04173248884955203, -0.08146650756458387, 0.023573184131458865, -0.0013360094267551885, -0.013052428116116838, -0.004403507244856124, -0.0479366453414975, 0.0917923667943701, 0.008010607217553235, 0.013909651526368534, -0.000986022034459115, -0.002053380554048978, -0.0037502618970303558, -0.002831216348691319, -0.013298526390972589, 0.018886944436947464, -0.0053569546065652856, -0.0005099873384956504, 0.028348595364866336, -0.002775899192874017, 0.001846452653053828, 0.014463178438836597, 0.012171308734241743, 0.01455954752245202, -0.014301994992680277, -0.020004763337819555, 0.012624371127630516, 0.041439864789657006, -0.011952735400611897, 0.4002213605393072, 0.006638050671228457, -0.0006869868236454863, -0.004436334208480625, -0.16223432547713365, -0.04793061940696418, 0.027410852077865734, 0.004344994030009611, -0.016985663174553817, -0.010989334778938611, 0.008011275563929976], [-0.004856847093610772, -0.04041855220934778, -0.00218855270173911, 0.2059381508563459, 0.08846721196800648, 0.2762716045407131, -0.018032084080811542, -0.002480221735609177, -0.00839073294031377, -0.00407656088970064, 0.0018267801230560162, 0.005296487063202299, 0.007994425332002661, 0.003813880421091535, 0.0015693600310652221, -0.024546091317004633, -0.004541596024915626, -0.018777874449325816, -0.009320601571051674, -0.0020344361686714433, -0.013039776093290465, -0.006062761955904585, -0.006569416548672249, -0.008848153376243912, -0.006389790542188923, -0.0035885935703553985, -0.007888230591161576, -0.3382147072077267, -0.21931825659539708, -0.23804122405132774, -0.33521832170860355, -0.29716637471211255, -0.47077942286773655, 0.05235551317072396, 0.006726970009998767, 0.0015618909241998644, 0.050037493585841614, 0.01932017741034854, 0.045614244792821314, -0.03322342702328193, -0.04157416849596941, -0.028041584104578333, -0.011682865811911546, -0.029859170535654084, -0.02993972335180079, -0.009738929530456145, -0.004617961823501428, -0.004451626714707838, -0.007748188114047133, -0.0016181287719527911, -0.0006102729835357391, 0.006309073392430781, 0.022300741606226603, 0.02434275524663295, 0.007641332519832688, 0.024993345306195236, 0.002577021258325178, 0.00820006774145736, -0.0005178142425250243, 0.0040815742908721885, 0.0005621156922088593, 0.1094514873806116, 0.061373369453013915, 0.06311566136447139, 0.08812189257436231, 0.10088983270144243, 0.15676590605907276, -0.02862831568851863, -0.011827469409738441, -0.009546395419221018, -0.02075687480715725, -0.012811713588234847, -0.017092558296563348, -0.057333369864290995, 0.02345667326029633, -0.011190896458755277, 0.05177963740230723, 0.11894969970057181, 0.12965881800365753, 0.0448200865241739, 0.06692426705026827, 0.04632828173086444, 0.05574191382201447, 0.0915285234549872, 0.13830046285158182, 0.07927106418920066, 0.09957095409063521, 0.06682188662093642, 0.10158235947758537, 0.10817193319850359, 0.008876025626704327, 0.0051942542159021405, 0.0060909235981944695, 0.0043701098869339, -0.012305795012853301, -0.021416066741209053, -0.004331642517489149, -0.018990891795881933, -0.007311381849197559, 0.00147718240118113, -0.020360248771925892, -0.022254982278011964, 0.0059265185331875865, -0.01652316023023814, -0.0029703514331270403, -0.012568527050961575, -0.021259693967690427, -0.008408727158841264, 0.009489947221097127, 0.06503680158924387, -0.0483361028168575, -0.08899225025393763, -0.01671832069037795, 0.001799396411633094, 0.014003100120566409, 0.08885144329263736, -0.029170404079485877, -0.028096896521836657, -0.00354846847709236, -0.02181679244701719, 0.012550617077613617, -0.02836024230961005], [0.003626255505010598, 0.0022239424630687, 0.022354635785845213, 0.1865337447438782, -0.009055617608603787, -0.026025651067961498, 0.004766852994835092, 0.00930473476888549, -0.001738633881543171, 0.006567371717176766, -0.29371795590407745, -0.2037536829586579, 0.05974311044559706, 0.04303672109447247, -0.000982342967901105, 0.023305516076839568, 0.00777243114683934, 0.0056496751055959745, 0.0043198329583093685, -0.020646832608507987, 0.010925054330968366, 3.659616045612781e-05, 0.0027063112067875717, 0.0032515751303573734, 0.00014894599779487002, 0.0023299667980468206, 0.0009288691612341311, -0.13964218724785785, -0.07724615171042103, -0.06315631220193123, -0.11066043005300948, -0.08719239197550496, -0.12722920553950495, 0.02859995035265941, 0.006277940376465051, 0.0025977956590502414, 0.020793376065519828, 0.005629982081874708, 0.016610468894706264, 0.049693003722657746, 0.01802706294678746, 0.024485316429561674, 0.034675819248334, 0.07169743329834041, 0.03151910213393629, 0.0032571900457498758, 0.012137826223923344, 0.0034656927374600932, 0.009468647096509006, 0.0012742191201020072, 0.0013055917481153883, -0.048609471571535764, -0.06857296354687137, -0.09434380840576917, -0.024762766859453212, -0.10252158497583308, 0.0010878700333534646, -0.01621712671515927, -0.000857041037995405, -0.013295798545379949, 0.0065838408987765355, 0.11694489249880448, 0.023550942365170045, 0.01110312193370214, 0.05228536898250959, 0.019849233608276312, 0.06740852311842889, -0.01288663605514516, 0.0027882348471335136, 0.0027210139740363125, -0.00551915133895374, 0.0010547926235626465, 0.004603852731908304, -0.10540109788700314, -0.24619253559713059, -0.12951315833987664, -0.15174163153887973, -0.1977278667426491, -0.20448660372813346, -0.08817905893030828, -0.20084431363809802, -0.15287874217501377, -0.03393256674002234, -0.29228921905729977, -0.21837702001414439, -0.14675274118171938, -0.22595291661444808, -0.15608008580892097, -0.3190298652372742, -0.22237294855128534, 0.007895751714666614, 0.044678149152421714, 0.022719428167883523, 0.0049667901318959685, 0.022856648114050023, 0.04084255252332866, 0.015174556290968167, 0.04070189146071708, 0.029621761868094253, -0.0052745494270026476, 0.06465858626999896, 0.027679020834178093, -0.020133937350285205, 0.03166604047711351, 0.009869051848858296, 0.06286300424654713, 0.040530482487363684, -0.005335197424175112, -0.013001402938991845, -0.050425036444632525, 0.024744002221151366, 0.12344259393648115, 0.011365504387511194, 0.0026490879882473243, -0.002182708241940177, 0.11829208950651991, 0.04535750782282486, -0.010825063637609305, -0.0005547765976304784, 0.00960419053325439, 0.01656172471299302, -0.012312904558249396]])
    explained_variance = np.array([6058.720042384061, 1086.1950151059002, 1067.5402069549418, 922.33502269886, 621.2514872204996, 557.6017085816206, 549.2972185227105, 527.6367771038994, 401.1535625094648, 382.6068353800439, 359.7605232553832, 354.6891835593702, 229.51458033929546, 206.07766592296022, 55.6773161623405, 44.504825846506115, 25.164507537875558, 23.858655681282016, 21.25931279550789, 18.604246675287666])
    X = X - mean
    X_transformed = np.dot(X, components.T)
    return X_transformed


def __convert(cell):
    value = str(cell)
    try:
        result = int(value)
        return result
    except ValueError:
        try:
            result = float(value)
            if math.isnan(result):
                raise PredictorError('NaN value found. Aborting.', code=1)
            return result
        except ValueError:
            result = (binascii.crc32(value.encode('utf8')) % (1 << 32))
            return result
        except Exception as e:
            raise e


def __get_key(val, dictionary):
    if dictionary == {}:
        return val
    for key, value in dictionary.items():
        if val == value:
            return key
    if val not in dictionary.values():
        raise PredictorError(f"Label {val} key does not exist", code=2)


def __confusion_matrix(y_true, y_pred, json):
    stats = {}
    labels = np.array(list(mapping.keys()))
    sample_weight = np.ones(y_true.shape[0], dtype=np.int64)
    for class_i in range(n_classes):
        class_i_label = __get_key(class_i, mapping)
        stats[int(class_i)] = {}
        class_i_indices = np.argwhere(y_true == class_i_label)
        not_class_i_indices = np.argwhere(y_true != class_i_label)
        # None represents N/A in this case
        stats[int(class_i)]['TP'] = TP = int(np.sum(y_pred[class_i_indices] == class_i_label)) if class_i_indices.size > 0 else None
        stats[int(class_i)]['FN'] = FN = int(np.sum(y_pred[class_i_indices] != class_i_label)) if class_i_indices.size > 0 else None
        stats[int(class_i)]['TN'] = TN = int(np.sum(y_pred[not_class_i_indices] != class_i_label)) if not_class_i_indices.size > 0 else None
        stats[int(class_i)]['FP'] = FP = int(np.sum(y_pred[not_class_i_indices] == class_i_label)) if not_class_i_indices.size > 0 else None
        if TP is None or FN is None or (TP + FN == 0):
            stats[int(class_i)]['TPR'] = None
        else:
            stats[int(class_i)]['TPR'] = (TP / (TP + FN))
        if TN is None or FP is None or (TN + FP == 0):
            stats[int(class_i)]['TNR'] = None
        else:
            stats[int(class_i)]['TNR'] = (TN / (TN + FP))
        if TP is None or FP is None or (TP + FP == 0):
            stats[int(class_i)]['PPV'] = None
        else:
            stats[int(class_i)]['PPV'] = (TP / (TP + FP))
        if TN is None or FN is None or (TN + FN == 0):
            stats[int(class_i)]['NPV'] = None
        else:
            stats[int(class_i)]['NPV'] = (TN / (TN + FN))
        if TP is None or FP is None or FN is None or (TP + FP + FN == 0):
            stats[int(class_i)]['F1'] = None
        else:
            stats[int(class_i)]['F1'] = ((2 * TP) / (2 * TP + FP + FN))
        if TP is None or FP is None or FN is None or (TP + FP + FN == 0):
            stats[int(class_i)]['TS'] = None
        else:
            stats[int(class_i)]['TS'] = (TP / (TP + FP + FN))

    if not report_cmat:
        return np.array([]), stats

    label_to_ind = {label: i for i, label in enumerate(labels)}
    y_pred = np.array([label_to_ind.get(x, n_classes + 1) for x in y_pred])
    y_true = np.array([label_to_ind.get(x, n_classes + 1) for x in y_true])

    ind = np.logical_and(y_pred < n_classes, y_true < n_classes)
    y_pred = y_pred[ind]
    y_true = y_true[ind]
    sample_weight = sample_weight[ind]

    cm = coo_matrix((sample_weight, (y_true, y_pred)), shape=(n_classes, n_classes), dtype=np.int64).toarray()
    with np.errstate(all='ignore'):
        cm = np.nan_to_num(cm)

    return cm, stats


def __preprocess_and_clean_in_memory(arr):
    clean_arr = np.zeros((len(arr), len(important_idxs)))
    for i, row in enumerate(arr):
        try:
            row_used_cols_only = [row[i] for i in important_idxs]
        except IndexError:
            error_str = f"The input has shape ({len(arr)}, {len(row)}) but the expected shape is (*, {len(ignorecolumns) + len(important_idxs)})."
            if len(arr) == num_attr and len(arr[0]) != num_attr:
                error_str += "\n\nNote: You may have passed an input directly to 'preprocess_and_clean_in_memory' or 'predict_in_memory' "
                error_str += "rather than as an element of a list. Make sure that even single instances "
                error_str += "are enclosed in a list. Example: predict_in_memory(0) is invalid but "
                error_str += "predict_in_memory([0]) is valid."
            raise PredictorError(error_str, 3)
        clean_arr[i] = [float(__convert(field)) for field in row_used_cols_only]
    return clean_arr


def __classify(arr, return_probabilities=False):
    h = np.dot(arr, w_h.T) + b_h
    relu = np.maximum(h, np.zeros_like(h))
    out = np.dot(relu, w_o.T) + b_o
    if return_probabilities:
        exp_o = np.zeros((out.shape[0],))
        idxs_negative = np.argwhere(out < 0.).reshape(-1)
        if idxs_negative.shape[0] > 0:
            exp_o[idxs_negative] = 1. - 1. / (1. + np.exp(out[idxs_negative])).reshape(-1)
        idxs_positive = np.argwhere(out >= 0.).reshape(-1)
        if idxs_positive.shape[0] > 0:
            exp_o[idxs_positive] = 1. / (1. + np.exp(-out[idxs_positive])).reshape(-1)
        exp_o = exp_o.reshape(-1, 1)
        output = np.concatenate((1. - exp_o, exp_o), axis=1)
    else:
        output = (out >= 0).astype('int').reshape(-1)
    return output



def __validate_kwargs(kwargs):
    for key in kwargs:

        if key not in ['return_probabilities']:
            raise PredictorError(f'{key} is not a keyword argument for Brainome\'s {classifier_type} predictor. Please see the documentation.', 4)


def __validate_data(row_or_arr, validate, row_num=None):
    if validate:
        expected_columns = len(important_idxs) + len(ignore_idxs) + 1
    else:
        expected_columns = len(important_idxs) + len(ignore_idxs)

    input_is_array = isinstance(row_or_arr, np.ndarray)
    n_cols = row_or_arr.shape[1] if input_is_array else len(row_or_arr)

    if n_cols != expected_columns:

        if row_num is None:
            err_str = f"Your data contains {n_cols} columns but {expected_columns} are required."
        else:
            err_str = f"At row {row_num}, your data contains {n_cols} columns but {expected_columns} are required."

        if validate:
            err_str += " The predictor's validate() method works on data that has the same columns in the same order as were present in the training CSV."
            err_str += " This includes the target column and features that are not used by the model but existed in the training CSV."
            if n_cols == 1 + len(important_idxs):
                err_str += f" We suggest confirming that the {len(ignore_idxs)} unused features are present in the data."
            elif n_cols == len(important_idxs):
                err_str += f" We suggest confirming that the {len(ignore_idxs)} unused features are present in the data as well as the target column. "
            elif n_cols == len(important_idxs) + len(ignore_idxs):
                err_str += " We suggest confirming that the target column present in the data. "
            err_str += " To make predictions, see the predictor's predict() method."
        else:
            err_str += " The predictor's predict() method works on data that has the same feature columns in the same relative order as were present in the training CSV."
            err_str += " This DOES NOT include the target column but DOES include features that are not used by the model but existed in the training CSV."
            if n_cols == 1 + len(important_idxs):
                err_str += f" We suggest confirming that the {len(ignore_idxs)} unused features are present in the data and that the target column is not present."
            elif n_cols == len(important_idxs):
                err_str += f" We suggest confirming that the {len(ignore_idxs)} unused features are present in the data."
            elif n_cols == 1 + len(important_idxs) + len(ignore_idxs):
                err_str += " We suggest confirming that the target column is not present."
            err_str += " To receive a performance summary, instead of make predictions, see the predictor's validate() method."

        raise PredictorError(err_str, 5)

    else:

        if not input_is_array:
            return row_or_arr


def __write_predictions(arr, header, headerless, trim, outfile=None):
    predictions = predict(arr)

    if not headerless:
        if trim:
            header = ','.join([x for i, x in enumerate(header) if i in important_idxs] + ['Prediction'])
        else:
            header = ','.join(header.tolist() + ['Prediction'])
        if outfile is None:
            print(header)
        else:
            print(header, file=outfile)

    for row, prediction in zip(arr, predictions):
        if trim:
            row = ['"' + field + '"' if ',' in field else field for i, field in enumerate(row) if i in important_idxs]
        else:
            row = ['"' + field + '"' if ',' in field else field for field in row]
        row.append(prediction)
        if outfile is None:
            print(','.join(row))
        else:
            print(','.join(row), file=outfile)


def load_data(csvfile, headerless, validate):
    """
    Parameters
    ----------
    csvfile : str
        The path to the CSV file containing the data.

    headerless : bool
        True if the CSV does not contain a header.

    validate : bool
        True if the data should be loaded to be used by the predictor's validate() method.
        False if the data should be loaded to be used by the predictor's predict() method.

    Returns
    -------
    arr : np.ndarray
        The data (observations and labels) found in the CSV without any header.

    data : np.ndarray or NoneType
        None if validate is False, otherwise the observations (data without the labels) found in the CSV.

    labels : np.ndarray or NoneType
        None if the validate is False, otherwise the labels found in the CSV.

    header : np.ndarray or NoneType
        None if the CSV is headerless, otherwise the header.
    """

    with open(csvfile, 'r', encoding='utf-8') as csvinput:
        arr = np.array([__validate_data(row, validate, row_num=i) for i, row in enumerate(csv.reader(csvinput)) if row != []], dtype=str)
    if headerless:
        header = None
    else:
        header = arr[0]
        arr = arr[1:]
    if validate:
        labels = arr[:, target_column]
        feature_columns = [i for i in range(arr.shape[1]) if i != target_column]
        data = arr[:, feature_columns]
    else:
        data, labels = None, None

    if validate and ignorelabels != []:
        idxs_to_keep = np.argwhere(np.logical_not(np.isin(labels, ignorelabels))).reshape(-1)
        labels = labels[idxs_to_keep]
        data = data[idxs_to_keep]

    return arr, data, labels, header


def predict(arr, remap=True, **kwargs):
    """
    Parameters
    ----------
    arr : list[list]
        An array of inputs to be cleaned by 'preprocess_and_clean_in_memory'. This
        should contain all the features that were present in the training data,
        regardless of whether or not they are used by the model, with the same
        relative order as in the training data. There should be no target column.


    remap : bool
        If True and 'return_probs' is False, remaps the output to the original class
        label. If 'return_probs' is True this instead adds a header indicating which
        original class label each column of output corresponds to.

    **kwargs :
        return_probabilities : bool
            If true, return class membership probabilities instead of classifications.

    Returns
    -------
    output : np.ndarray

        A numpy array of
            1. Class predictions if 'return_probabilities' is False.
            2. Class probabilities if 'return_probabilities' is True.

    """
    if not isinstance(arr, np.ndarray) and not isinstance(arr, list):
        raise PredictorError(f'Data must be provided to \'predict\' and \'validate\' as a list or np.ndarray, but an input of type {type(arr).__name__} was found.', 6)
    if isinstance(arr, list):
        arr = np.array(arr, dtype=str)

    kwargs = kwargs or {}
    __validate_kwargs(kwargs)
    __validate_data(arr, False)
    remove_bad_chars = lambda x: str(x).replace('"', '').replace(',', '').replace('(', '').replace(')', '').replace("'", '')
    arr = [[remove_bad_chars(field) for field in row] for row in arr]
    arr = __preprocess_and_clean_in_memory(arr)

    arr = __normalize(arr)

    arr = __transform(arr)

    output = __classify(arr, **kwargs)

    if remap:
        if kwargs.get('return_probabilities'):
            header = np.array([__get_key(i, mapping) for i in range(output.shape[1])], dtype=str).reshape(1, -1)
            output = np.concatenate((header, output), axis=0)
        else:
            output = np.array([__get_key(prediction, mapping) for prediction in output])

    return output


def validate(arr, labels):
    """
    Parameters
    ----------
    cleanarr : np.ndarray
        An array of float values that has undergone each pre-
        prediction step.

    Returns
    -------
    count : int
        A count of the number of instances in cleanarr.

    correct_count : int
        A count of the number of correctly classified instances in
        cleanarr.

    numeachclass : dict
        A dictionary mapping each class to its number of instances.

    outputs : np.ndarray
        The output of the predictor's '__classify' method on cleanarr.
    """
    predictions = predict(arr)
    correct_count = int(np.sum(predictions.reshape(-1) == labels.reshape(-1)))
    count = predictions.shape[0]
    
    class_0, class_1 = __get_key(0, mapping), __get_key(1, mapping)
    num_TP, num_TN, num_FP, num_FN, num_class_1, num_class_0 = 0, 0, 0, 0, 0, 0
    num_TP = int(np.sum(np.logical_and(predictions.reshape(-1) == class_1, labels.reshape(-1) == class_1)))
    num_TN = int(np.sum(np.logical_and(predictions.reshape(-1) == class_0, labels.reshape(-1) == class_0)))
    num_FN = int(np.sum(np.logical_and(predictions.reshape(-1) == class_0, labels.reshape(-1) == class_1)))
    num_FP = int(np.sum(np.logical_and(predictions.reshape(-1) == class_1, labels.reshape(-1) == class_0)))
    num_class_0 = int(np.sum(labels.reshape(-1) == class_0))
    num_class_1 = int(np.sum(labels.reshape(-1) == class_1))
    return count, correct_count, num_TP, num_TN, num_FP, num_FN, num_class_1, num_class_0, predictions


def __main():
    parser = argparse.ArgumentParser(description='Predictor trained on ' + str(TRAINFILE))
    parser.add_argument('csvfile', type=str, help='CSV file containing test set (unlabeled).')
    parser.add_argument('-validate', action='store_true', help='Validation mode. csvfile must be labeled. Output is classification statistics rather than predictions.')
    parser.add_argument('-headerless', help='Do not treat the first line of csvfile as a header.', action='store_true')
    parser.add_argument('-json', action="store_true", default=False, help="report measurements as json")
    parser.add_argument('-trim', action="store_true", help="If true, the prediction will not output ignored columns.")
    args = parser.parse_args()
    faulthandler.enable()

    arr, data, labels, header = load_data(csvfile=args.csvfile, headerless=args.headerless, validate=args.validate)

    if not args.validate:
        __write_predictions(arr, header, args.headerless, args.trim)
    else:

        count, correct_count, num_TP, num_TN, num_FP, num_FN, num_class_1, num_class_0, preds = validate(data, labels)

        classcounts = np.bincount(np.array([mapping[label] for label in labels], dtype='int32')).reshape(-1)
        class_balance = (classcounts[np.argwhere(classcounts > 0)] / arr.shape[0]).reshape(-1).tolist()
        best_guess = round(100.0 * np.max(class_balance), 2)
        H = float(-1.0 * sum([class_balance[i] * math.log(class_balance[i]) / math.log(2) for i in range(len(class_balance))]))
        modelacc = int(float(correct_count * 10000) / count) / 100.0
        mtrx, stats = __confusion_matrix(np.array(labels).reshape(-1), np.array(preds).reshape(-1), args.json)

        if args.json:
            json_dict = {'instance_count': count,
                         'classifier_type': classifier_type,
                         'classes': n_classes,
                         'number_correct': correct_count,
                         'accuracy': {
                             'best_guess': (best_guess/100),
                             'improvement': (modelacc - best_guess)/100,
                              'model_accuracy': (modelacc/100),
                         },
                         'model_capacity': model_cap,
                         'generalization_ratio': int(float(correct_count * 100) / model_cap) / 100.0 * H,
                         'model_efficiency': int(100 * (modelacc - best_guess) / model_cap) / 100.0,
                         'shannon_entropy_of_labels': H,
                         'class_balance': class_balance,
                         'confusion_matrix': mtrx.tolist(),
                         'multiclass_stats': stats}

            print(json.dumps(json_dict))
        else:
            pad = lambda s, length, pad_right: str(s) + ' ' * max(0, length - len(str(s))) if pad_right else ' ' * max(0, length - len(str(s))) + str(s)
            labels = np.array(list(mapping.keys())).reshape(-1, 1)
            max_class_name_len = max([len(clss) for clss in mapping.keys()] + [7])

            max_TP_len = max([len(str(stats[key]['TP'])) for key in stats.keys()] + [2])
            max_FP_len = max([len(str(stats[key]['FP'])) for key in stats.keys()] + [2])
            max_TN_len = max([len(str(stats[key]['TN'])) for key in stats.keys()] + [2])
            max_FN_len = max([len(str(stats[key]['FN'])) for key in stats.keys()] + [2])

            cmat_template_1 = "    {} | {}"
            cmat_template_2 = "    {} | " + " {} " * n_classes
            acc_by_class_template_1 = "    {} | {}  {}  {}  {}  {}  {}  {}  {}  {}  {}"

            acc_by_class_lengths = [max_class_name_len, max_TP_len, max_FP_len, max_TN_len, max_FN_len, 7, 7, 7, 7, 7, 7]
            acc_by_class_header_fields = ['target', 'TP', 'FP', 'TN', 'FN', 'TPR', 'TNR', 'PPV', 'NPV', 'F1', 'TS']
            print("Classifier Type:                    Neural Network")

            print(f"System Type:                        {n_classes}-way classifier\n")

            print("Accuracy:")
            print("    Best-guess accuracy:            {:.2f}%".format(best_guess))
            print("    Model accuracy:                 {:.2f}%".format(modelacc) + " (" + str(int(correct_count)) + "/" + str(count) + " correct)")
            print("    Improvement over best guess:    {:.2f}%".format(modelacc - best_guess) + " (of possible " + str(round(100 - best_guess, 2)) + "%)\n")

            print("Model capacity (MEC):               {:.0f} bits".format(model_cap))
            print("Generalization ratio:               {:.2f}".format(int(float(correct_count * 100) / model_cap) / 100.0 * H) + " bits/bit")

            if report_cmat:
                max_cmat_entry_len = len(str(int(np.max(mtrx))))
                mtrx = np.concatenate((labels, mtrx.astype('str')), axis=1).astype('str')
                max_pred_len = (mtrx.shape[1] - 1) * max_cmat_entry_len + n_classes * 2 - 1
                print("\nConfusion Matrix:\n")
                print(cmat_template_1.format(pad("Actual", max_class_name_len, False), "Predicted"))
                print(cmat_template_1.format("-" * max_class_name_len, "-" * max(max_pred_len, 9)))
                for row in mtrx:
                    print(cmat_template_2.format(
                        *[pad(field, max_class_name_len if i == 0 else max_cmat_entry_len, False) for i, field in enumerate(row)]))

            print("\nAccuracy by Class:\n")
            print(acc_by_class_template_1.format(
                *[pad(header_field, length, False) for i, (header_field, length) in enumerate(zip(acc_by_class_header_fields, acc_by_class_lengths))]))
            print(acc_by_class_template_1.format(
                *["-" * length for length in acc_by_class_lengths]))

            pct_format_string = "{:8.2%}"      # width = 8, decimals = 2
            for raw_class in mapping.keys():
                class_stats = stats[int(mapping[raw_class])]
                TP, FP, TN, FN = class_stats.get('TP', None), class_stats.get('FP', None), class_stats.get('TN', None), class_stats.get('FN', None)
                TPR = pct_format_string.format(class_stats['TPR']) if class_stats['TPR'] is not None else 'N/A'
                TNR = pct_format_string.format(class_stats['TNR']) if class_stats['TNR'] is not None else 'N/A'
                PPV = pct_format_string.format(class_stats['PPV']) if class_stats['PPV'] is not None else 'N/A'
                NPV = pct_format_string.format(class_stats['NPV']) if class_stats['NPV'] is not None else 'N/A'
                F1 = pct_format_string.format(class_stats['F1']) if class_stats['F1'] is not None else 'N/A'
                TS = pct_format_string.format(class_stats['TS']) if class_stats['TS'] is not None else 'N/A'
                line_fields = [raw_class, TP, FP, TN, FN, TPR, TNR, PPV, NPV, F1, TS]
                print(acc_by_class_template_1.format(
                    *[pad(field, length, False) for i, (field, length) in enumerate(zip(line_fields, acc_by_class_lengths))]))


if __name__ == "__main__":
    try:
        __main()
    except PredictorError as e:
        print(e, file=sys.stderr)
        sys.exit(e.code)
    except Exception as e:
        print(f"An unknown exception of type {type(e).__name__} occurred.", file=sys.stderr)
        sys.exit(-1)
